{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "title",
   "metadata": {},
   "source": [
    "# 04a Residual Diagnostics and Specification Tests\n",
    "\n",
    "Breusch-Pagan, White, Durbin-Watson, Breusch-Godfrey, RESET"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "toc",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "- [Residual Plots](#residual-plots)\n",
    "- [Heteroskedasticity Tests](#heteroskedasticity-tests)\n",
    "- [Serial Correlation Tests](#serial-correlation-tests)\n",
    "- [Specification Tests (RESET)](#specification-tests-reset)\n",
    "- [Structural Break (Chow Test)](#structural-break-chow-test)\n",
    "- [Checkpoint (Self-Check)](#checkpoint-self-check)\n",
    "- [Extensions (Optional)](#extensions-optional)\n",
    "- [Reflection](#reflection)\n",
    "- [Solutions (Reference)](#solutions-reference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "why-matters",
   "metadata": {},
   "source": [
    "## Why This Notebook Matters\n",
    "\n",
    "OLS gives you coefficients no matter what. But the standard errors, p-values, and confidence intervals that accompany those coefficients depend on assumptions: homoskedasticity, no serial correlation, and correct functional form. When those assumptions fail, your inference can be badly misleading -- coefficients look significant when they are not, or vice versa.\n",
    "\n",
    "This notebook teaches you to **diagnose** assumption violations and **choose the right remedy**:\n",
    "- Heteroskedasticity detected? Use robust (HC3) or White-corrected standard errors.\n",
    "- Serial correlation detected? Use HAC/Newey-West standard errors.\n",
    "- Functional form wrong? Re-specify the model (add nonlinear terms, logs, interactions).\n",
    "- Structural break? Split the sample or add regime indicators.\n",
    "\n",
    "You will learn to run formal statistical tests (Breusch-Pagan, White, Durbin-Watson, Breusch-Godfrey, RESET, Chow) and interpret them correctly.\n",
    "\n",
    "\n",
    "## Prerequisites (Quick Self-Check)\n",
    "- Completed Parts 00-03 (foundations + data + basic regression).\n",
    "- Familiarity with OLS estimation and `statsmodels` output (see Notebook 00).\n",
    "- Understanding of robust standard errors from Notebook 04.\n",
    "\n",
    "## What You Will Produce\n",
    "- (no file output; learning/analysis notebook)\n",
    "\n",
    "## Success Criteria\n",
    "- You can run every diagnostic test and correctly interpret its null hypothesis and p-value.\n",
    "- You can explain when to use HC3 vs HAC vs re-specification.\n",
    "- You can run your work end-to-end without undefined variables.\n",
    "\n",
    "## Common Pitfalls\n",
    "- Running cells top-to-bottom without reading the instructions.\n",
    "- Leaving `...` placeholders in code cells.\n",
    "- Confusing \"failing to reject\" with \"the assumption holds\" (absence of evidence is not evidence of absence).\n",
    "- Applying Durbin-Watson to cross-sectional data (it is a time-series test).\n",
    "- Treating test results mechanically without thinking about economic context.\n",
    "\n",
    "## Quick Fixes (When You Get Stuck)\n",
    "- If you see `ModuleNotFoundError`, re-run the bootstrap cell and restart the kernel; make sure `PROJECT_ROOT` is the repo root.\n",
    "- If a `data/processed/*` file is missing, either run the matching build script (see guide) or use the notebook's `data/sample/*` fallback.\n",
    "- If results look \"too good,\" suspect leakage; re-check shifts, rolling windows, and time splits.\n",
    "- If a model errors, check dtypes (`astype(float)`) and missingness (`dropna()` on required columns).\n",
    "\n",
    "## Matching Guide\n",
    "- `docs/guides/02_regression/04a_residual_diagnostics.md`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "how-to-use",
   "metadata": {},
   "source": [
    "## How To Use This Notebook\n",
    "- Work section-by-section; don't skip the markdown.\n",
    "- Most code cells are incomplete on purpose: replace TODOs and `...`, then run.\n",
    "- After each section, write 2-4 sentences answering the interpretation prompts (what changed, why it matters).\n",
    "- Prefer `data/processed/*` if you have built the real datasets; otherwise use the bundled `data/sample/*` fallbacks.\n",
    "- Use the **Checkpoint (Self-Check)** section to catch mistakes early.\n",
    "- Use **Solutions (Reference)** only to unblock yourself; then re-implement without looking.\n",
    "- Use the matching guide (`docs/guides/02_regression/04a_residual_diagnostics.md`) for the math, assumptions, and deeper context."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bootstrap-header",
   "metadata": {},
   "source": [
    "<a id=\"environment-bootstrap\"></a>\n",
    "## Environment Bootstrap\n",
    "Run this cell first. It makes the repo importable and defines common directories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bootstrap",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "\n",
    "def find_repo_root(start: Path) -> Path:\n",
    "    p = start\n",
    "    for _ in range(8):\n",
    "        if (p / 'src').exists() and (p / 'docs').exists():\n",
    "            return p\n",
    "        p = p.parent\n",
    "    raise RuntimeError('Could not find repo root. Start Jupyter from the repo root.')\n",
    "\n",
    "\n",
    "PROJECT_ROOT = find_repo_root(Path.cwd())\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.append(str(PROJECT_ROOT))\n",
    "\n",
    "DATA_DIR = PROJECT_ROOT / 'data'\n",
    "RAW_DIR = DATA_DIR / 'raw'\n",
    "PROCESSED_DIR = DATA_DIR / 'processed'\n",
    "SAMPLE_DIR = DATA_DIR / 'sample'\n",
    "\n",
    "PROJECT_ROOT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "goal",
   "metadata": {},
   "source": [
    "## Goal\n",
    "\n",
    "Learn the standard battery of residual diagnostics and specification tests that economists use after fitting an OLS model. By the end of this notebook you will know:\n",
    "\n",
    "1. **Visual diagnostics** -- what patterns in residual plots reveal about model problems.\n",
    "2. **Heteroskedasticity tests** -- Breusch-Pagan and White tests for non-constant variance.\n",
    "3. **Serial correlation tests** -- Durbin-Watson and Breusch-Godfrey for time-series residual dependence.\n",
    "4. **Specification tests** -- Ramsey RESET for functional form misspecification.\n",
    "5. **Structural break detection** -- manual Chow test for regime changes.\n",
    "\n",
    "Each test has a **null hypothesis**. Your job is to interpret the test statistic and p-value, then decide what remedy (if any) is needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "load-data-header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Load Data\n",
    "\n",
    "We use **two** datasets in this notebook:\n",
    "\n",
    "1. **Census county data** (cross-sectional) -- for heteroskedasticity tests and RESET.\n",
    "2. **Macro quarterly data** (time series) -- for serial correlation tests and structural break.\n",
    "\n",
    "### Your Turn (1): Load cross-sectional (county) data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-county",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# --- Cross-sectional data (county level) ---\n",
    "year = 2022  # TODO: set to the year you fetched\n",
    "path_county = PROCESSED_DIR / f'census_county_{year}.csv'\n",
    "\n",
    "if path_county.exists():\n",
    "    df_county = pd.read_csv(path_county)\n",
    "else:\n",
    "    df_county = pd.read_csv(SAMPLE_DIR / 'census_county_sample.csv')\n",
    "\n",
    "# Build log variables for cross-sectional regression\n",
    "income = pd.to_numeric(df_county['B19013_001E'], errors='coerce')\n",
    "rent = pd.to_numeric(df_county['B25064_001E'], errors='coerce')\n",
    "mask = (income > 0) & (rent > 0)\n",
    "\n",
    "df_cs = pd.DataFrame({\n",
    "    'income': income[mask],\n",
    "    'rent': rent[mask],\n",
    "}).dropna()\n",
    "df_cs['log_income'] = np.log(df_cs['income'])\n",
    "df_cs['log_rent'] = np.log(df_cs['rent'])\n",
    "\n",
    "print(f'Cross-sectional obs: {len(df_cs)}')\n",
    "df_cs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "load-macro-header",
   "metadata": {},
   "source": [
    "### Your Turn (2): Load time-series (macro) data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-macro",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Time-series data (macro quarterly) ---\n",
    "path_macro = PROCESSED_DIR / 'macro_quarterly.csv'\n",
    "\n",
    "if path_macro.exists():\n",
    "    df_macro = pd.read_csv(path_macro, index_col=0, parse_dates=True)\n",
    "else:\n",
    "    df_macro = pd.read_csv(SAMPLE_DIR / 'macro_quarterly_sample.csv', index_col=0, parse_dates=True)\n",
    "\n",
    "y_ts_col = 'gdp_growth_qoq'\n",
    "x_ts_cols = ['T10Y2Y_lag1']\n",
    "\n",
    "df_ts = df_macro[[y_ts_col] + x_ts_cols].dropna().copy()\n",
    "\n",
    "print(f'Time-series obs: {len(df_ts)}')\n",
    "df_ts.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fit-baseline-header",
   "metadata": {},
   "source": [
    "### Your Turn (3): Fit baseline OLS models\n",
    "\n",
    "Fit one model on each dataset. We will use these residuals throughout the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fit-baseline",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Cross-sectional model: log(rent) ~ log(income) ---\n",
    "X_cs = sm.add_constant(df_cs[['log_income']], has_constant='add')\n",
    "y_cs = df_cs['log_rent']\n",
    "res_cs = sm.OLS(y_cs, X_cs).fit()\n",
    "\n",
    "# --- Time-series model: gdp_growth ~ T10Y2Y_lag1 ---\n",
    "X_ts = sm.add_constant(df_ts[x_ts_cols], has_constant='add')\n",
    "y_ts = df_ts[y_ts_col]\n",
    "res_ts = sm.OLS(y_ts, X_ts).fit()\n",
    "\n",
    "print('=== Cross-Sectional Model ===')\n",
    "print(res_cs.summary())\n",
    "print('\\n=== Time-Series Model ===')\n",
    "print(res_ts.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "residual-plots-header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id=\"residual-plots\"></a>\n",
    "## 1. Residual Plots\n",
    "\n",
    "### Goal\n",
    "Visually inspect residuals to detect problems before running formal tests.\n",
    "\n",
    "**What to look for:**\n",
    "- **Fan shape** (residuals spread out as fitted values increase) -- suggests heteroskedasticity.\n",
    "- **Curvature** (residuals show a systematic U-shape or pattern) -- suggests nonlinearity / functional form misspecification.\n",
    "- **Outliers** (extreme residuals far from the bulk) -- may distort coefficient estimates.\n",
    "- **Clusters or bands** -- may indicate omitted categorical variables.\n",
    "\n",
    "### Your Turn (1): Fitted vs. residual plot (cross-sectional model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "resid-plot-cs",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# TODO: Plot fitted values vs residuals for the cross-sectional model.\n",
    "# Hint: res_cs.fittedvalues on x-axis, res_cs.resid on y-axis.\n",
    "# Add a horizontal line at y=0 with ax.axhline(0, ...).\n",
    "# Look for fan shapes or curvature.\n",
    "ax = axes[0]\n",
    "ax.set_title('Cross-Sectional: Fitted vs Residuals')\n",
    "ax.set_xlabel('Fitted values')\n",
    "ax.set_ylabel('Residuals')\n",
    "...\n",
    "\n",
    "# TODO: Plot fitted values vs residuals for the time-series model.\n",
    "ax = axes[1]\n",
    "ax.set_title('Time-Series: Fitted vs Residuals')\n",
    "ax.set_xlabel('Fitted values')\n",
    "ax.set_ylabel('Residuals')\n",
    "...\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "resid-ts-plot-header",
   "metadata": {},
   "source": [
    "### Your Turn (2): Residuals over time (time-series model only)\n",
    "\n",
    "For time-series data, also plot residuals against time. Look for trends, volatility clustering, or level shifts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "resid-time-plot",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 4))\n",
    "\n",
    "# TODO: Plot residuals over time for the time-series model.\n",
    "# Hint: res_ts.resid has a datetime index.\n",
    "# Add a horizontal line at y=0.\n",
    "# Look for periods of high vs low volatility or level shifts.\n",
    "...\n",
    "\n",
    "ax.set_title('Time-Series Residuals Over Time')\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel('Residual')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "resid-interpret",
   "metadata": {},
   "source": [
    "### Interpretation Prompt\n",
    "\n",
    "Write 2-4 sentences:\n",
    "- Do you see a fan shape in the cross-sectional plot? What does that suggest?\n",
    "- Do the time-series residuals look \"well-behaved\" (randomly scattered around zero) or do you see patterns?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "resid-interpret-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Write your interpretation.\n",
    "notes = \"\"\"\n",
    "...\n",
    "\"\"\"\n",
    "print(notes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "het-tests-header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id=\"heteroskedasticity-tests\"></a>\n",
    "## 2. Heteroskedasticity Tests\n",
    "\n",
    "### Goal\n",
    "Formally test whether the variance of residuals depends on the regressors (heteroskedasticity).\n",
    "\n",
    "**Key idea:**\n",
    "- **Null hypothesis ($H_0$):** Residuals are homoskedastic (constant variance).\n",
    "- **Alternative ($H_1$):** Residual variance varies with regressors.\n",
    "- **Low p-value** $\\Rightarrow$ reject $H_0$ $\\Rightarrow$ evidence of heteroskedasticity $\\Rightarrow$ use robust SE (e.g., HC3).\n",
    "\n",
    "### Two tests:\n",
    "\n",
    "| Test | What it regresses $e^2$ on | Flexibility |\n",
    "|------|---------------------------|-------------|\n",
    "| **Breusch-Pagan** | Original regressors ($X$) | Detects linear relationship between variance and $X$ |\n",
    "| **White** | $X$, $X^2$, and cross-products | Detects more general patterns (but uses more degrees of freedom) |\n",
    "\n",
    "### Your Turn (1): Breusch-Pagan test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bp-test",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.diagnostic import het_breuschpagan\n",
    "\n",
    "# TODO: Run the Breusch-Pagan test on the cross-sectional model.\n",
    "# het_breuschpagan returns (LM stat, LM p-value, F stat, F p-value)\n",
    "# Pass: residuals and the exogenous variables (including constant)\n",
    "bp_stat, bp_pval, bp_fstat, bp_fpval = het_breuschpagan(..., ...)\n",
    "\n",
    "print('Breusch-Pagan Test (Cross-Sectional Model)')\n",
    "print(f'  LM statistic : {bp_stat:.4f}')\n",
    "print(f'  LM p-value   : {bp_pval:.4f}')\n",
    "print(f'  F statistic  : {bp_fstat:.4f}')\n",
    "print(f'  F p-value    : {bp_fpval:.4f}')\n",
    "print(f'  Conclusion   : {\"Reject H0 (heteroskedastic)\" if bp_pval < 0.05 else \"Fail to reject H0 (homoskedastic)\"}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "white-test-header",
   "metadata": {},
   "source": [
    "### Your Turn (2): White test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "white-test",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.diagnostic import het_white\n",
    "\n",
    "# TODO: Run the White test on the cross-sectional model.\n",
    "# het_white returns (LM stat, LM p-value, F stat, F p-value)\n",
    "# Pass: residuals and the exogenous variables (including constant)\n",
    "white_stat, white_pval, white_fstat, white_fpval = het_white(..., ...)\n",
    "\n",
    "print('White Test (Cross-Sectional Model)')\n",
    "print(f'  LM statistic : {white_stat:.4f}')\n",
    "print(f'  LM p-value   : {white_pval:.4f}')\n",
    "print(f'  F statistic  : {white_fstat:.4f}')\n",
    "print(f'  F p-value    : {white_fpval:.4f}')\n",
    "print(f'  Conclusion   : {\"Reject H0 (heteroskedastic)\" if white_pval < 0.05 else \"Fail to reject H0 (homoskedastic)\"}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "het-compare-header",
   "metadata": {},
   "source": [
    "### Your Turn (3): Compare naive vs robust SE\n",
    "\n",
    "If heteroskedasticity is detected, the remedy is straightforward: use robust standard errors. The coefficients stay the same; only the SE / p-values / CI change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "het-compare",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Fit the same cross-sectional model with HC3 robust SE.\n",
    "# Compare the SE for log_income between naive and HC3.\n",
    "res_cs_hc3 = res_cs.get_robustcov_results(cov_type='HC3')\n",
    "\n",
    "print('Coefficient comparison (should be identical):')\n",
    "print(f'  Naive coef : {res_cs.params[\"log_income\"]:.4f}')\n",
    "print(f'  HC3 coef   : {res_cs_hc3.params[\"log_income\"]:.4f}')\n",
    "print()\n",
    "print('Standard error comparison:')\n",
    "print(f'  Naive SE   : {res_cs.bse[\"log_income\"]:.4f}')\n",
    "print(f'  HC3 SE     : {res_cs_hc3.bse[\"log_income\"]:.4f}')\n",
    "print()\n",
    "\n",
    "# TODO: What happened to the SE? Did it increase or decrease?\n",
    "# Write a 1-sentence interpretation.\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "het-interpret",
   "metadata": {},
   "source": [
    "### Interpretation Prompt\n",
    "\n",
    "Write 2-4 sentences:\n",
    "- Do the Breusch-Pagan and White tests agree? Why might they differ?\n",
    "- If you reject homoskedasticity, what is the practical remedy?\n",
    "- Does heteroskedasticity bias your coefficients, or only your inference (SE, CI, p-values)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "het-interpret-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Write your interpretation.\n",
    "notes = \"\"\"\n",
    "...\n",
    "\"\"\"\n",
    "print(notes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "serial-corr-header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id=\"serial-correlation-tests\"></a>\n",
    "## 3. Serial Correlation Tests\n",
    "\n",
    "### Goal\n",
    "Test whether the regression residuals are autocorrelated (common in macro time series).\n",
    "\n",
    "**Key idea:**\n",
    "- **Null hypothesis ($H_0$):** No autocorrelation in residuals.\n",
    "- **Alternative ($H_1$):** Residuals are serially correlated.\n",
    "- **Low p-value** $\\Rightarrow$ reject $H_0$ $\\Rightarrow$ evidence of serial correlation $\\Rightarrow$ use HAC/Newey-West SE.\n",
    "\n",
    "### Two tests:\n",
    "\n",
    "| Test | What it checks | Notes |\n",
    "|------|---------------|-------|\n",
    "| **Durbin-Watson** | AR(1) autocorrelation only | Value near 2 = no autocorrelation; near 0 = positive; near 4 = negative |\n",
    "| **Breusch-Godfrey** | AR(p) autocorrelation at multiple lags | More general; you choose the number of lags |\n",
    "\n",
    "**Important:** These tests are for **time-series** data. Applying them to cross-sectional data is meaningless unless the data has a natural ordering.\n",
    "\n",
    "### Your Turn (1): Durbin-Watson statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dw-test",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.stattools import durbin_watson\n",
    "\n",
    "# TODO: Compute the Durbin-Watson statistic for the time-series model.\n",
    "# durbin_watson takes an array of residuals.\n",
    "dw_stat = durbin_watson(...)\n",
    "\n",
    "print('Durbin-Watson Test (Time-Series Model)')\n",
    "print(f'  DW statistic : {dw_stat:.4f}')\n",
    "print(f'  Interpretation:')\n",
    "if dw_stat < 1.5:\n",
    "    print('    Value < 1.5: Evidence of positive autocorrelation.')\n",
    "elif dw_stat > 2.5:\n",
    "    print('    Value > 2.5: Evidence of negative autocorrelation.')\n",
    "else:\n",
    "    print('    Value near 2: Little evidence of AR(1) autocorrelation.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bg-test-header",
   "metadata": {},
   "source": [
    "### Your Turn (2): Breusch-Godfrey test\n",
    "\n",
    "Unlike Durbin-Watson, Breusch-Godfrey can test for autocorrelation at higher lags and works with lagged dependent variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bg-test",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.diagnostic import acorr_breusch_godfrey\n",
    "\n",
    "# TODO: Run the Breusch-Godfrey test for lags 1 through 4.\n",
    "# acorr_breusch_godfrey returns (LM stat, LM p-value, F stat, F p-value)\n",
    "bg_stat, bg_pval, bg_fstat, bg_fpval = acorr_breusch_godfrey(res_ts, nlags=...)\n",
    "\n",
    "print('Breusch-Godfrey Test (Time-Series Model, 4 lags)')\n",
    "print(f'  LM statistic : {bg_stat:.4f}')\n",
    "print(f'  LM p-value   : {bg_pval:.4f}')\n",
    "print(f'  F statistic  : {bg_fstat:.4f}')\n",
    "print(f'  F p-value    : {bg_fpval:.4f}')\n",
    "print(f'  Conclusion   : {\"Reject H0 (serial correlation)\" if bg_pval < 0.05 else \"Fail to reject H0 (no serial correlation)\"}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "serial-compare-header",
   "metadata": {},
   "source": [
    "### Your Turn (3): Compare naive vs HAC SE\n",
    "\n",
    "If serial correlation is detected, the remedy is HAC (Heteroskedasticity and Autocorrelation Consistent) standard errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "serial-compare",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Fit the same time-series model with HAC robust SE (maxlags=4).\n",
    "# Compare the SE for T10Y2Y_lag1 between naive and HAC.\n",
    "res_ts_hac = res_ts.get_robustcov_results(cov_type='HAC', cov_kwds={'maxlags': ...})\n",
    "\n",
    "print('Coefficient comparison (should be identical):')\n",
    "print(f'  Naive coef : {res_ts.params[\"T10Y2Y_lag1\"]:.4f}')\n",
    "print(f'  HAC coef   : {res_ts_hac.params[\"T10Y2Y_lag1\"]:.4f}')\n",
    "print()\n",
    "print('Standard error comparison:')\n",
    "print(f'  Naive SE   : {res_ts.bse[\"T10Y2Y_lag1\"]:.4f}')\n",
    "print(f'  HAC SE     : {res_ts_hac.bse[\"T10Y2Y_lag1\"]:.4f}')\n",
    "print()\n",
    "print('P-value comparison:')\n",
    "print(f'  Naive p    : {res_ts.pvalues[\"T10Y2Y_lag1\"]:.4f}')\n",
    "print(f'  HAC p      : {res_ts_hac.pvalues[\"T10Y2Y_lag1\"]:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "serial-interpret",
   "metadata": {},
   "source": [
    "### Interpretation Prompt\n",
    "\n",
    "Write 2-4 sentences:\n",
    "- What does the Durbin-Watson value tell you? Does Breusch-Godfrey agree?\n",
    "- How did HAC correction affect the standard errors and p-values?\n",
    "- If serial correlation is present, does it bias coefficients or only inference?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "serial-interpret-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Write your interpretation.\n",
    "notes = \"\"\"\n",
    "...\n",
    "\"\"\"\n",
    "print(notes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reset-header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id=\"specification-tests-reset\"></a>\n",
    "## 4. Specification Tests (RESET)\n",
    "\n",
    "### Goal\n",
    "Test whether the functional form of the model is correctly specified.\n",
    "\n",
    "**Ramsey RESET (Regression Equation Specification Error Test):**\n",
    "- Adds powers of the fitted values ($\\hat{y}^2$, $\\hat{y}^3$) to the regression.\n",
    "- If these extra terms are jointly significant, the original specification may be wrong (missing nonlinearities, interactions, or transformations).\n",
    "- **Null hypothesis ($H_0$):** The functional form is correctly specified (powers of $\\hat{y}$ add no explanatory power).\n",
    "- **Low p-value** $\\Rightarrow$ reject $H_0$ $\\Rightarrow$ consider adding polynomial terms, logs, or interactions.\n",
    "\n",
    "### Your Turn (1): RESET test on the cross-sectional model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reset-cs",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.diagnostic import linear_reset\n",
    "\n",
    "# TODO: Run the RESET test on the cross-sectional model.\n",
    "# linear_reset returns a test result object with .statistic and .pvalue attributes.\n",
    "# The 'power' parameter controls which powers of y_hat to include (default is [2, 3]).\n",
    "reset_cs = linear_reset(res_cs, power=...)\n",
    "\n",
    "print('RESET Test (Cross-Sectional Model)')\n",
    "print(f'  F statistic : {reset_cs.statistic:.4f}')\n",
    "print(f'  p-value     : {reset_cs.pvalue:.4f}')\n",
    "print(f'  Conclusion  : {\"Reject H0 (misspecification)\" if reset_cs.pvalue < 0.05 else \"Fail to reject H0 (no evidence of misspecification)\"}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reset-ts-header",
   "metadata": {},
   "source": [
    "### Your Turn (2): RESET test on the time-series model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reset-ts",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Run the RESET test on the time-series model.\n",
    "reset_ts = linear_reset(res_ts, power=...)\n",
    "\n",
    "print('RESET Test (Time-Series Model)')\n",
    "print(f'  F statistic : {reset_ts.statistic:.4f}')\n",
    "print(f'  p-value     : {reset_ts.pvalue:.4f}')\n",
    "print(f'  Conclusion  : {\"Reject H0 (misspecification)\" if reset_ts.pvalue < 0.05 else \"Fail to reject H0 (no evidence of misspecification)\"}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reset-interpret",
   "metadata": {},
   "source": [
    "### Interpretation Prompt\n",
    "\n",
    "Write 2-4 sentences:\n",
    "- If RESET rejects, what does that suggest about your model?\n",
    "- What would you do next? (Add polynomial terms? Transform variables? Add interactions?)\n",
    "- Does RESET tell you *what* the correct specification is, or only that the current one is wrong?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reset-interpret-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Write your interpretation.\n",
    "notes = \"\"\"\n",
    "...\n",
    "\"\"\"\n",
    "print(notes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chow-header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id=\"structural-break-chow-test\"></a>\n",
    "## 5. Structural Break (Chow Test)\n",
    "\n",
    "### Goal\n",
    "Test whether the regression coefficients are stable across two sub-periods, or whether there is a structural break at a known date.\n",
    "\n",
    "**Chow test intuition:**\n",
    "1. Estimate the model on the **full sample** and get the sum of squared residuals ($SSR_{full}$).\n",
    "2. Split the sample at a known break date. Estimate the model on **each sub-sample** separately ($SSR_1$, $SSR_2$).\n",
    "3. If the model is the same in both sub-periods, then $SSR_{full} \\approx SSR_1 + SSR_2$.\n",
    "4. If the model differs, $SSR_{full}$ will be much larger than $SSR_1 + SSR_2$.\n",
    "\n",
    "**Test statistic:**\n",
    "\n",
    "$$F = \\frac{(SSR_{full} - SSR_1 - SSR_2) / k}{(SSR_1 + SSR_2) / (n - 2k)}$$\n",
    "\n",
    "where $k$ is the number of parameters and $n$ is the total number of observations.\n",
    "\n",
    "- **Null hypothesis ($H_0$):** No structural break (coefficients are the same in both sub-periods).\n",
    "- **Low p-value** $\\Rightarrow$ reject $H_0$ $\\Rightarrow$ evidence of a structural break.\n",
    "\n",
    "### Your Turn (1): Choose a break date and split the sample\n",
    "\n",
    "We will split the macro time series at the Great Recession (2008-Q4) as a natural candidate for a structural break."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chow-split",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Choose a break date and split the time-series data.\n",
    "break_date = '2008-12-31'\n",
    "\n",
    "df_pre = df_ts[df_ts.index <= break_date].copy()\n",
    "df_post = df_ts[df_ts.index > break_date].copy()\n",
    "\n",
    "print(f'Pre-break obs  : {len(df_pre)}  ({df_pre.index.min().date()} to {df_pre.index.max().date()})')\n",
    "print(f'Post-break obs : {len(df_post)}  ({df_post.index.min().date()} to {df_post.index.max().date()})')\n",
    "\n",
    "# Sanity check: both sub-samples need enough observations\n",
    "assert len(df_pre) >= 10, 'Pre-break sample too small'\n",
    "assert len(df_post) >= 10, 'Post-break sample too small'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chow-compute-header",
   "metadata": {},
   "source": [
    "### Your Turn (2): Compute the Chow test statistic manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chow-compute",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "# TODO: Fit OLS on each sub-sample and compute SSR.\n",
    "\n",
    "# Full-sample SSR (already have this from res_ts)\n",
    "ssr_full = res_ts.ssr\n",
    "\n",
    "# Pre-break model\n",
    "X_pre = sm.add_constant(df_pre[x_ts_cols], has_constant='add')\n",
    "y_pre = df_pre[y_ts_col]\n",
    "res_pre = sm.OLS(y_pre, X_pre).fit()\n",
    "ssr_pre = ...\n",
    "\n",
    "# Post-break model\n",
    "X_post = sm.add_constant(df_post[x_ts_cols], has_constant='add')\n",
    "y_post = df_post[y_ts_col]\n",
    "res_post = sm.OLS(y_post, X_post).fit()\n",
    "ssr_post = ...\n",
    "\n",
    "# Chow F-statistic\n",
    "k = len(res_ts.params)           # number of parameters (including constant)\n",
    "n = len(df_ts)                    # total observations\n",
    "\n",
    "# TODO: Compute the F statistic using the formula above.\n",
    "chow_f = ...\n",
    "chow_pval = 1 - stats.f.cdf(chow_f, dfn=k, dfd=n - 2 * k)\n",
    "\n",
    "print('Chow Test (Structural Break)')\n",
    "print(f'  Break date   : {break_date}')\n",
    "print(f'  SSR (full)   : {ssr_full:.4f}')\n",
    "print(f'  SSR (pre)    : {ssr_pre:.4f}')\n",
    "print(f'  SSR (post)   : {ssr_post:.4f}')\n",
    "print(f'  F statistic  : {chow_f:.4f}')\n",
    "print(f'  p-value      : {chow_pval:.4f}')\n",
    "print(f'  Conclusion   : {\"Reject H0 (structural break)\" if chow_pval < 0.05 else \"Fail to reject H0 (no structural break)\"}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chow-coef-header",
   "metadata": {},
   "source": [
    "### Your Turn (3): Compare coefficients across sub-samples\n",
    "\n",
    "Even without a formal test, comparing coefficients visually helps build intuition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chow-coef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Print and compare coefficients from pre- and post-break models.\n",
    "comparison = pd.DataFrame({\n",
    "    'Full Sample': res_ts.params,\n",
    "    'Pre-Break': ...,\n",
    "    'Post-Break': ...,\n",
    "})\n",
    "\n",
    "print('Coefficient Comparison Across Sub-Samples')\n",
    "print(comparison.round(4))\n",
    "print()\n",
    "print('If coefficients differ substantially, the relationship may have changed after the break.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chow-interpret",
   "metadata": {},
   "source": [
    "### Interpretation Prompt\n",
    "\n",
    "Write 2-4 sentences:\n",
    "- Does the Chow test suggest a structural break at 2008-Q4?\n",
    "- How do the coefficients differ between sub-periods?\n",
    "- What are the limitations of the Chow test? (Hint: you must choose the break date in advance.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chow-interpret-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Write your interpretation.\n",
    "notes = \"\"\"\n",
    "...\n",
    "\"\"\"\n",
    "print(notes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary-table-header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary: Diagnostic Decision Table\n",
    "\n",
    "| Problem | Visual Clue | Formal Test | Remedy |\n",
    "|---------|------------|-------------|--------|\n",
    "| Heteroskedasticity | Fan shape in residual plot | Breusch-Pagan, White | HC3 robust SE |\n",
    "| Serial correlation | Residuals cluster in time | Durbin-Watson, Breusch-Godfrey | HAC/Newey-West SE |\n",
    "| Functional form | Curvature in residual plot | Ramsey RESET | Add nonlinear terms, logs, interactions |\n",
    "| Structural break | Level shift in residuals over time | Chow test | Split sample, add regime dummies |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "checkpoint-header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id=\"checkpoint-self-check\"></a>\n",
    "## Checkpoint (Self-Check)\n",
    "\n",
    "Run a few asserts and write 2-3 sentences summarizing what you verified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "checkpoint",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Validate your results. Uncomment and adjust as needed.\n",
    "\n",
    "# Cross-sectional data loaded\n",
    "# assert df_cs.shape[0] > 50, f'Too few county observations: {df_cs.shape[0]}'\n",
    "\n",
    "# Time-series data loaded\n",
    "# assert df_ts.shape[0] > 30, f'Too few time-series observations: {df_ts.shape[0]}'\n",
    "\n",
    "# Breusch-Pagan ran successfully\n",
    "# assert 0 <= bp_pval <= 1, f'BP p-value out of range: {bp_pval}'\n",
    "\n",
    "# White test ran successfully\n",
    "# assert 0 <= white_pval <= 1, f'White p-value out of range: {white_pval}'\n",
    "\n",
    "# Durbin-Watson in valid range\n",
    "# assert 0 <= dw_stat <= 4, f'DW statistic out of range: {dw_stat}'\n",
    "\n",
    "# Breusch-Godfrey ran successfully\n",
    "# assert 0 <= bg_pval <= 1, f'BG p-value out of range: {bg_pval}'\n",
    "\n",
    "# RESET ran successfully\n",
    "# assert 0 <= reset_cs.pvalue <= 1, f'RESET p-value out of range'\n",
    "\n",
    "# Chow test: SSR_full >= SSR_pre + SSR_post (by construction)\n",
    "# assert ssr_full >= ssr_pre + ssr_post - 1e-6, 'SSR arithmetic check failed'\n",
    "\n",
    "print('All checkpoint assertions passed.')\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extensions-header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id=\"extensions-optional\"></a>\n",
    "## Extensions (Optional)\n",
    "\n",
    "- Try running the heteroskedasticity tests on the **time-series** model. Do you find heteroskedasticity there too?\n",
    "- Run the Breusch-Godfrey test at different lag lengths (1, 2, 4, 8). How sensitive are the results to the lag choice?\n",
    "- If RESET rejects, try adding a squared term (e.g., `log_income**2`) to the cross-sectional model and re-run RESET. Does it pass now?\n",
    "- Try different break dates for the Chow test (e.g., 2001-Q3 for 9/11, 2020-Q1 for COVID). Which break is most significant?\n",
    "- Implement a **rolling Chow test** that moves the break date across the sample and plots the F-statistic over time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reflection-header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id=\"reflection\"></a>\n",
    "## Reflection\n",
    "\n",
    "- What did you assume implicitly when running these tests (e.g., about the data-generating process, normality, correct specification of the auxiliary regression)?\n",
    "- Can you \"test your way\" to a correct model, or do diagnostics only flag certain problems?\n",
    "- In practice, do you run all of these tests on every model, or do you select based on context (cross-section vs time series, domain knowledge)?\n",
    "- If you had to ship a regression-based forecast, which of these diagnostics would you include in your model monitoring dashboard?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "solutions-header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id=\"solutions-reference\"></a>\n",
    "## Solutions (Reference)\n",
    "\n",
    "Try the TODOs first. Use these only to unblock yourself or to compare approaches.\n",
    "\n",
    "<details><summary>Solution: Residual Plots</summary>\n",
    "\n",
    "_One possible approach. Your variable names may differ; align them with the notebook._\n",
    "\n",
    "```python\n",
    "# Reference solution for 04a — Residual Plots\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Cross-sectional: fitted vs residuals\n",
    "ax = axes[0]\n",
    "ax.scatter(res_cs.fittedvalues, res_cs.resid, alpha=0.3, s=10)\n",
    "ax.axhline(0, color='red', linestyle='--', linewidth=1)\n",
    "ax.set_title('Cross-Sectional: Fitted vs Residuals')\n",
    "ax.set_xlabel('Fitted values')\n",
    "ax.set_ylabel('Residuals')\n",
    "\n",
    "# Time-series: fitted vs residuals\n",
    "ax = axes[1]\n",
    "ax.scatter(res_ts.fittedvalues, res_ts.resid, alpha=0.5, s=15)\n",
    "ax.axhline(0, color='red', linestyle='--', linewidth=1)\n",
    "ax.set_title('Time-Series: Fitted vs Residuals')\n",
    "ax.set_xlabel('Fitted values')\n",
    "ax.set_ylabel('Residuals')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "```python\n",
    "# Residuals over time\n",
    "fig, ax = plt.subplots(figsize=(10, 4))\n",
    "ax.plot(res_ts.resid.index, res_ts.resid.values, linewidth=0.8)\n",
    "ax.axhline(0, color='red', linestyle='--', linewidth=1)\n",
    "ax.set_title('Time-Series Residuals Over Time')\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel('Residual')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "<details><summary>Solution: Heteroskedasticity Tests</summary>\n",
    "\n",
    "_One possible approach. Your variable names may differ; align them with the notebook._\n",
    "\n",
    "```python\n",
    "# Reference solution for 04a — Heteroskedasticity Tests\n",
    "from statsmodels.stats.diagnostic import het_breuschpagan, het_white\n",
    "\n",
    "# Breusch-Pagan\n",
    "bp_stat, bp_pval, bp_fstat, bp_fpval = het_breuschpagan(res_cs.resid, res_cs.model.exog)\n",
    "print(f'BP p-value: {bp_pval:.4f}')\n",
    "\n",
    "# White\n",
    "white_stat, white_pval, white_fstat, white_fpval = het_white(res_cs.resid, res_cs.model.exog)\n",
    "print(f'White p-value: {white_pval:.4f}')\n",
    "\n",
    "# Robust SE comparison\n",
    "res_cs_hc3 = res_cs.get_robustcov_results(cov_type='HC3')\n",
    "print(f'Naive SE: {res_cs.bse[\"log_income\"]:.4f}')\n",
    "print(f'HC3 SE:   {res_cs_hc3.bse[\"log_income\"]:.4f}')\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "<details><summary>Solution: Serial Correlation Tests</summary>\n",
    "\n",
    "_One possible approach. Your variable names may differ; align them with the notebook._\n",
    "\n",
    "```python\n",
    "# Reference solution for 04a — Serial Correlation Tests\n",
    "from statsmodels.stats.stattools import durbin_watson\n",
    "from statsmodels.stats.diagnostic import acorr_breusch_godfrey\n",
    "\n",
    "# Durbin-Watson\n",
    "dw_stat = durbin_watson(res_ts.resid)\n",
    "print(f'DW statistic: {dw_stat:.4f}')\n",
    "\n",
    "# Breusch-Godfrey (4 lags)\n",
    "bg_stat, bg_pval, bg_fstat, bg_fpval = acorr_breusch_godfrey(res_ts, nlags=4)\n",
    "print(f'BG p-value: {bg_pval:.4f}')\n",
    "\n",
    "# HAC comparison\n",
    "res_ts_hac = res_ts.get_robustcov_results(cov_type='HAC', cov_kwds={'maxlags': 4})\n",
    "print(f'Naive SE: {res_ts.bse[\"T10Y2Y_lag1\"]:.4f}')\n",
    "print(f'HAC SE:   {res_ts_hac.bse[\"T10Y2Y_lag1\"]:.4f}')\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "<details><summary>Solution: Specification Tests (RESET)</summary>\n",
    "\n",
    "_One possible approach. Your variable names may differ; align them with the notebook._\n",
    "\n",
    "```python\n",
    "# Reference solution for 04a — RESET\n",
    "from statsmodels.stats.diagnostic import linear_reset\n",
    "\n",
    "# Cross-sectional RESET (powers 2 and 3)\n",
    "reset_cs = linear_reset(res_cs, power=np.array([2, 3]))\n",
    "print(f'RESET (CS) F={reset_cs.statistic:.4f}, p={reset_cs.pvalue:.4f}')\n",
    "\n",
    "# Time-series RESET\n",
    "reset_ts = linear_reset(res_ts, power=np.array([2, 3]))\n",
    "print(f'RESET (TS) F={reset_ts.statistic:.4f}, p={reset_ts.pvalue:.4f}')\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "<details><summary>Solution: Structural Break (Chow Test)</summary>\n",
    "\n",
    "_One possible approach. Your variable names may differ; align them with the notebook._\n",
    "\n",
    "```python\n",
    "# Reference solution for 04a — Chow Test\n",
    "from scipy import stats\n",
    "\n",
    "break_date = '2008-12-31'\n",
    "df_pre = df_ts[df_ts.index <= break_date].copy()\n",
    "df_post = df_ts[df_ts.index > break_date].copy()\n",
    "\n",
    "# Full sample SSR\n",
    "ssr_full = res_ts.ssr\n",
    "\n",
    "# Pre-break\n",
    "X_pre = sm.add_constant(df_pre[x_ts_cols], has_constant='add')\n",
    "y_pre = df_pre[y_ts_col]\n",
    "res_pre = sm.OLS(y_pre, X_pre).fit()\n",
    "ssr_pre = res_pre.ssr\n",
    "\n",
    "# Post-break\n",
    "X_post = sm.add_constant(df_post[x_ts_cols], has_constant='add')\n",
    "y_post = df_post[y_ts_col]\n",
    "res_post = sm.OLS(y_post, X_post).fit()\n",
    "ssr_post = res_post.ssr\n",
    "\n",
    "# F statistic\n",
    "k = len(res_ts.params)\n",
    "n = len(df_ts)\n",
    "chow_f = ((ssr_full - ssr_pre - ssr_post) / k) / ((ssr_pre + ssr_post) / (n - 2 * k))\n",
    "chow_pval = 1 - stats.f.cdf(chow_f, dfn=k, dfd=n - 2 * k)\n",
    "\n",
    "print(f'Chow F={chow_f:.4f}, p={chow_pval:.4f}')\n",
    "\n",
    "# Coefficient comparison\n",
    "comparison = pd.DataFrame({\n",
    "    'Full Sample': res_ts.params,\n",
    "    'Pre-Break': res_pre.params,\n",
    "    'Post-Break': res_post.params,\n",
    "})\n",
    "print(comparison.round(4))\n",
    "```\n",
    "\n",
    "</details>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbformat_minor": 5,
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
