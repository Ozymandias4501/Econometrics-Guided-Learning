{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 06 Rolling Regressions and Stability\n",
        "\n",
        "Rolling windows to see regime changes.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Table of Contents\n",
        "- [Rolling regression](#rolling-regression)\n",
        "- [Coefficient drift](#coefficient-drift)\n",
        "- [Regime interpretation](#regime-interpretation)\n",
        "- [Checkpoint (Self-Check)](#checkpoint-self-check)\n",
        "- [Solutions (Reference)](#solutions-reference)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Why This Notebook Matters\n",
        "Regression is the bridge between statistics and ML. You will learn:\n",
        "- single-factor vs multi-factor interpretation,\n",
        "- robust standard errors,\n",
        "- coefficient stability and multicollinearity.\n",
        "\n",
        "\n",
        "## Prerequisites (Quick Self-Check)\n",
        "- Completed Parts 00\u201301 (foundations + data).\n",
        "- Basic algebra comfort (reading coefficient tables, units).\n",
        "\n",
        "## What You Will Produce\n",
        "- (no file output; learning/analysis notebook)\n",
        "\n",
        "## Success Criteria\n",
        "- You can explain what you built and why each step exists.\n",
        "- You can run your work end-to-end without undefined variables.\n",
        "\n",
        "## Common Pitfalls\n",
        "- Running cells top-to-bottom without reading the instructions.\n",
        "- Leaving `...` placeholders in code cells.\n",
        "- Treating coefficients as causal without a causal design.\n",
        "- Ignoring multicollinearity (unstable coefficients).\n",
        "\n",
        "## Quick Fixes (When You Get Stuck)\n",
        "- If you see `ModuleNotFoundError`, re-run the bootstrap cell and restart the kernel; make sure `PROJECT_ROOT` is the repo root.\n",
        "- If a `data/processed/*` file is missing, either run the matching build script (see guide) or use the notebook\u2019s `data/sample/*` fallback.\n",
        "- If results look \u201ctoo good,\u201d suspect leakage; re-check shifts, rolling windows, and time splits.\n",
        "- If a model errors, check dtypes (`astype(float)`) and missingness (`dropna()` on required columns).\n",
        "\n",
        "## Matching Guide\n",
        "- `docs/guides/02_regression/06_rolling_regressions_stability.md`\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## How To Use This Notebook\n",
        "- Work section-by-section; don\u2019t skip the markdown.\n",
        "- Most code cells are incomplete on purpose: replace TODOs and `...`, then run.\n",
        "- After each section, write 2\u20134 sentences answering the interpretation prompts (what changed, why it matters).\n",
        "- Prefer `data/processed/*` if you have built the real datasets; otherwise use the bundled `data/sample/*` fallbacks.\n",
        "- Use the **Checkpoint (Self-Check)** section to catch mistakes early.\n",
        "- Use **Solutions (Reference)** only to unblock yourself; then re-implement without looking.\n",
        "- Use the matching guide (`docs/guides/02_regression/06_rolling_regressions_stability.md`) for the math, assumptions, and deeper context.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"environment-bootstrap\"></a>\n",
        "## Environment Bootstrap\n",
        "Run this cell first. It makes the repo importable and defines common directories.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "from pathlib import Path\n",
        "import sys\n",
        "\n",
        "\n",
        "def find_repo_root(start: Path) -> Path:\n",
        "    p = start\n",
        "    for _ in range(8):\n",
        "        if (p / 'src').exists() and (p / 'docs').exists():\n",
        "            return p\n",
        "        p = p.parent\n",
        "    raise RuntimeError('Could not find repo root. Start Jupyter from the repo root.')\n",
        "\n",
        "\n",
        "PROJECT_ROOT = find_repo_root(Path.cwd())\n",
        "if str(PROJECT_ROOT) not in sys.path:\n",
        "    sys.path.append(str(PROJECT_ROOT))\n",
        "\n",
        "DATA_DIR = PROJECT_ROOT / 'data'\n",
        "RAW_DIR = DATA_DIR / 'raw'\n",
        "PROCESSED_DIR = DATA_DIR / 'processed'\n",
        "SAMPLE_DIR = DATA_DIR / 'sample'\n",
        "\n",
        "PROJECT_ROOT\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Goal\n",
        "Use rolling regressions to see how relationships change over time.\n",
        "\n",
        "This is a realism check:\n",
        "- A coefficient that is stable across decades is rare in macro.\n",
        "- If coefficients drift, you should be cautious about \"the\" relationship.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Primer: pandas time series essentials (indexing, resampling, lags)\n",
        "\n",
        "Most \u201cmysterious bugs\u201d in time series work come from index and alignment mistakes. This primer gives you the minimum patterns to avoid them.\n",
        "\n",
        "### 1) DatetimeIndex (the first thing to verify)\n",
        "\n",
        "Most time-series operations assume a `DatetimeIndex`:\n",
        "\n",
        "```python\n",
        "import pandas as pd\n",
        "\n",
        "df = df.copy()\n",
        "df.index = pd.to_datetime(df.index)\n",
        "df = df.sort_index()\n",
        "assert isinstance(df.index, pd.DatetimeIndex)\n",
        "```\n",
        "\n",
        "**Expected output / sanity checks**\n",
        "- `df.index.min(), df.index.max()` look reasonable\n",
        "- `df.index.is_monotonic_increasing` is `True`\n",
        "\n",
        "### 2) Resampling (frequency alignment)\n",
        "\n",
        "Resampling converts one frequency to another. Choose the aggregation rule intentionally.\n",
        "\n",
        "```python\n",
        "# month-end last value (end-of-period)\n",
        "df_me_last = df.resample(\"ME\").last()\n",
        "\n",
        "# month-end mean (average-of-period)\n",
        "df_me_mean = df.resample(\"ME\").mean()\n",
        "\n",
        "# quarter-end mean\n",
        "df_q_mean = df.resample(\"QE\").mean()\n",
        "```\n",
        "\n",
        "**Interpretation matters**\n",
        "- `.last()` treats end-of-period value as \u201cthe period\u2019s value.\u201d\n",
        "- `.mean()` treats the period average as \u201cthe period\u2019s value.\u201d\n",
        "\n",
        "### 3) Alignment and merging\n",
        "\n",
        "When joining series, always check missingness after the join:\n",
        "\n",
        "```python\n",
        "merged = df1.join(df2, how=\"outer\").sort_index()\n",
        "print(merged.isna().sum().sort_values(ascending=False).head(10))\n",
        "```\n",
        "\n",
        "### 4) Lags and rolling windows (watch for leakage!)\n",
        "\n",
        "```python\n",
        "# lag 1 period (past-only)\n",
        "df[\"x_lag1\"] = df[\"x\"].shift(1)\n",
        "\n",
        "# rolling mean using past values ending at t\n",
        "df[\"x_roll12\"] = df[\"x\"].rolling(12).mean()\n",
        "```\n",
        "\n",
        "**Leakage pitfalls**\n",
        "- `shift(-1)` uses the future.\n",
        "- `rolling(..., center=True)` uses the future.\n",
        "\n",
        "### 5) A quick workflow you should repeat\n",
        "\n",
        "1) Set and verify DatetimeIndex.\n",
        "2) Resample intentionally (mean vs last).\n",
        "3) Join and inspect missingness.\n",
        "4) Add lags/rolls (past-only).\n",
        "5) `dropna()` to build a clean modeling table.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Primer: `statsmodels` vs `scikit-learn` (inference vs prediction)\n",
        "\n",
        "This repo uses both libraries because they serve different goals:\n",
        "\n",
        "- **Prediction (ML):** optimize out-of-sample accuracy \u2192 `scikit-learn`\n",
        "- **Inference (econometrics):** interpret coefficients + quantify uncertainty \u2192 `statsmodels`\n",
        "\n",
        "### Minimal `statsmodels` OLS pattern\n",
        "\n",
        "```python\n",
        "import statsmodels.api as sm\n",
        "\n",
        "# X: DataFrame of features, y: Series target\n",
        "Xc = sm.add_constant(X, has_constant=\"add\")  # add intercept\n",
        "res = sm.OLS(y, Xc).fit()\n",
        "print(res.summary())\n",
        "```\n",
        "\n",
        "**Expected output / sanity check**\n",
        "- a table with `coef`, `std err`, `t`, `P>|t|`, and a CI column\n",
        "- coefficient names match your column names\n",
        "\n",
        "### What you are looking at in `res.summary()`\n",
        "\n",
        "- **coef**: $\\\\hat\\\\beta$ (estimated effect in the model)\n",
        "- **std err**: estimated uncertainty $\\\\widehat{SE}(\\\\hat\\\\beta)$\n",
        "- **t**: $\\\\hat\\\\beta / \\\\widehat{SE}(\\\\hat\\\\beta)$\n",
        "- **P>|t|**: p-value for $H_0: \\\\beta=0$ (conditional on assumptions)\n",
        "- **[0.025, 0.975]**: 95% confidence interval\n",
        "\n",
        "### Robust standard errors (change uncertainty, not coefficients)\n",
        "\n",
        "```python\n",
        "# Cross-section heteroskedasticity\n",
        "res_hc3 = res.get_robustcov_results(cov_type=\"HC3\")\n",
        "\n",
        "# Time series autocorrelation + heteroskedasticity\n",
        "res_hac = res.get_robustcov_results(cov_type=\"HAC\", cov_kwds={\"maxlags\": 4})\n",
        "```\n",
        "\n",
        "### Common pitfalls (and quick fixes)\n",
        "\n",
        "- **Forgetting the intercept**\n",
        "  - Fix: always `add_constant`.\n",
        "- **Wrong SE for time series**\n",
        "  - Fix: use HAC when residuals are autocorrelated.\n",
        "- **Treating p-values as causal proof**\n",
        "  - Fix: write the identification assumption; otherwise interpret as association.\n",
        "- **Mixing prediction and inference**\n",
        "  - Fix: use `sklearn` pipelines + time splits for prediction; use `statsmodels` for coefficient uncertainty.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"rolling-regression\"></a>\n",
        "## Rolling regression\n",
        "\n",
        "### Goal\n",
        "Fit the same regression repeatedly on a moving window.\n",
        "\n",
        "We will start with a simple model:\n",
        "- GDP growth ~ yield curve spread (lagged)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Your Turn (1): Load data and set up the window\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "path = PROCESSED_DIR / 'macro_quarterly.csv'\n",
        "if path.exists():\n",
        "    df = pd.read_csv(path, index_col=0, parse_dates=True)\n",
        "else:\n",
        "    df = pd.read_csv(SAMPLE_DIR / 'macro_quarterly_sample.csv', index_col=0, parse_dates=True)\n",
        "\n",
        "y_col = 'gdp_growth_qoq'\n",
        "x_col = 'T10Y2Y_lag1'\n",
        "\n",
        "df_m = df[[y_col, x_col, 'recession']].dropna().copy()\n",
        "\n",
        "# Rolling window length in quarters\n",
        "window = 40  # ~10 years\n",
        "df_m.head()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Your Turn (2): Fit rolling windows and collect coefficients\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import statsmodels.api as sm\n",
        "\n",
        "rows = []\n",
        "for end in range(window, len(df_m) + 1):\n",
        "    chunk = df_m.iloc[end - window : end]\n",
        "    X = sm.add_constant(chunk[[x_col]], has_constant='add')\n",
        "    y = chunk[y_col]\n",
        "    res = sm.OLS(y, X).fit()\n",
        "\n",
        "    # Record the coefficient on x_col and a simple CI\n",
        "    beta = float(res.params[x_col])\n",
        "    ci_low, ci_high = res.conf_int().loc[x_col].tolist()\n",
        "    rows.append({\n",
        "        'date': chunk.index.max(),\n",
        "        'beta': beta,\n",
        "        'ci_low': float(ci_low),\n",
        "        'ci_high': float(ci_high),\n",
        "    })\n",
        "\n",
        "roll = pd.DataFrame(rows).set_index('date')\n",
        "roll.head()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"coefficient-drift\"></a>\n",
        "## Coefficient drift\n",
        "\n",
        "### Goal\n",
        "Visualize coefficient stability over time.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Your Turn (1): Plot coefficient + CI over time\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# TODO: Plot roll['beta'] and a shaded CI band.\n",
        "...\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Your Turn (2): Summarize coefficient distribution\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# TODO: Compute summary stats for beta.\n",
        "# Identify periods where the sign changed.\n",
        "roll['beta'].describe()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"regime-interpretation\"></a>\n",
        "## Regime interpretation\n",
        "\n",
        "### Goal\n",
        "Compare coefficient drift to recession periods.\n",
        "\n",
        "This is not proof of causality.\n",
        "It is a structured way to ask: \"does the relationship change during recessions or different eras?\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Your Turn (1): Overlay recession shading (simple)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# TODO: Create a recession indicator aligned to roll index.\n",
        "# Hint: use df_m['recession'] reindexed to roll.index\n",
        "...\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Reflection\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- When does the sign or magnitude change?\n",
        "- What macro regimes might explain it?\n",
        "- If you were building a model, would you trust one fixed coefficient?\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"checkpoint-self-check\"></a>\n",
        "## Checkpoint (Self-Check)\n",
        "Run a few asserts and write 2-3 sentences summarizing what you verified.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# TODO: After you build X/y and split by time, validate the split.\n",
        "# Example (adjust variable names):\n",
        "# assert X_train.index.max() < X_test.index.min()\n",
        "# assert y_train.index.equals(X_train.index)\n",
        "# assert y_test.index.equals(X_test.index)\n",
        "# assert not X_train.isna().any().any()\n",
        "# assert not X_test.isna().any().any()\n",
        "...\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Extensions (Optional)\n",
        "- Try one additional variant beyond the main path (different features, different split, different model).\n",
        "- Write down what improved, what got worse, and your hypothesis for why.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Reflection\n",
        "- What did you assume implicitly (about timing, availability, stationarity, or costs)?\n",
        "- If you had to ship this model, what would you monitor?\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"solutions-reference\"></a>\n",
        "## Solutions (Reference)\n",
        "\n",
        "Try the TODOs first. Use these only to unblock yourself or to compare approaches.\n",
        "\n",
        "<details><summary>Solution: Rolling regression</summary>\n",
        "\n",
        "_One possible approach. Your variable names may differ; align them with the notebook._\n",
        "\n",
        "```python\n",
        "# Reference solution for 06_rolling_regressions_stability \u2014 Rolling regression\n",
        "import pandas as pd\n",
        "import statsmodels.api as sm\n",
        "\n",
        "df = pd.read_csv(SAMPLE_DIR / 'macro_quarterly_sample.csv', index_col=0, parse_dates=True).dropna()\n",
        "window = 12  # quarters\n",
        "betas = []\n",
        "dates = []\n",
        "for i in range(window, len(df)+1):\n",
        "    sub = df.iloc[i-window:i]\n",
        "    X = sm.add_constant(sub[['T10Y2Y']])\n",
        "    res = sm.OLS(sub['gdp_growth_qoq'], X).fit()\n",
        "    betas.append(res.params['T10Y2Y'])\n",
        "    dates.append(sub.index[-1])\n",
        "beta_series = pd.Series(betas, index=dates)\n",
        "beta_series.tail()\n",
        "```\n",
        "\n",
        "</details>\n",
        "\n",
        "<details><summary>Solution: Coefficient drift</summary>\n",
        "\n",
        "_One possible approach. Your variable names may differ; align them with the notebook._\n",
        "\n",
        "```python\n",
        "# Reference solution for 06_rolling_regressions_stability \u2014 Coefficient drift\n",
        "import matplotlib.pyplot as plt\n",
        "beta_series.plot(title='Rolling coefficient: GDP growth ~ yield spread')\n",
        "plt.show()\n",
        "```\n",
        "\n",
        "</details>\n",
        "\n",
        "<details><summary>Solution: Regime interpretation</summary>\n",
        "\n",
        "_One possible approach. Your variable names may differ; align them with the notebook._\n",
        "\n",
        "```python\n",
        "# Reference solution for 06_rolling_regressions_stability \u2014 Regime interpretation\n",
        "# Coefficient drift suggests relationships are not stable across eras.\n",
        "```\n",
        "\n",
        "</details>\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "python3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}