{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 03 Instrumental Variables (2SLS)\n",
        "\n",
        "Endogeneity, instruments, and two-stage least squares (2SLS).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Table of Contents\n",
        "- [Simulate endogeneity](#simulate-endogeneity)\n",
        "- [OLS vs 2SLS](#ols-vs-2sls)\n",
        "- [First-stage + weak IV checks](#first-stage-weak-iv-checks)\n",
        "- [Interpretation + limitations](#interpretation-limitations)\n",
        "- [Checkpoint (Self-Check)](#checkpoint-self-check)\n",
        "- [Solutions (Reference)](#solutions-reference)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Why This Notebook Matters\n",
        "Causal notebooks focus on **identification**: what would have to be true for a coefficient to represent a causal effect.\n",
        "You will practice:\n",
        "- building a county-year panel,\n",
        "- fixed effects (TWFE),\n",
        "- clustered standard errors,\n",
        "- DiD + event studies,\n",
        "- IV/2SLS.\n",
        "\n",
        "\n",
        "## What You Will Produce\n",
        "- (no file output; learning/analysis notebook)\n",
        "\n",
        "## Success Criteria\n",
        "- You can explain what you built and why each step exists.\n",
        "- You can run your work end-to-end without undefined variables.\n",
        "\n",
        "## Common Pitfalls\n",
        "- Running cells top-to-bottom without reading the instructions.\n",
        "- Leaving `...` placeholders in code cells.\n",
        "- Treating regression output as causal without stating identification assumptions.\n",
        "- Using non-clustered SE when shocks are correlated within groups (e.g., states).\n",
        "\n",
        "## Matching Guide\n",
        "- `docs/guides/07_causal/03_instrumental_variables_2sls.md`\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## How To Use This Notebook\n",
        "- This notebook is hands-on. Most code cells are incomplete on purpose.\n",
        "- Complete each TODO, then run the cell.\n",
        "- Use the matching guide (`docs/guides/07_causal/03_instrumental_variables_2sls.md`) for deep explanations and alternative examples.\n",
        "- Write short interpretation notes as you go (what changed, why it matters).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"environment-bootstrap\"></a>\n",
        "## Environment Bootstrap\n",
        "Run this cell first. It makes the repo importable and defines common directories.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "from pathlib import Path\n",
        "import sys\n",
        "\n",
        "\n",
        "def find_repo_root(start: Path) -> Path:\n",
        "    p = start\n",
        "    for _ in range(8):\n",
        "        if (p / 'src').exists() and (p / 'docs').exists():\n",
        "            return p\n",
        "        p = p.parent\n",
        "    raise RuntimeError('Could not find repo root. Start Jupyter from the repo root.')\n",
        "\n",
        "\n",
        "PROJECT_ROOT = find_repo_root(Path.cwd())\n",
        "if str(PROJECT_ROOT) not in sys.path:\n",
        "    sys.path.append(str(PROJECT_ROOT))\n",
        "\n",
        "DATA_DIR = PROJECT_ROOT / 'data'\n",
        "RAW_DIR = DATA_DIR / 'raw'\n",
        "PROCESSED_DIR = DATA_DIR / 'processed'\n",
        "SAMPLE_DIR = DATA_DIR / 'sample'\n",
        "\n",
        "PROJECT_ROOT\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Goal\n",
        "Practice IV/2SLS by simulating a classic endogeneity problem.\n",
        "\n",
        "We do this synthetically so you can see the bias and how IV can fix it under assumptions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Primer: Panel and IV regression with `linearmodels`\n",
        "\n",
        "`statsmodels` is great for OLS inference, but panel and IV workflows are often cleaner with `linearmodels`.\n",
        "\n",
        "This project uses `linearmodels` for:\n",
        "- **PanelOLS** (fixed effects / TWFE)\n",
        "- **IV2SLS** (instrumental variables)\n",
        "\n",
        "### Panel data shape\n",
        "Most panel estimators expect a **MultiIndex**:\n",
        "- level 0: entity (e.g., county `fips`)\n",
        "- level 1: time (e.g., `year`)\n",
        "\n",
        "In pandas:\n",
        "```python\n",
        "# df is a DataFrame with columns fips, year, y, x1, x2\n",
        "# df = df.set_index(['fips', 'year']).sort_index()\n",
        "```\n",
        "\n",
        "### Minimal PanelOLS (two-way fixed effects)\n",
        "```python\n",
        "from linearmodels.panel import PanelOLS\n",
        "\n",
        "# y: Series with MultiIndex\n",
        "# X: DataFrame with MultiIndex\n",
        "\n",
        "# model: y_it = beta'X_it + alpha_i + gamma_t + eps_it\n",
        "# res = PanelOLS(y, X, entity_effects=True, time_effects=True).fit(cov_type='robust')\n",
        "# print(res.summary)\n",
        "```\n",
        "\n",
        "### Clustered standard errors (common in applied work)\n",
        "If errors are correlated within clusters (e.g., state), use clustered SE:\n",
        "```python\n",
        "# clusters must align with y/X index (same rows)\n",
        "# res = PanelOLS(y, X, entity_effects=True, time_effects=True).fit(\n",
        "#     cov_type='clustered',\n",
        "#     clusters=df['state'],  # e.g., state-level clustering\n",
        "# )\n",
        "```\n",
        "\n",
        "### Minimal IV2SLS (one endogenous regressor)\n",
        "```python\n",
        "from linearmodels.iv import IV2SLS\n",
        "import statsmodels.api as sm\n",
        "\n",
        "# y: Series\n",
        "# endog: DataFrame with endogenous regressor(s)\n",
        "# exog: DataFrame with controls (include a constant)\n",
        "# instr: DataFrame with instruments\n",
        "\n",
        "# exog = sm.add_constant(exog, has_constant='add')\n",
        "# res = IV2SLS(y, exog, endog, instr).fit(cov_type='robust')\n",
        "# print(res.summary)\n",
        "```\n",
        "\n",
        "### Practical rule\n",
        "- If the goal is **causal identification**, always write down the assumptions first (parallel trends, exclusion restriction, etc.).\n",
        "- Then treat the model output as conditional on those assumptions, not as \u201ctruth\u201d.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"simulate-endogeneity\"></a>\n",
        "## Simulate endogeneity\n",
        "\n",
        "### Goal\n",
        "Create data where:\n",
        "- x is correlated with the error term (endogenous)\n",
        "- z shifts x but not y directly (instrument)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Your Turn: Simulate (y, x, z)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "rng = np.random.default_rng(0)\n",
        "n = 2000\n",
        "\n",
        "# Instrument\n",
        "z = rng.normal(size=n)\n",
        "\n",
        "# Hidden confounder\n",
        "u = rng.normal(size=n)\n",
        "\n",
        "# Endogenous regressor: depends on z and u\n",
        "x = 0.8*z + 0.8*u + rng.normal(size=n)\n",
        "\n",
        "# Error term correlated with u\n",
        "eps = 0.8*u + rng.normal(size=n)\n",
        "\n",
        "beta_true = 1.5\n",
        "y = beta_true * x + eps\n",
        "\n",
        "df = pd.DataFrame({'y': y, 'x': x, 'z': z})\n",
        "df.head()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"ols-vs-2sls\"></a>\n",
        "## OLS vs 2SLS\n",
        "\n",
        "### Goal\n",
        "Compare naive OLS (biased) to IV/2SLS.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Your Turn: Fit OLS and 2SLS\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import statsmodels.api as sm\n",
        "from src.causal import fit_iv_2sls\n",
        "\n",
        "# OLS\n",
        "ols = sm.OLS(df['y'], sm.add_constant(df[['x']], has_constant='add')).fit()\n",
        "print('OLS beta:', float(ols.params['x']))\n",
        "\n",
        "# 2SLS\n",
        "iv = fit_iv_2sls(df, y_col='y', x_endog='x', x_exog=[], z_cols=['z'])\n",
        "print('IV beta :', float(iv.params['x']))\n",
        "\n",
        "iv.summary\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"first-stage-weak-iv-checks\"></a>\n",
        "## First-stage + weak IV checks\n",
        "\n",
        "### Goal\n",
        "Inspect the first stage and discuss instrument strength.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Your Turn: Inspect first stage\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# TODO: Explore first-stage outputs.\n",
        "# Hint: `iv.first_stage` is usually informative.\n",
        "iv.first_stage\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"interpretation-limitations\"></a>\n",
        "## Interpretation + limitations\n",
        "\n",
        "Write 5-8 sentences on:\n",
        "- relevance and exclusion in this synthetic setup\n",
        "- what would break IV in real data\n",
        "- why IV identifies a local effect when effects are heterogeneous (LATE intuition)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"checkpoint-self-check\"></a>\n",
        "## Checkpoint (Self-Check)\n",
        "Run a few asserts and write 2-3 sentences summarizing what you verified.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Expected output: (see notebook front matter)\n",
        "# TODO: If you created a panel DataFrame, verify the indexing + core columns.\n",
        "# Example (adjust variable names):\n",
        "# assert isinstance(panel.index, pd.MultiIndex)\n",
        "# assert panel.index.names[:2] == ['fips', 'year']\n",
        "# assert panel['year'].astype(int).between(1900, 2100).all()\n",
        "# assert panel['fips'].astype(str).str.len().eq(5).all()\n",
        "#\n",
        "# TODO: Write 2-3 sentences:\n",
        "# - What is the identification assumption for your causal estimate?\n",
        "# - What diagnostic/falsification did you run?\n",
        "...\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Extensions (Optional)\n",
        "- Try one additional variant beyond the main path (different features, different split, different model).\n",
        "- Write down what improved, what got worse, and your hypothesis for why.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Reflection\n",
        "- What did you assume implicitly (about timing, availability, stationarity, or costs)?\n",
        "- If you had to ship this model, what would you monitor?\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"solutions-reference\"></a>\n",
        "## Solutions (Reference)\n",
        "\n",
        "Try the TODOs first. Use these only to unblock yourself or to compare approaches.\n",
        "\n",
        "<details><summary>Solution: Simulate endogeneity</summary>\n",
        "\n",
        "_One possible approach. Your variable names may differ; align them with the notebook._\n",
        "\n",
        "```python\n",
        "# Reference solution for 03_instrumental_variables_2sls \u2014 Simulate endogeneity\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "rng = np.random.default_rng(0)\n",
        "n = 2000\n",
        "z = rng.normal(size=n)          # instrument\n",
        "u = rng.normal(size=n)          # unobserved confounder\n",
        "\n",
        "x = 0.8*z + 0.8*u + rng.normal(size=n)  # endogenous regressor\n",
        "eps = 0.8*u + rng.normal(size=n)        # error correlated with x\n",
        "\n",
        "beta_true = 1.5\n",
        "y = beta_true * x + eps\n",
        "\n",
        "df = pd.DataFrame({'y': y, 'x': x, 'z': z})\n",
        "df.head()\n",
        "```\n",
        "\n",
        "</details>\n",
        "\n",
        "<details><summary>Solution: OLS vs 2SLS</summary>\n",
        "\n",
        "_One possible approach. Your variable names may differ; align them with the notebook._\n",
        "\n",
        "```python\n",
        "# Reference solution for 03_instrumental_variables_2sls \u2014 OLS vs 2SLS\n",
        "import statsmodels.api as sm\n",
        "from src.causal import fit_iv_2sls\n",
        "\n",
        "ols = sm.OLS(df['y'], sm.add_constant(df[['x']], has_constant='add')).fit()\n",
        "print('OLS beta:', float(ols.params['x']))\n",
        "\n",
        "iv = fit_iv_2sls(df, y_col='y', x_endog='x', x_exog=[], z_cols=['z'])\n",
        "print('IV beta :', float(iv.params['x']))\n",
        "```\n",
        "\n",
        "</details>\n",
        "\n",
        "<details><summary>Solution: First-stage + weak IV checks</summary>\n",
        "\n",
        "_One possible approach. Your variable names may differ; align them with the notebook._\n",
        "\n",
        "```python\n",
        "# Reference solution for 03_instrumental_variables_2sls \u2014 First-stage + weak IV checks\n",
        "# Inspect first stage output (instrument strength):\n",
        "# iv.first_stage\n",
        "```\n",
        "\n",
        "</details>\n",
        "\n",
        "<details><summary>Solution: Interpretation + limitations</summary>\n",
        "\n",
        "_One possible approach. Your variable names may differ; align them with the notebook._\n",
        "\n",
        "```python\n",
        "# Reference solution for 03_instrumental_variables_2sls \u2014 Interpretation + limitations\n",
        "# Write 3-5 sentences on:\n",
        "# - relevance + exclusion in your simulated setup\n",
        "# - why IV can fix endogeneity here\n",
        "```\n",
        "\n",
        "</details>\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "python3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}