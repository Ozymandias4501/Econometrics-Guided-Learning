{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0f1e1c0",
   "metadata": {},
   "source": [
    "# 02a Endogeneity: Sources and Consequences\n",
    "\n",
    "Why OLS can fail and how to recognize it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c2d3e4",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "- [What is endogeneity?](#what-is-endogeneity)\n",
    "- [Source 1: Omitted variable bias (OVB)](#source-1-omitted-variable-bias-ovb)\n",
    "- [Source 2: Measurement error](#source-2-measurement-error)\n",
    "- [Source 3: Simultaneity / reverse causality](#source-3-simultaneity-reverse-causality)\n",
    "- [What can we do about endogeneity?](#what-can-we-do-about-endogeneity)\n",
    "- [Checkpoint (Self-Check)](#checkpoint-self-check)\n",
    "- [Solutions (Reference)](#solutions-reference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d3e4f5",
   "metadata": {},
   "source": [
    "## Why This Notebook Matters\n",
    "Causal notebooks focus on **identification**: what would have to be true for a coefficient to represent a causal effect.\n",
    "Endogeneity is the single most important threat to causal inference in observational data.\n",
    "If you cannot recognize it, every regression you run risks producing misleading conclusions.\n",
    "\n",
    "You will practice:\n",
    "- defining endogeneity formally and connecting it to OLS bias,\n",
    "- simulating each of the three classical sources (OVB, measurement error, simultaneity),\n",
    "- observing *how* and *why* OLS fails in each case,\n",
    "- summarizing the remedies that lead into the IV/2SLS notebook next.\n",
    "\n",
    "\n",
    "## Prerequisites (Quick Self-Check)\n",
    "- Completed notebooks `01_panel_fixed_effects_clustered_se` and `02_difference_in_differences_event_study`.\n",
    "- Understanding of the OLS assumption $E[\\varepsilon \\mid X] = 0$ and why it matters.\n",
    "- Basic familiarity with `numpy` random number generation and `statsmodels` OLS.\n",
    "\n",
    "## What You Will Produce\n",
    "- (no file output; learning/analysis notebook)\n",
    "\n",
    "## Success Criteria\n",
    "- You can explain what you built and why each step exists.\n",
    "- You can run your work end-to-end without undefined variables.\n",
    "- You can identify which source of endogeneity is present in a given scenario.\n",
    "- You can predict the direction of bias from OVB and classical measurement error.\n",
    "\n",
    "## Common Pitfalls\n",
    "- Running cells top-to-bottom without reading the instructions.\n",
    "- Leaving `...` placeholders in code cells.\n",
    "- Treating regression output as causal without stating identification assumptions.\n",
    "- Confusing \"bias\" (systematic deviation) with \"noise\" (random variation).\n",
    "- Thinking that a large sample fixes endogeneity (it does not; endogeneity causes *inconsistency*).\n",
    "\n",
    "## Quick Fixes (When You Get Stuck)\n",
    "- If you see `ModuleNotFoundError`, re-run the bootstrap cell and restart the kernel; make sure `PROJECT_ROOT` is the repo root.\n",
    "- If a `data/processed/*` file is missing, either run the matching build script (see guide) or use the notebook's `data/sample/*` fallback.\n",
    "- If results look \"too good,\" suspect leakage; re-check shifts, rolling windows, and time splits.\n",
    "- If a model errors, check dtypes (`astype(float)`) and missingness (`dropna()` on required columns).\n",
    "\n",
    "## Matching Guide\n",
    "- `docs/guides/07_causal/02a_endogeneity_sources.md`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e4f5a6",
   "metadata": {},
   "source": [
    "## How To Use This Notebook\n",
    "- Work section-by-section; don't skip the markdown.\n",
    "- Most code cells are incomplete on purpose: replace TODOs and `...`, then run.\n",
    "- After each section, write 2--4 sentences answering the interpretation prompts (what changed, why it matters).\n",
    "- This notebook uses only synthetic/simulated data -- no external datasets needed.\n",
    "- Use the **Checkpoint (Self-Check)** section to catch mistakes early.\n",
    "- Use **Solutions (Reference)** only to unblock yourself; then re-implement without looking.\n",
    "- Use the matching guide (`docs/guides/07_causal/02a_endogeneity_sources.md`) for the math, assumptions, and deeper context."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f5a6b7",
   "metadata": {},
   "source": [
    "<a id=\"environment-bootstrap\"></a>\n",
    "## Environment Bootstrap\n",
    "Run this cell first. It makes the repo importable and defines common directories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a6b7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "\n",
    "def find_repo_root(start: Path) -> Path:\n",
    "    p = start\n",
    "    for _ in range(8):\n",
    "        if (p / 'src').exists() and (p / 'docs').exists():\n",
    "            return p\n",
    "        p = p.parent\n",
    "    raise RuntimeError('Could not find repo root. Start Jupyter from the repo root.')\n",
    "\n",
    "\n",
    "PROJECT_ROOT = find_repo_root(Path.cwd())\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.append(str(PROJECT_ROOT))\n",
    "\n",
    "DATA_DIR = PROJECT_ROOT / 'data'\n",
    "RAW_DIR = DATA_DIR / 'raw'\n",
    "PROCESSED_DIR = DATA_DIR / 'processed'\n",
    "SAMPLE_DIR = DATA_DIR / 'sample'\n",
    "\n",
    "PROJECT_ROOT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b7c8d9",
   "metadata": {},
   "source": [
    "## Goal\n",
    "Understand the three classical sources of endogeneity through simulation.\n",
    "\n",
    "By building the data-generating process (DGP) yourself, you control the true parameters.\n",
    "This lets you compare OLS estimates to the truth and *see* the bias directly.\n",
    "\n",
    "All data in this notebook is synthetic. No external datasets are required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c8d9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d9e0f1",
   "metadata": {},
   "source": [
    "<a id=\"what-is-endogeneity\"></a>\n",
    "## What is endogeneity?\n",
    "\n",
    "### Background\n",
    "The OLS estimator is the workhorse of empirical economics. It works beautifully -- **when its assumptions hold**.\n",
    "\n",
    "The critical assumption for causal interpretation is **strict exogeneity**:\n",
    "\n",
    "$$\n",
    "E[\\varepsilon \\mid X] = 0\n",
    "$$\n",
    "\n",
    "This says the error term is mean-independent of the regressors. When this holds, OLS is:\n",
    "- **Unbiased**: $E[\\hat{\\beta}] = \\beta$\n",
    "- **Consistent**: $\\hat{\\beta} \\xrightarrow{p} \\beta$ as $n \\to \\infty$\n",
    "\n",
    "**Endogeneity** is what we call it when this assumption fails: $E[\\varepsilon \\mid X] \\neq 0$.\n",
    "\n",
    "When endogeneity is present:\n",
    "- OLS is **biased** in finite samples.\n",
    "- OLS is **inconsistent** -- more data does not fix the problem.\n",
    "- The coefficient $\\hat{\\beta}$ **does not have a causal interpretation**.\n",
    "\n",
    "### The three classical sources\n",
    "\n",
    "| Source | Mechanism | Direction of bias |\n",
    "|--------|-----------|-------------------|\n",
    "| **Omitted variable bias** | A confounding variable affects both $X$ and $Y$ | Depends on signs of the omitted relationships |\n",
    "| **Measurement error** | $X$ is measured with noise ($X = X^* + \\nu$) | Attenuation: coefficient shrinks toward zero |\n",
    "| **Simultaneity** | $Y$ affects $X$ and $X$ affects $Y$ | Depends on the simultaneous system |\n",
    "\n",
    "### Interpretation prompts\n",
    "- In your own words, why does more data not fix endogeneity?\n",
    "- Can you think of a real-world example where $E[\\varepsilon \\mid X] \\neq 0$?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e0f1a2",
   "metadata": {},
   "source": [
    "### Warm-up: OLS works when exogeneity holds\n",
    "\n",
    "Before breaking OLS, let's confirm it works when the assumption holds.\n",
    "We simulate data where $X$ and $\\varepsilon$ are truly independent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f1a2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(42)\n",
    "n = 5000\n",
    "\n",
    "beta_true = 2.0\n",
    "alpha_true = 1.0\n",
    "\n",
    "# Exogenous X and independent error\n",
    "X_clean = rng.normal(loc=5, scale=2, size=n)\n",
    "eps_clean = rng.normal(loc=0, scale=1, size=n)\n",
    "Y_clean = alpha_true + beta_true * X_clean + eps_clean\n",
    "\n",
    "# TODO: Fit OLS and print the estimated coefficient on X.\n",
    "# Hint: sm.OLS(Y_clean, sm.add_constant(X_clean)).fit()\n",
    "res_clean = ...\n",
    "\n",
    "print(f'True beta:      {beta_true}')\n",
    "print(f'Estimated beta: {float(res_clean.params[1]):.4f}')\n",
    "print(f'Bias:           {float(res_clean.params[1]) - beta_true:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a2b3c4",
   "metadata": {},
   "source": [
    "<a id=\"source-1-omitted-variable-bias-ovb\"></a>\n",
    "## Source 1: Omitted variable bias (OVB)\n",
    "\n",
    "### Background\n",
    "OVB is the most common source of endogeneity in applied work.\n",
    "\n",
    "**Setup**: The true model is:\n",
    "$$\n",
    "Y_i = \\beta_0 + \\beta_1 X_i + \\gamma W_i + \\varepsilon_i\n",
    "$$\n",
    "\n",
    "where $W$ is an omitted variable (a confounder). If you run the **short regression** without $W$:\n",
    "$$\n",
    "Y_i = \\tilde{\\beta}_0 + \\tilde{\\beta}_1 X_i + \\tilde{\\varepsilon}_i\n",
    "$$\n",
    "\n",
    "then the OLS estimator $\\tilde{\\beta}_1$ converges to:\n",
    "$$\n",
    "\\tilde{\\beta}_1 \\xrightarrow{p} \\beta_1 + \\gamma \\cdot \\delta\n",
    "$$\n",
    "\n",
    "where $\\delta$ is the coefficient from regressing $W$ on $X$:\n",
    "$$\n",
    "W_i = \\delta_0 + \\delta X_i + \\nu_i\n",
    "$$\n",
    "\n",
    "### The OVB formula\n",
    "\n",
    "$$\n",
    "\\text{Bias} = \\gamma \\times \\delta\n",
    "$$\n",
    "\n",
    "- $\\gamma$: the effect of the omitted variable $W$ on $Y$ (holding $X$ constant).\n",
    "- $\\delta$: the relationship between $W$ and $X$.\n",
    "\n",
    "**Signing the bias** (the most useful skill in applied econometrics):\n",
    "\n",
    "| $\\gamma$ (W on Y) | $\\delta$ (W on X) | Bias direction |\n",
    "|---|---|---|\n",
    "| + | + | Positive (upward) |\n",
    "| + | - | Negative (downward) |\n",
    "| - | + | Negative (downward) |\n",
    "| - | - | Positive (upward) |\n",
    "\n",
    "### Classic example\n",
    "**Returns to education**: $Y$ = wage, $X$ = years of education, $W$ = ability (unobserved).\n",
    "- $\\gamma > 0$: ability raises wages.\n",
    "- $\\delta > 0$: more able people get more education.\n",
    "- Bias is **positive**: OLS overstates the return to education.\n",
    "\n",
    "### What you should see\n",
    "- The short regression (omitting $W$) gives a biased estimate of $\\beta_1$.\n",
    "- The long regression (including $W$) recovers the true $\\beta_1$.\n",
    "- The bias matches $\\gamma \\times \\delta$.\n",
    "\n",
    "### Interpretation prompts\n",
    "- Can you sign the OVB direction before running the simulation?\n",
    "- Why does adding more observations not fix this problem?\n",
    "\n",
    "### Goal\n",
    "Simulate OVB and verify the bias formula."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b3c4d5",
   "metadata": {},
   "source": [
    "### Your Turn: Simulate OVB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c4d5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(42)\n",
    "n = 5000\n",
    "\n",
    "# --- True DGP ---\n",
    "# Y = beta0 + beta1 * X + gamma * W + eps\n",
    "# W is correlated with X (confounding)\n",
    "\n",
    "beta0 = 1.0\n",
    "beta1 = 2.0   # true causal effect of X on Y\n",
    "gamma = 3.0   # effect of omitted variable W on Y\n",
    "\n",
    "# Generate X and the confounder W with correlation\n",
    "X = rng.normal(loc=5, scale=2, size=n)\n",
    "W = 0.5 * X + rng.normal(loc=0, scale=1, size=n)  # W depends on X (delta ~ 0.5)\n",
    "eps = rng.normal(loc=0, scale=1, size=n)\n",
    "\n",
    "Y = beta0 + beta1 * X + gamma * W + eps\n",
    "\n",
    "df_ovb = pd.DataFrame({'Y': Y, 'X': X, 'W': W})\n",
    "df_ovb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d5e6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Short regression (omitting W) ---\n",
    "# TODO: Fit OLS of Y on X only (with a constant).\n",
    "res_short = ...\n",
    "\n",
    "# --- Long regression (including W) ---\n",
    "# TODO: Fit OLS of Y on X and W (with a constant).\n",
    "res_long = ...\n",
    "\n",
    "print('=== Short regression (Y ~ X, omitting W) ===')\n",
    "print(f'  beta1_hat (short): {float(res_short.params[\"X\"]):.4f}')\n",
    "print(f'  True beta1:        {beta1}')\n",
    "print(f'  Bias:              {float(res_short.params[\"X\"]) - beta1:.4f}')\n",
    "print()\n",
    "print('=== Long regression (Y ~ X + W) ===')\n",
    "print(f'  beta1_hat (long):  {float(res_long.params[\"X\"]):.4f}')\n",
    "print(f'  True beta1:        {beta1}')\n",
    "print(f'  Bias:              {float(res_long.params[\"X\"]) - beta1:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e6f7a8",
   "metadata": {},
   "source": [
    "### Your Turn: Verify the OVB formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f7a8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 1: Estimate delta by regressing W on X ---\n",
    "# TODO: Fit OLS of W on X (with a constant) and extract delta.\n",
    "res_aux = ...\n",
    "delta_hat = ...  # Hint: float(res_aux.params['X'])\n",
    "\n",
    "# --- Step 2: Compute predicted bias ---\n",
    "# OVB formula: bias = gamma * delta\n",
    "# TODO: Compute predicted bias and compare to actual bias.\n",
    "predicted_bias = ...  # Hint: gamma * delta_hat\n",
    "actual_bias = float(res_short.params['X']) - beta1\n",
    "\n",
    "print(f'delta_hat (W ~ X):  {delta_hat:.4f}')\n",
    "print(f'gamma (true):       {gamma}')\n",
    "print(f'Predicted bias:     {predicted_bias:.4f}')\n",
    "print(f'Actual bias:        {actual_bias:.4f}')\n",
    "print(f'Match:              {abs(predicted_bias - actual_bias) < 0.01}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a8b9c0",
   "metadata": {},
   "source": [
    "### Your Turn: Visualize OVB across sample sizes\n",
    "\n",
    "Show that the bias persists even as $n$ grows (inconsistency)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b9c0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Loop over different sample sizes, fit the short regression each time,\n",
    "# and record the estimated beta1. Plot bias vs n.\n",
    "\n",
    "sample_sizes = [100, 500, 1000, 5000, 10000, 50000]\n",
    "biases = []\n",
    "\n",
    "for n_i in sample_sizes:\n",
    "    rng_i = np.random.default_rng(42)\n",
    "    X_i = rng_i.normal(loc=5, scale=2, size=n_i)\n",
    "    W_i = 0.5 * X_i + rng_i.normal(loc=0, scale=1, size=n_i)\n",
    "    eps_i = rng_i.normal(loc=0, scale=1, size=n_i)\n",
    "    Y_i = beta0 + beta1 * X_i + gamma * W_i + eps_i\n",
    "\n",
    "    # TODO: Fit the short regression (Y ~ X) and record the bias.\n",
    "    beta1_hat_i = ...  # Hint: fit OLS and extract the coefficient\n",
    "    biases.append(beta1_hat_i - beta1)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "ax.plot(sample_sizes, biases, 'o-', markersize=8)\n",
    "ax.axhline(gamma * 0.5, color='red', linestyle='--', label=f'Predicted bias = {gamma * 0.5:.2f}')\n",
    "ax.set_xlabel('Sample size (n)')\n",
    "ax.set_ylabel('Bias (beta1_hat - beta1_true)')\n",
    "ax.set_title('OVB does not vanish with more data (inconsistency)')\n",
    "ax.set_xscale('log')\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c0d1e2",
   "metadata": {},
   "source": [
    "### Interpretation prompt\n",
    "\n",
    "Write 2--4 sentences:\n",
    "- Does the bias shrink as the sample grows? Why or why not?\n",
    "- In the education-wage example, what would $W$ be, and which direction would OVB push the estimated return to education?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d1e2f3",
   "metadata": {},
   "source": [
    "<a id=\"source-2-measurement-error\"></a>\n",
    "## Source 2: Measurement error\n",
    "\n",
    "### Background\n",
    "In practice, we often cannot measure the true variable $X^*$ perfectly. Instead, we observe:\n",
    "$$\n",
    "X_i = X_i^* + \\nu_i, \\quad \\nu_i \\sim (0, \\sigma_\\nu^2), \\quad \\nu_i \\perp X_i^*, \\varepsilon_i\n",
    "$$\n",
    "\n",
    "This is called **classical errors-in-variables** (CEV).\n",
    "\n",
    "The true model is:\n",
    "$$\n",
    "Y_i = \\beta_0 + \\beta_1 X_i^* + \\varepsilon_i\n",
    "$$\n",
    "\n",
    "But we estimate:\n",
    "$$\n",
    "Y_i = \\beta_0 + \\beta_1 X_i + \\tilde{\\varepsilon}_i\n",
    "$$\n",
    "\n",
    "Since $X_i = X_i^* + \\nu_i$, the new error $\\tilde{\\varepsilon}_i = \\varepsilon_i - \\beta_1 \\nu_i$ is correlated with $X_i$ (through $\\nu_i$). This is endogeneity.\n",
    "\n",
    "### Attenuation bias\n",
    "\n",
    "The OLS estimator converges to:\n",
    "$$\n",
    "\\hat{\\beta}_1 \\xrightarrow{p} \\beta_1 \\cdot \\frac{\\sigma_{X^*}^2}{\\sigma_{X^*}^2 + \\sigma_\\nu^2}\n",
    "$$\n",
    "\n",
    "The fraction $\\frac{\\sigma_{X^*}^2}{\\sigma_{X^*}^2 + \\sigma_\\nu^2}$ is always between 0 and 1, so:\n",
    "- The coefficient is **attenuated** (shrunk toward zero).\n",
    "- More noise ($\\sigma_\\nu^2$ larger) means more attenuation.\n",
    "- This is called **attenuation bias**.\n",
    "\n",
    "### What you should see\n",
    "- As measurement noise increases, the OLS coefficient on $X$ shrinks toward zero.\n",
    "- The attenuation matches the formula above.\n",
    "\n",
    "### Interpretation prompts\n",
    "- Why does measurement error in $X$ bias the coefficient *toward zero* rather than in a random direction?\n",
    "- If you have noisy data and find a \"small\" effect, should you conclude the true effect is small?\n",
    "\n",
    "### Goal\n",
    "Simulate classical measurement error and show attenuation bias."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e2f3a4",
   "metadata": {},
   "source": [
    "### Your Turn: Simulate measurement error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f3a4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(42)\n",
    "n = 5000\n",
    "\n",
    "beta0_me = 1.0\n",
    "beta1_me = 3.0  # true effect\n",
    "\n",
    "# True X* (unobserved in practice)\n",
    "X_star = rng.normal(loc=5, scale=2, size=n)\n",
    "eps_me = rng.normal(loc=0, scale=1, size=n)\n",
    "\n",
    "# True relationship\n",
    "Y_me = beta0_me + beta1_me * X_star + eps_me\n",
    "\n",
    "# Measurement noise of different magnitudes\n",
    "noise_levels = [0.0, 0.5, 1.0, 2.0, 4.0]\n",
    "\n",
    "print(f'{\"Noise SD\":>10s}  {\"beta1_hat\":>10s}  {\"Attenuation\":>12s}  {\"Predicted\":>10s}')\n",
    "print('-' * 50)\n",
    "\n",
    "for sigma_nu in noise_levels:\n",
    "    # Measured X = X* + noise\n",
    "    nu = rng.normal(loc=0, scale=sigma_nu, size=n) if sigma_nu > 0 else np.zeros(n)\n",
    "    X_measured = X_star + nu\n",
    "\n",
    "    # TODO: Fit OLS of Y_me on X_measured (with constant) and extract beta1_hat.\n",
    "    beta1_hat = ...  # Hint: fit OLS and extract coefficient\n",
    "\n",
    "    # Predicted attenuation factor: var(X*) / (var(X*) + sigma_nu^2)\n",
    "    var_x_star = np.var(X_star)\n",
    "    # TODO: Compute predicted coefficient.\n",
    "    predicted = ...  # Hint: beta1_me * var_x_star / (var_x_star + sigma_nu**2)\n",
    "\n",
    "    print(f'{sigma_nu:10.1f}  {beta1_hat:10.4f}  {beta1_hat / beta1_me:12.4f}  {predicted:10.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a4b5c6",
   "metadata": {},
   "source": [
    "### Your Turn: Visualize attenuation bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b5c6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Plot the estimated coefficient vs noise level.\n",
    "# Include the theoretical attenuation curve for comparison.\n",
    "\n",
    "sigma_grid = np.linspace(0, 5, 50)\n",
    "var_x_star = np.var(X_star)\n",
    "\n",
    "# Theoretical curve\n",
    "theoretical = ...  # Hint: beta1_me * var_x_star / (var_x_star + sigma_grid**2)\n",
    "\n",
    "# Simulated points\n",
    "sim_betas = []\n",
    "for sigma_nu in sigma_grid:\n",
    "    nu_i = rng.normal(loc=0, scale=sigma_nu, size=n) if sigma_nu > 0 else np.zeros(n)\n",
    "    X_m_i = X_star + nu_i\n",
    "    res_i = sm.OLS(Y_me, sm.add_constant(X_m_i)).fit()\n",
    "    sim_betas.append(float(res_i.params[1]))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "ax.plot(sigma_grid, theoretical, 'r-', linewidth=2, label='Theoretical attenuation')\n",
    "ax.plot(sigma_grid, sim_betas, 'b.', alpha=0.5, label='Simulated OLS estimates')\n",
    "ax.axhline(beta1_me, color='green', linestyle='--', label=f'True beta = {beta1_me}')\n",
    "ax.set_xlabel('Measurement noise SD (sigma_nu)')\n",
    "ax.set_ylabel('Estimated beta1')\n",
    "ax.set_title('Classical Measurement Error: Attenuation Bias')\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c6d7e8",
   "metadata": {},
   "source": [
    "### Interpretation prompt\n",
    "\n",
    "Write 2--4 sentences:\n",
    "- Does the attenuation formula match the simulation?\n",
    "- In what applied settings is measurement error likely to be a serious concern?\n",
    "- Why is attenuation bias especially dangerous when the true effect is modest?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d7e8f9",
   "metadata": {},
   "source": [
    "<a id=\"source-3-simultaneity-reverse-causality\"></a>\n",
    "## Source 3: Simultaneity / reverse causality\n",
    "\n",
    "### Background\n",
    "Simultaneity arises when $Y$ affects $X$ and $X$ affects $Y$ at the same time. This creates a system of simultaneous equations:\n",
    "\n",
    "**Supply and demand example**:\n",
    "- Demand: $Q = \\alpha_d - \\beta_d P + \\varepsilon_d$  (higher price, less demand)\n",
    "- Supply: $Q = \\alpha_s + \\beta_s P + \\varepsilon_s$  (higher price, more supply)\n",
    "\n",
    "We observe the equilibrium $(P^*, Q^*)$ where supply equals demand. Regressing $Q$ on $P$ does not recover either the demand or supply curve -- it gives a confounded mix of both.\n",
    "\n",
    "**Other examples**:\n",
    "- Crime and police: more crime leads to more police, but more police may deter crime.\n",
    "- Exports and GDP: exports increase GDP, but higher GDP countries produce more to export.\n",
    "- Advertising and sales: ads boost sales, but firms with high sales spend more on ads.\n",
    "\n",
    "### Why OLS fails\n",
    "In the supply/demand system, the equilibrium price $P^*$ depends on *both* $\\varepsilon_d$ and $\\varepsilon_s$.\n",
    "So $P$ is correlated with the demand error and the supply error simultaneously.\n",
    "OLS on either equation alone is inconsistent.\n",
    "\n",
    "### What you should see\n",
    "- A naive OLS regression of $Q$ on $P$ gives a coefficient that is neither the demand slope nor the supply slope.\n",
    "- The estimate is a confounded mixture of both structural parameters.\n",
    "\n",
    "### Interpretation prompts\n",
    "- Why can't you just regress $Q$ on $P$ to get the demand curve?\n",
    "- What would you need (conceptually) to identify the demand curve separately from the supply curve?\n",
    "\n",
    "### Goal\n",
    "Simulate a simple simultaneous system and show OLS gives wrong answers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e8f9a0",
   "metadata": {},
   "source": [
    "### Your Turn: Simulate a supply-demand system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f9a0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(42)\n",
    "n = 5000\n",
    "\n",
    "# --- Structural parameters ---\n",
    "# Demand: Q = alpha_d - beta_d * P + eps_d\n",
    "# Supply: Q = alpha_s + beta_s * P + eps_s\n",
    "alpha_d = 10.0\n",
    "beta_d = 2.0    # demand slope (positive; enters as -beta_d)\n",
    "alpha_s = 2.0\n",
    "beta_s = 1.0    # supply slope (positive)\n",
    "\n",
    "eps_d = rng.normal(loc=0, scale=1, size=n)  # demand shocks\n",
    "eps_s = rng.normal(loc=0, scale=1, size=n)  # supply shocks\n",
    "\n",
    "# --- Solve for equilibrium ---\n",
    "# At equilibrium: alpha_d - beta_d * P + eps_d = alpha_s + beta_s * P + eps_s\n",
    "# => P* = (alpha_d - alpha_s + eps_d - eps_s) / (beta_d + beta_s)\n",
    "# => Q* = substitute P* into either equation\n",
    "\n",
    "# TODO: Solve for equilibrium price and quantity.\n",
    "P_star = ...  # Hint: (alpha_d - alpha_s + eps_d - eps_s) / (beta_d + beta_s)\n",
    "Q_star = ...  # Hint: substitute P_star into the demand equation\n",
    "\n",
    "df_sim = pd.DataFrame({'P': P_star, 'Q': Q_star})\n",
    "print(f'Mean equilibrium price:    {P_star.mean():.2f}')\n",
    "print(f'Mean equilibrium quantity: {Q_star.mean():.2f}')\n",
    "df_sim.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a0b1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Naive OLS: regress Q on P ---\n",
    "# TODO: Fit OLS of Q on P (with constant) and extract the coefficient on P.\n",
    "res_naive = ...\n",
    "\n",
    "print('=== Naive OLS: Q ~ P ===')\n",
    "print(f'  Estimated slope:      {float(res_naive.params[\"P\"]):.4f}')\n",
    "print(f'  True demand slope:   {-beta_d:.4f} (negative: higher P -> lower Q demanded)')\n",
    "print(f'  True supply slope:   {+beta_s:.4f} (positive: higher P -> higher Q supplied)')\n",
    "print()\n",
    "print('The OLS estimate is neither the demand nor supply slope.')\n",
    "print('It is a confounded mixture of both structural relationships.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0b1c2d3",
   "metadata": {},
   "source": [
    "### Your Turn: Visualize the identification problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c2d3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create a scatter plot of Q vs P with the OLS line,\n",
    "# the true demand curve (evaluated at mean shocks), and\n",
    "# the true supply curve (evaluated at mean shocks).\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "# Scatter of equilibrium observations\n",
    "ax.scatter(P_star, Q_star, alpha=0.1, s=5, label='Observed equilibria')\n",
    "\n",
    "# OLS fitted line\n",
    "p_grid = np.linspace(P_star.min(), P_star.max(), 100)\n",
    "q_ols = ...  # TODO: Hint: res_naive.params['const'] + res_naive.params['P'] * p_grid\n",
    "\n",
    "# True demand curve (at eps_d = 0)\n",
    "q_demand = ...  # TODO: Hint: alpha_d - beta_d * p_grid\n",
    "\n",
    "# True supply curve (at eps_s = 0)\n",
    "q_supply = ...  # TODO: Hint: alpha_s + beta_s * p_grid\n",
    "\n",
    "ax.plot(p_grid, q_ols, 'r-', linewidth=2, label='OLS fit (confounded)')\n",
    "ax.plot(p_grid, q_demand, 'b--', linewidth=2, label=f'True demand (slope = {-beta_d})')\n",
    "ax.plot(p_grid, q_supply, 'g--', linewidth=2, label=f'True supply (slope = +{beta_s})')\n",
    "\n",
    "ax.set_xlabel('Price (P)')\n",
    "ax.set_ylabel('Quantity (Q)')\n",
    "ax.set_title('Simultaneity Bias: OLS Cannot Recover Structural Curves')\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d3e4f6",
   "metadata": {},
   "source": [
    "### Your Turn: Show the OLS slope depends on variance of shocks\n",
    "\n",
    "When demand shocks dominate ($\\sigma_d \\gg \\sigma_s$), the observed variation traces out\n",
    "the supply curve. When supply shocks dominate, it traces out the demand curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e4f5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Vary the ratio of demand-shock variance to supply-shock variance.\n",
    "# Show how the OLS coefficient shifts between the supply and demand slopes.\n",
    "\n",
    "ratios = [0.01, 0.1, 0.5, 1.0, 2.0, 10.0, 100.0]  # sigma_d / sigma_s\n",
    "ols_slopes = []\n",
    "\n",
    "for ratio in ratios:\n",
    "    sigma_d = ratio\n",
    "    sigma_s = 1.0\n",
    "    ed = rng.normal(0, sigma_d, n)\n",
    "    es = rng.normal(0, sigma_s, n)\n",
    "    P_eq = (alpha_d - alpha_s + ed - es) / (beta_d + beta_s)\n",
    "    Q_eq = alpha_d - beta_d * P_eq + ed\n",
    "\n",
    "    # TODO: Fit OLS of Q_eq on P_eq and record the slope.\n",
    "    slope_i = ...  # Hint: fit OLS and extract coefficient\n",
    "    ols_slopes.append(slope_i)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "ax.semilogx(ratios, ols_slopes, 'o-', markersize=8, label='OLS slope')\n",
    "ax.axhline(-beta_d, color='blue', linestyle='--', label=f'True demand slope ({-beta_d})')\n",
    "ax.axhline(beta_s, color='green', linestyle='--', label=f'True supply slope (+{beta_s})')\n",
    "ax.set_xlabel('Ratio sigma_d / sigma_s')\n",
    "ax.set_ylabel('OLS coefficient (Q ~ P)')\n",
    "ax.set_title('OLS slope varies with relative shock variance')\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f5a6b8",
   "metadata": {},
   "source": [
    "### Interpretation prompt\n",
    "\n",
    "Write 2--4 sentences:\n",
    "- When demand shocks are large, which structural curve does OLS approximate? Why?\n",
    "- Why is IV/2SLS the standard solution for simultaneity? (Preview for the next notebook.)\n",
    "- Name a real-world setting with simultaneity that you have encountered."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a6b7c9",
   "metadata": {},
   "source": [
    "<a id=\"what-can-we-do-about-endogeneity\"></a>\n",
    "## What can we do about endogeneity?\n",
    "\n",
    "### Summary\n",
    "\n",
    "You have now seen three sources of endogeneity. Each has a different mechanism, but they all violate $E[\\varepsilon \\mid X] = 0$ and render OLS biased and inconsistent.\n",
    "\n",
    "The good news: econometrics has developed targeted remedies for each source.\n",
    "\n",
    "| Source | Mechanism | Remedies |\n",
    "|--------|-----------|----------|\n",
    "| **Omitted variable bias** | Confounding variable correlated with both $X$ and $Y$ | (1) Add controls if the omitted variable is observable; (2) Panel fixed effects (absorb time-invariant confounders); (3) Instrumental variables |\n",
    "| **Measurement error** | Noisy measurement of $X$ attenuates the coefficient | (1) Instrumental variables (use an instrument correlated with $X^*$ but not the noise); (2) Better measurement (reduce $\\sigma_\\nu^2$) |\n",
    "| **Simultaneity** | $Y$ affects $X$ and $X$ affects $Y$ | (1) IV/2SLS (find a variable that shifts one equation but not the other); (2) Natural experiments; (3) Structural models |\n",
    "\n",
    "### The common thread: Instrumental Variables\n",
    "\n",
    "Notice that IV appears as a remedy for **all three** sources. This is why IV/2SLS is the most important single tool in the causal inference toolkit.\n",
    "\n",
    "An instrument $Z$ must satisfy:\n",
    "1. **Relevance**: $\\mathrm{Cov}(Z, X) \\neq 0$ (the instrument affects the endogenous regressor).\n",
    "2. **Exclusion**: $\\mathrm{Cov}(Z, \\varepsilon) = 0$ (the instrument affects $Y$ *only* through $X$).\n",
    "\n",
    "**This leads directly to the next notebook**: `03_instrumental_variables_2sls`, where you will implement IV/2SLS, check instrument strength, and compare IV estimates to the biased OLS estimates you have seen here.\n",
    "\n",
    "### Decision tree (practical)\n",
    "\n",
    "```\n",
    "Is your regressor X plausibly exogenous?\n",
    "  |\n",
    "  +-- YES: OLS is fine. Report robust SE. Done.\n",
    "  |\n",
    "  +-- NO: What is the source?\n",
    "       |\n",
    "       +-- OVB: Can you observe the omitted variable?\n",
    "       |     +-- YES: Add it as a control.\n",
    "       |     +-- NO: Use panel FE (if time-invariant) or IV.\n",
    "       |\n",
    "       +-- Measurement error: Can you get better data?\n",
    "       |     +-- YES: Use it.\n",
    "       |     +-- NO: Use IV.\n",
    "       |\n",
    "       +-- Simultaneity: Do you have a valid instrument?\n",
    "             +-- YES: Use IV/2SLS.\n",
    "             +-- NO: Consider natural experiments, RDD, DiD.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b7c8da",
   "metadata": {},
   "source": [
    "### Your Turn: Classify endogeneity scenarios\n",
    "\n",
    "For each scenario below, identify the most likely source of endogeneity and the recommended remedy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c8d9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: For each scenario, fill in the source and remedy.\n",
    "# Replace the '...' with your answers.\n",
    "\n",
    "scenarios = pd.DataFrame({\n",
    "    'scenario': [\n",
    "        'Regressing wages on education (ability is unobserved)',\n",
    "        'Regressing health outcomes on self-reported exercise (noisy measure)',\n",
    "        'Regressing city crime rates on police spending',\n",
    "        'Regressing firm profits on R&D spending (innovative firms do both)',\n",
    "        'Regressing test scores on class size (using survey-reported class size)',\n",
    "    ],\n",
    "    'source': [\n",
    "        ...,  # TODO: 'OVB', 'measurement error', or 'simultaneity'\n",
    "        ...,\n",
    "        ...,\n",
    "        ...,\n",
    "        ...,\n",
    "    ],\n",
    "    'remedy': [\n",
    "        ...,  # TODO: brief description of the recommended approach\n",
    "        ...,\n",
    "        ...,\n",
    "        ...,\n",
    "        ...,\n",
    "    ],\n",
    "})\n",
    "\n",
    "scenarios"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d9e0f2",
   "metadata": {},
   "source": [
    "<a id=\"checkpoint-self-check\"></a>\n",
    "## Checkpoint (Self-Check)\n",
    "Run a few asserts and write 2--3 sentences summarizing what you verified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e0f1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Self-check asserts ---\n",
    "\n",
    "# OVB: short regression should overestimate beta1\n",
    "# (because gamma > 0 and delta > 0, so bias is positive)\n",
    "assert float(res_short.params['X']) > beta1, \\\n",
    "    'Short regression should overestimate beta1 (positive OVB)'\n",
    "\n",
    "# OVB: long regression should be close to true beta1\n",
    "assert abs(float(res_long.params['X']) - beta1) < 0.2, \\\n",
    "    'Long regression should recover beta1 (close to 2.0)'\n",
    "\n",
    "# OVB formula should match\n",
    "assert abs(predicted_bias - actual_bias) < 0.05, \\\n",
    "    'OVB formula (gamma * delta) should match actual bias'\n",
    "\n",
    "# Simultaneity: OLS slope should not match either structural slope\n",
    "ols_sim_slope = float(res_naive.params['P'])\n",
    "assert abs(ols_sim_slope - (-beta_d)) > 0.3, \\\n",
    "    'OLS should not recover the demand slope'\n",
    "assert abs(ols_sim_slope - beta_s) > 0.3, \\\n",
    "    'OLS should not recover the supply slope'\n",
    "\n",
    "print('All checkpoint asserts passed.')\n",
    "\n",
    "# TODO: Write 2-3 sentences:\n",
    "# - Which source of endogeneity produces the most predictable bias direction?\n",
    "# - What is the common remedy across all three sources?\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f1a2b4",
   "metadata": {},
   "source": [
    "## Extensions (Optional)\n",
    "- Try one additional variant beyond the main path (different DGP parameters, different noise structure).\n",
    "- Write down what improved, what got worse, and your hypothesis for why.\n",
    "\n",
    "Suggestions:\n",
    "- **OVB with multiple omitted variables**: Add a second confounder $W_2$ that is negatively correlated with $X$. Does the total bias increase or decrease?\n",
    "- **Non-classical measurement error**: Try multiplicative noise ($X = X^* \\cdot \\nu$ where $\\nu > 0$). Does attenuation bias still hold?\n",
    "- **Simultaneity with an instrument**: Add an instrument to the supply/demand system (e.g., a weather shock that shifts supply). Show that IV recovers the demand slope. (This is a preview of notebook 03.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a2b3c5",
   "metadata": {},
   "source": [
    "## Reflection\n",
    "- What did you assume implicitly (about timing, availability, stationarity, or costs)?\n",
    "- If you had to ship this model, what would you monitor?\n",
    "- In your own applied work, which source of endogeneity do you think is most likely to arise?\n",
    "- How does the OVB formula help you reason about the *direction* of bias even when you cannot observe the confounder?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b3c4d6",
   "metadata": {},
   "source": [
    "<a id=\"solutions-reference\"></a>\n",
    "## Solutions (Reference)\n",
    "\n",
    "Try the TODOs first. Use these only to unblock yourself or to compare approaches.\n",
    "\n",
    "<details><summary>Solution: OLS when exogeneity holds</summary>\n",
    "\n",
    "_One possible approach. Your variable names may differ; align them with the notebook._\n",
    "\n",
    "```python\n",
    "# Reference solution for 02a -- OLS when exogeneity holds\n",
    "res_clean = sm.OLS(Y_clean, sm.add_constant(X_clean)).fit()\n",
    "\n",
    "print(f'True beta:      {beta_true}')\n",
    "print(f'Estimated beta: {float(res_clean.params[1]):.4f}')\n",
    "print(f'Bias:           {float(res_clean.params[1]) - beta_true:.4f}')\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "<details><summary>Solution: Simulate OVB (short and long regressions)</summary>\n",
    "\n",
    "_One possible approach. Your variable names may differ; align them with the notebook._\n",
    "\n",
    "```python\n",
    "# Reference solution for 02a -- OVB short and long regressions\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Short regression (omitting W)\n",
    "res_short = sm.OLS(\n",
    "    df_ovb['Y'],\n",
    "    sm.add_constant(df_ovb[['X']], has_constant='add'),\n",
    ").fit()\n",
    "\n",
    "# Long regression (including W)\n",
    "res_long = sm.OLS(\n",
    "    df_ovb['Y'],\n",
    "    sm.add_constant(df_ovb[['X', 'W']], has_constant='add'),\n",
    ").fit()\n",
    "\n",
    "print('Short regression beta1:', float(res_short.params['X']))\n",
    "print('Long regression beta1: ', float(res_long.params['X']))\n",
    "print('True beta1:            ', beta1)\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "<details><summary>Solution: Verify the OVB formula</summary>\n",
    "\n",
    "_One possible approach. Your variable names may differ; align them with the notebook._\n",
    "\n",
    "```python\n",
    "# Reference solution for 02a -- OVB formula verification\n",
    "# Step 1: Estimate delta by regressing W on X\n",
    "res_aux = sm.OLS(\n",
    "    df_ovb['W'],\n",
    "    sm.add_constant(df_ovb[['X']], has_constant='add'),\n",
    ").fit()\n",
    "delta_hat = float(res_aux.params['X'])\n",
    "\n",
    "# Step 2: Compute predicted bias\n",
    "predicted_bias = gamma * delta_hat\n",
    "actual_bias = float(res_short.params['X']) - beta1\n",
    "\n",
    "print(f'delta_hat:       {delta_hat:.4f}')\n",
    "print(f'Predicted bias:  {predicted_bias:.4f}')\n",
    "print(f'Actual bias:     {actual_bias:.4f}')\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "<details><summary>Solution: OVB across sample sizes</summary>\n",
    "\n",
    "_One possible approach. Your variable names may differ; align them with the notebook._\n",
    "\n",
    "```python\n",
    "# Reference solution for 02a -- OVB across sample sizes\n",
    "sample_sizes = [100, 500, 1000, 5000, 10000, 50000]\n",
    "biases = []\n",
    "\n",
    "for n_i in sample_sizes:\n",
    "    rng_i = np.random.default_rng(42)\n",
    "    X_i = rng_i.normal(loc=5, scale=2, size=n_i)\n",
    "    W_i = 0.5 * X_i + rng_i.normal(loc=0, scale=1, size=n_i)\n",
    "    eps_i = rng_i.normal(loc=0, scale=1, size=n_i)\n",
    "    Y_i = beta0 + beta1 * X_i + gamma * W_i + eps_i\n",
    "\n",
    "    res_i = sm.OLS(Y_i, sm.add_constant(X_i)).fit()\n",
    "    beta1_hat_i = float(res_i.params[1])\n",
    "    biases.append(beta1_hat_i - beta1)\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "<details><summary>Solution: Simulate measurement error</summary>\n",
    "\n",
    "_One possible approach. Your variable names may differ; align them with the notebook._\n",
    "\n",
    "```python\n",
    "# Reference solution for 02a -- Measurement error\n",
    "for sigma_nu in noise_levels:\n",
    "    nu = rng.normal(loc=0, scale=sigma_nu, size=n) if sigma_nu > 0 else np.zeros(n)\n",
    "    X_measured = X_star + nu\n",
    "\n",
    "    res_me_i = sm.OLS(Y_me, sm.add_constant(X_measured)).fit()\n",
    "    beta1_hat = float(res_me_i.params[1])\n",
    "\n",
    "    var_x_star = np.var(X_star)\n",
    "    predicted = beta1_me * var_x_star / (var_x_star + sigma_nu**2)\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "<details><summary>Solution: Visualize attenuation bias</summary>\n",
    "\n",
    "_One possible approach. Your variable names may differ; align them with the notebook._\n",
    "\n",
    "```python\n",
    "# Reference solution for 02a -- Attenuation bias visualization\n",
    "sigma_grid = np.linspace(0, 5, 50)\n",
    "var_x_star = np.var(X_star)\n",
    "\n",
    "theoretical = beta1_me * var_x_star / (var_x_star + sigma_grid**2)\n",
    "\n",
    "sim_betas = []\n",
    "for sigma_nu in sigma_grid:\n",
    "    nu_i = rng.normal(loc=0, scale=sigma_nu, size=n) if sigma_nu > 0 else np.zeros(n)\n",
    "    X_m_i = X_star + nu_i\n",
    "    res_i = sm.OLS(Y_me, sm.add_constant(X_m_i)).fit()\n",
    "    sim_betas.append(float(res_i.params[1]))\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "<details><summary>Solution: Simulate supply-demand system</summary>\n",
    "\n",
    "_One possible approach. Your variable names may differ; align them with the notebook._\n",
    "\n",
    "```python\n",
    "# Reference solution for 02a -- Supply-demand simultaneity\n",
    "P_star = (alpha_d - alpha_s + eps_d - eps_s) / (beta_d + beta_s)\n",
    "Q_star = alpha_d - beta_d * P_star + eps_d\n",
    "\n",
    "# Naive OLS\n",
    "res_naive = sm.OLS(\n",
    "    df_sim['Q'],\n",
    "    sm.add_constant(df_sim[['P']], has_constant='add'),\n",
    ").fit()\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "<details><summary>Solution: Visualize simultaneity</summary>\n",
    "\n",
    "_One possible approach. Your variable names may differ; align them with the notebook._\n",
    "\n",
    "```python\n",
    "# Reference solution for 02a -- Simultaneity visualization\n",
    "p_grid = np.linspace(P_star.min(), P_star.max(), 100)\n",
    "\n",
    "q_ols = float(res_naive.params['const']) + float(res_naive.params['P']) * p_grid\n",
    "q_demand = alpha_d - beta_d * p_grid\n",
    "q_supply = alpha_s + beta_s * p_grid\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "ax.scatter(P_star, Q_star, alpha=0.1, s=5, label='Observed equilibria')\n",
    "ax.plot(p_grid, q_ols, 'r-', linewidth=2, label='OLS fit (confounded)')\n",
    "ax.plot(p_grid, q_demand, 'b--', linewidth=2, label=f'True demand (slope = {-beta_d})')\n",
    "ax.plot(p_grid, q_supply, 'g--', linewidth=2, label=f'True supply (slope = +{beta_s})')\n",
    "ax.set_xlabel('Price (P)')\n",
    "ax.set_ylabel('Quantity (Q)')\n",
    "ax.set_title('Simultaneity Bias: OLS Cannot Recover Structural Curves')\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "<details><summary>Solution: OLS slope depends on variance of shocks</summary>\n",
    "\n",
    "_One possible approach. Your variable names may differ; align them with the notebook._\n",
    "\n",
    "```python\n",
    "# Reference solution for 02a -- Simultaneity shock variance\n",
    "ratios = [0.01, 0.1, 0.5, 1.0, 2.0, 10.0, 100.0]\n",
    "ols_slopes = []\n",
    "\n",
    "for ratio in ratios:\n",
    "    sigma_d = ratio\n",
    "    sigma_s = 1.0\n",
    "    ed = rng.normal(0, sigma_d, n)\n",
    "    es = rng.normal(0, sigma_s, n)\n",
    "    P_eq = (alpha_d - alpha_s + ed - es) / (beta_d + beta_s)\n",
    "    Q_eq = alpha_d - beta_d * P_eq + ed\n",
    "\n",
    "    res_i = sm.OLS(Q_eq, sm.add_constant(P_eq)).fit()\n",
    "    slope_i = float(res_i.params[1])\n",
    "    ols_slopes.append(slope_i)\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "<details><summary>Solution: Classify endogeneity scenarios</summary>\n",
    "\n",
    "_One possible approach._\n",
    "\n",
    "```python\n",
    "# Reference solution for 02a -- Classify scenarios\n",
    "scenarios = pd.DataFrame({\n",
    "    'scenario': [\n",
    "        'Regressing wages on education (ability is unobserved)',\n",
    "        'Regressing health outcomes on self-reported exercise (noisy measure)',\n",
    "        'Regressing city crime rates on police spending',\n",
    "        'Regressing firm profits on R&D spending (innovative firms do both)',\n",
    "        'Regressing test scores on class size (using survey-reported class size)',\n",
    "    ],\n",
    "    'source': [\n",
    "        'OVB',\n",
    "        'measurement error',\n",
    "        'simultaneity',\n",
    "        'OVB (or simultaneity)',\n",
    "        'measurement error (+ possible OVB)',\n",
    "    ],\n",
    "    'remedy': [\n",
    "        'IV (e.g., proximity to college, compulsory schooling laws)',\n",
    "        'IV or use objective measurement (e.g., accelerometer data)',\n",
    "        'IV (e.g., use a policy shock that changes police but not crime directly)',\n",
    "        'Panel FE (control for firm-level unobservables) or IV',\n",
    "        'Administrative records for class size; IV for remaining endogeneity',\n",
    "    ],\n",
    "})\n",
    "scenarios\n",
    "```\n",
    "\n",
    "</details>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}