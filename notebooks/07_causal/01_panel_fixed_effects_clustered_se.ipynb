{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 01 Panel Fixed Effects + Clustered SE\n",
        "\n",
        "Pooled vs two-way fixed effects and clustered standard errors.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Table of Contents\n",
        "- [Load panel and define variables](#load-panel-and-define-variables)\n",
        "- [Pooled OLS baseline](#pooled-ols-baseline)\n",
        "- [Two-way fixed effects](#two-way-fixed-effects)\n",
        "- [Clustered standard errors](#clustered-standard-errors)\n",
        "- [Checkpoint (Self-Check)](#checkpoint-self-check)\n",
        "- [Solutions (Reference)](#solutions-reference)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Why This Notebook Matters\n",
        "Causal notebooks focus on **identification**: what would have to be true for a coefficient to represent a causal effect.\n",
        "You will practice:\n",
        "- building a county-year panel,\n",
        "- fixed effects (TWFE),\n",
        "- clustered standard errors,\n",
        "- DiD + event studies,\n",
        "- IV/2SLS.\n",
        "\n",
        "\n",
        "## What You Will Produce\n",
        "- (no file output; learning/analysis notebook)\n",
        "\n",
        "## Success Criteria\n",
        "- You can explain what you built and why each step exists.\n",
        "- You can run your work end-to-end without undefined variables.\n",
        "\n",
        "## Common Pitfalls\n",
        "- Running cells top-to-bottom without reading the instructions.\n",
        "- Leaving `...` placeholders in code cells.\n",
        "- Treating regression output as causal without stating identification assumptions.\n",
        "- Using non-clustered SE when shocks are correlated within groups (e.g., states).\n",
        "\n",
        "## Matching Guide\n",
        "- `docs/guides/07_causal/01_panel_fixed_effects_clustered_se.md`\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## How To Use This Notebook\n",
        "- This notebook is hands-on. Most code cells are incomplete on purpose.\n",
        "- Complete each TODO, then run the cell.\n",
        "- Use the matching guide (`docs/guides/07_causal/01_panel_fixed_effects_clustered_se.md`) for deep explanations and alternative examples.\n",
        "- Write short interpretation notes as you go (what changed, why it matters).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"environment-bootstrap\"></a>\n",
        "## Environment Bootstrap\n",
        "Run this cell first. It makes the repo importable and defines common directories.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "from pathlib import Path\n",
        "import sys\n",
        "\n",
        "\n",
        "def find_repo_root(start: Path) -> Path:\n",
        "    p = start\n",
        "    for _ in range(8):\n",
        "        if (p / 'src').exists() and (p / 'docs').exists():\n",
        "            return p\n",
        "        p = p.parent\n",
        "    raise RuntimeError('Could not find repo root. Start Jupyter from the repo root.')\n",
        "\n",
        "\n",
        "PROJECT_ROOT = find_repo_root(Path.cwd())\n",
        "if str(PROJECT_ROOT) not in sys.path:\n",
        "    sys.path.append(str(PROJECT_ROOT))\n",
        "\n",
        "DATA_DIR = PROJECT_ROOT / 'data'\n",
        "RAW_DIR = DATA_DIR / 'raw'\n",
        "PROCESSED_DIR = DATA_DIR / 'processed'\n",
        "SAMPLE_DIR = DATA_DIR / 'sample'\n",
        "\n",
        "PROJECT_ROOT\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Goal\n",
        "Compare:\n",
        "- pooled OLS (ignores panel structure)\n",
        "- two-way fixed effects (county FE + year FE)\n",
        "- robust vs clustered standard errors\n",
        "\n",
        "This is still not causal by default. FE helps control time-invariant confounding, not everything.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Primer: Panel and IV regression with `linearmodels`\n",
        "\n",
        "`statsmodels` is great for OLS inference, but panel and IV workflows are often cleaner with `linearmodels`.\n",
        "\n",
        "This project uses `linearmodels` for:\n",
        "- **PanelOLS** (fixed effects / TWFE)\n",
        "- **IV2SLS** (instrumental variables)\n",
        "\n",
        "### Panel data shape\n",
        "Most panel estimators expect a **MultiIndex**:\n",
        "- level 0: entity (e.g., county `fips`)\n",
        "- level 1: time (e.g., `year`)\n",
        "\n",
        "In pandas:\n",
        "```python\n",
        "# df is a DataFrame with columns fips, year, y, x1, x2\n",
        "# df = df.set_index(['fips', 'year']).sort_index()\n",
        "```\n",
        "\n",
        "### Minimal PanelOLS (two-way fixed effects)\n",
        "```python\n",
        "from linearmodels.panel import PanelOLS\n",
        "\n",
        "# y: Series with MultiIndex\n",
        "# X: DataFrame with MultiIndex\n",
        "\n",
        "# model: y_it = beta'X_it + alpha_i + gamma_t + eps_it\n",
        "# res = PanelOLS(y, X, entity_effects=True, time_effects=True).fit(cov_type='robust')\n",
        "# print(res.summary)\n",
        "```\n",
        "\n",
        "### Clustered standard errors (common in applied work)\n",
        "If errors are correlated within clusters (e.g., state), use clustered SE:\n",
        "```python\n",
        "# clusters must align with y/X index (same rows)\n",
        "# res = PanelOLS(y, X, entity_effects=True, time_effects=True).fit(\n",
        "#     cov_type='clustered',\n",
        "#     clusters=df['state'],  # e.g., state-level clustering\n",
        "# )\n",
        "```\n",
        "\n",
        "### Minimal IV2SLS (one endogenous regressor)\n",
        "```python\n",
        "from linearmodels.iv import IV2SLS\n",
        "import statsmodels.api as sm\n",
        "\n",
        "# y: Series\n",
        "# endog: DataFrame with endogenous regressor(s)\n",
        "# exog: DataFrame with controls (include a constant)\n",
        "# instr: DataFrame with instruments\n",
        "\n",
        "# exog = sm.add_constant(exog, has_constant='add')\n",
        "# res = IV2SLS(y, exog, endog, instr).fit(cov_type='robust')\n",
        "# print(res.summary)\n",
        "```\n",
        "\n",
        "### Practical rule\n",
        "- If the goal is **causal identification**, always write down the assumptions first (parallel trends, exclusion restriction, etc.).\n",
        "- Then treat the model output as conditional on those assumptions, not as \u201ctruth\u201d.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"load-panel-and-define-variables\"></a>\n",
        "## Load panel and define variables\n",
        "\n",
        "### Goal\n",
        "Load the county-year panel and build a small modeling table.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Your Turn: Load panel (processed or sample)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "path = PROCESSED_DIR / 'census_county_panel.csv'\n",
        "if path.exists():\n",
        "    df = pd.read_csv(path)\n",
        "else:\n",
        "    df = pd.read_csv(SAMPLE_DIR / 'census_county_panel_sample.csv')\n",
        "\n",
        "# TODO: Ensure fips/year exist and build a MultiIndex\n",
        "df['fips'] = df['fips'].astype(str)\n",
        "df['year'] = df['year'].astype(int)\n",
        "df = df.set_index(['fips', 'year'], drop=False).sort_index()\n",
        "\n",
        "# Starter transforms\n",
        "df['log_income'] = np.log(df['B19013_001E'].astype(float))\n",
        "df['log_rent'] = np.log(df['B25064_001E'].astype(float))\n",
        "\n",
        "df[['poverty_rate', 'unemployment_rate', 'log_income', 'log_rent']].describe()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"pooled-ols-baseline\"></a>\n",
        "## Pooled OLS baseline\n",
        "\n",
        "### Goal\n",
        "Fit a pooled model that ignores FE.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Your Turn: Fit pooled OLS\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import statsmodels.api as sm\n",
        "\n",
        "y_col = 'poverty_rate'\n",
        "x_cols = ['log_income', 'unemployment_rate']\n",
        "\n",
        "tmp = df[[y_col] + x_cols].dropna().copy()\n",
        "y = tmp[y_col].astype(float)\n",
        "X = sm.add_constant(tmp[x_cols].astype(float), has_constant='add')\n",
        "\n",
        "# TODO: Fit and print a summary (HC3 as a baseline)\n",
        "res_pool = sm.OLS(y, X).fit(cov_type='HC3')\n",
        "print(res_pool.summary())\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"two-way-fixed-effects\"></a>\n",
        "## Two-way fixed effects\n",
        "\n",
        "### Goal\n",
        "Estimate a TWFE model:\n",
        "- county FE (entity)\n",
        "- year FE (time)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Your Turn: Fit TWFE with PanelOLS\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "from src.causal import fit_twfe_panel_ols\n",
        "\n",
        "# TODO: Fit TWFE (robust SE)\n",
        "res_twfe = fit_twfe_panel_ols(\n",
        "    df,\n",
        "    y_col=y_col,\n",
        "    x_cols=x_cols,\n",
        "    entity_effects=True,\n",
        "    time_effects=True,\n",
        ")\n",
        "print(res_twfe.summary)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"clustered-standard-errors\"></a>\n",
        "## Clustered standard errors\n",
        "\n",
        "### Goal\n",
        "Re-fit TWFE with clustered SE.\n",
        "\n",
        "Typical clustering choice here:\n",
        "- by state (shared shocks/policies)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Your Turn: Cluster by state and compare SE\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from src.causal import fit_twfe_panel_ols\n",
        "\n",
        "# TODO: Compare robust vs clustered SE\n",
        "res_cluster = fit_twfe_panel_ols(\n",
        "    df,\n",
        "    y_col=y_col,\n",
        "    x_cols=x_cols,\n",
        "    entity_effects=True,\n",
        "    time_effects=True,\n",
        "    cluster_col='state',\n",
        ")\n",
        "\n",
        "pd.DataFrame({'robust_se': res_twfe.std_errors, 'cluster_se': res_cluster.std_errors})\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"checkpoint-self-check\"></a>\n",
        "## Checkpoint (Self-Check)\n",
        "Run a few asserts and write 2-3 sentences summarizing what you verified.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Expected output: (see notebook front matter)\n",
        "# TODO: If you created a panel DataFrame, verify the indexing + core columns.\n",
        "# Example (adjust variable names):\n",
        "# assert isinstance(panel.index, pd.MultiIndex)\n",
        "# assert panel.index.names[:2] == ['fips', 'year']\n",
        "# assert panel['year'].astype(int).between(1900, 2100).all()\n",
        "# assert panel['fips'].astype(str).str.len().eq(5).all()\n",
        "#\n",
        "# TODO: Write 2-3 sentences:\n",
        "# - What is the identification assumption for your causal estimate?\n",
        "# - What diagnostic/falsification did you run?\n",
        "...\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Extensions (Optional)\n",
        "- Try one additional variant beyond the main path (different features, different split, different model).\n",
        "- Write down what improved, what got worse, and your hypothesis for why.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Reflection\n",
        "- What did you assume implicitly (about timing, availability, stationarity, or costs)?\n",
        "- If you had to ship this model, what would you monitor?\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"solutions-reference\"></a>\n",
        "## Solutions (Reference)\n",
        "\n",
        "Try the TODOs first. Use these only to unblock yourself or to compare approaches.\n",
        "\n",
        "<details><summary>Solution: Load panel and define variables</summary>\n",
        "\n",
        "_One possible approach. Your variable names may differ; align them with the notebook._\n",
        "\n",
        "```python\n",
        "# Reference solution for 01_panel_fixed_effects_clustered_se \u2014 Load panel and define variables\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "path = PROCESSED_DIR / 'census_county_panel.csv'\n",
        "if path.exists():\n",
        "    df = pd.read_csv(path)\n",
        "else:\n",
        "    df = pd.read_csv(SAMPLE_DIR / 'census_county_panel_sample.csv')\n",
        "\n",
        "df['fips'] = df['fips'].astype(str)\n",
        "df['year'] = df['year'].astype(int)\n",
        "df = df.set_index(['fips', 'year'], drop=False).sort_index()\n",
        "\n",
        "df['log_income'] = np.log(df['B19013_001E'].astype(float))\n",
        "df['log_rent'] = np.log(df['B25064_001E'].astype(float))\n",
        "df[['poverty_rate', 'log_income', 'unemployment_rate']].describe()\n",
        "```\n",
        "\n",
        "</details>\n",
        "\n",
        "<details><summary>Solution: Pooled OLS baseline</summary>\n",
        "\n",
        "_One possible approach. Your variable names may differ; align them with the notebook._\n",
        "\n",
        "```python\n",
        "# Reference solution for 01_panel_fixed_effects_clustered_se \u2014 Pooled OLS baseline\n",
        "import statsmodels.api as sm\n",
        "\n",
        "tmp = df[['poverty_rate', 'log_income', 'unemployment_rate']].dropna().copy()\n",
        "y = tmp['poverty_rate'].astype(float)\n",
        "X = sm.add_constant(tmp[['log_income', 'unemployment_rate']], has_constant='add')\n",
        "res = sm.OLS(y, X).fit(cov_type='HC3')\n",
        "print(res.summary())\n",
        "```\n",
        "\n",
        "</details>\n",
        "\n",
        "<details><summary>Solution: Two-way fixed effects</summary>\n",
        "\n",
        "_One possible approach. Your variable names may differ; align them with the notebook._\n",
        "\n",
        "```python\n",
        "# Reference solution for 01_panel_fixed_effects_clustered_se \u2014 Two-way fixed effects\n",
        "from src.causal import fit_twfe_panel_ols\n",
        "\n",
        "res_twfe = fit_twfe_panel_ols(\n",
        "    df,\n",
        "    y_col='poverty_rate',\n",
        "    x_cols=['log_income', 'unemployment_rate'],\n",
        "    entity_effects=True,\n",
        "    time_effects=True,\n",
        ")\n",
        "print(res_twfe.summary)\n",
        "```\n",
        "\n",
        "</details>\n",
        "\n",
        "<details><summary>Solution: Clustered standard errors</summary>\n",
        "\n",
        "_One possible approach. Your variable names may differ; align them with the notebook._\n",
        "\n",
        "```python\n",
        "# Reference solution for 01_panel_fixed_effects_clustered_se \u2014 Clustered standard errors\n",
        "from src.causal import fit_twfe_panel_ols\n",
        "\n",
        "res_cluster = fit_twfe_panel_ols(\n",
        "    df,\n",
        "    y_col='poverty_rate',\n",
        "    x_cols=['log_income', 'unemployment_rate'],\n",
        "    entity_effects=True,\n",
        "    time_effects=True,\n",
        "    cluster_col='state',\n",
        ")\n",
        "\n",
        "pd.DataFrame({'robust_se': res_twfe.std_errors, 'cluster_se': res_cluster.std_errors})\n",
        "```\n",
        "\n",
        "</details>\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "python3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}