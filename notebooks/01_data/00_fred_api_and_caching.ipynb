{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 00 FRED API and Caching\n",
        "\n",
        "Fetch indicators from FRED and cache raw JSON.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Table of Contents\n",
        "- [Choose series](#choose-series)\n",
        "- [Fetch metadata](#fetch-metadata)\n",
        "- [Fetch + cache observations](#fetch-cache-observations)\n",
        "- [Fallback to sample](#fallback-to-sample)\n",
        "- [Checkpoint (Self-Check)](#checkpoint-self-check)\n",
        "- [Solutions (Reference)](#solutions-reference)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Why This Notebook Matters\n",
        "Data notebooks build the datasets used everywhere else. If these steps are wrong, every model result is suspect.\n",
        "You will practice:\n",
        "- API ingestion and caching,\n",
        "- frequency alignment,\n",
        "- label construction.\n",
        "\n",
        "\n",
        "## Prerequisites (Quick Self-Check)\n",
        "- Completed Part 00 (foundations) or equivalent time-series basics.\n",
        "- FRED API key set (`FRED_API_KEY`) for real data (sample data works offline).\n",
        "\n",
        "## What You Will Produce\n",
        "- (no file output; learning/analysis notebook)\n",
        "\n",
        "## Success Criteria\n",
        "- You can explain what you built and why each step exists.\n",
        "- You can run your work end-to-end without undefined variables.\n",
        "\n",
        "## Common Pitfalls\n",
        "- Running cells top-to-bottom without reading the instructions.\n",
        "- Leaving `...` placeholders in code cells.\n",
        "- Merging mixed-frequency series without explicit resampling/aggregation.\n",
        "- Forgetting to shift targets for forecasting tasks.\n",
        "\n",
        "## Quick Fixes (When You Get Stuck)\n",
        "- If you see `ModuleNotFoundError`, re-run the bootstrap cell and restart the kernel; make sure `PROJECT_ROOT` is the repo root.\n",
        "- If a `data/processed/*` file is missing, either run the matching build script (see guide) or use the notebook\u2019s `data/sample/*` fallback.\n",
        "- If results look \u201ctoo good,\u201d suspect leakage; re-check shifts, rolling windows, and time splits.\n",
        "- If a model errors, check dtypes (`astype(float)`) and missingness (`dropna()` on required columns).\n",
        "\n",
        "## Matching Guide\n",
        "- `docs/guides/01_data/00_fred_api_and_caching.md`\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## How To Use This Notebook\n",
        "- Work section-by-section; don\u2019t skip the markdown.\n",
        "- Most code cells are incomplete on purpose: replace TODOs and `...`, then run.\n",
        "- After each section, write 2\u20134 sentences answering the interpretation prompts (what changed, why it matters).\n",
        "- Prefer `data/processed/*` if you have built the real datasets; otherwise use the bundled `data/sample/*` fallbacks.\n",
        "- Use the **Checkpoint (Self-Check)** section to catch mistakes early.\n",
        "- Use **Solutions (Reference)** only to unblock yourself; then re-implement without looking.\n",
        "- Use the matching guide (`docs/guides/01_data/00_fred_api_and_caching.md`) for the math, assumptions, and deeper context.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"environment-bootstrap\"></a>\n",
        "## Environment Bootstrap\n",
        "Run this cell first. It makes the repo importable and defines common directories.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "from pathlib import Path\n",
        "import sys\n",
        "\n",
        "\n",
        "def find_repo_root(start: Path) -> Path:\n",
        "    p = start\n",
        "    for _ in range(8):\n",
        "        if (p / 'src').exists() and (p / 'docs').exists():\n",
        "            return p\n",
        "        p = p.parent\n",
        "    raise RuntimeError('Could not find repo root. Start Jupyter from the repo root.')\n",
        "\n",
        "\n",
        "PROJECT_ROOT = find_repo_root(Path.cwd())\n",
        "if str(PROJECT_ROOT) not in sys.path:\n",
        "    sys.path.append(str(PROJECT_ROOT))\n",
        "\n",
        "DATA_DIR = PROJECT_ROOT / 'data'\n",
        "RAW_DIR = DATA_DIR / 'raw'\n",
        "PROCESSED_DIR = DATA_DIR / 'processed'\n",
        "SAMPLE_DIR = DATA_DIR / 'sample'\n",
        "\n",
        "PROJECT_ROOT\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Goal\n",
        "Fetch a basket of economic indicators from FRED, cache the raw API responses, and build a tidy time series panel.\n",
        "\n",
        "### Why this matters\n",
        "You want to separate:\n",
        "- **data acquisition** (API calls) from\n",
        "- **analysis/modeling** (notebooks and scripts).\n",
        "\n",
        "Caching makes your work reproducible and faster.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Primer: Paths, files, and environment variables (how this repo stays reproducible)\n",
        "\n",
        "You will see a few patterns repeatedly in notebooks and scripts.\n",
        "\n",
        "### Environment variables (API keys)\n",
        "\n",
        "Environment variables are key/value settings provided by your shell to Python.\n",
        "This repo uses them for API keys:\n",
        "- `FRED_API_KEY`\n",
        "- `CENSUS_API_KEY` (optional)\n",
        "\n",
        "```python\n",
        "import os\n",
        "\n",
        "fred_key = os.getenv(\"FRED_API_KEY\")\n",
        "print(\"FRED key set?\", fred_key is not None)\n",
        "```\n",
        "\n",
        "If you set a key in a terminal, restart the Jupyter kernel so Python sees it.\n",
        "\n",
        "### Paths (why `pathlib.Path` is the default)\n",
        "\n",
        "Use `Path` to build OS-safe file paths:\n",
        "\n",
        "```python\n",
        "from pathlib import Path\n",
        "\n",
        "p = Path(\"data\") / \"sample\" / \"macro_quarterly_sample.csv\"\n",
        "print(p, \"exists?\", p.exists())\n",
        "```\n",
        "\n",
        "### Repo bootstrap variables (defined in every notebook)\n",
        "\n",
        "The notebook bootstrap cell defines:\n",
        "- `PROJECT_ROOT` (repo root)\n",
        "- `DATA_DIR`, `RAW_DIR`, `PROCESSED_DIR`, `SAMPLE_DIR`\n",
        "\n",
        "Prefer these over hard-coded relative paths.\n",
        "\n",
        "### Sample vs processed data (offline-first)\n",
        "\n",
        "Most notebooks follow this pattern:\n",
        "1) try `data/processed/*` (real pipeline output)\n",
        "2) fall back to `data/sample/*` (small offline dataset)\n",
        "\n",
        "This keeps notebooks runnable without network access.\n",
        "\n",
        "### Common \u201cfile not found\u201d fixes\n",
        "\n",
        "- Print the path and check `.exists()`\n",
        "- Print current working directory:\n",
        "  - `import os; print(os.getcwd())`\n",
        "- Start Jupyter from the repo root (so bootstrap can find `src/` and `docs/`)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"choose-series\"></a>\n",
        "## Choose series\n",
        "\n",
        "### Goal\n",
        "Pick a starter basket of macro indicators.\n",
        "\n",
        "### Notes\n",
        "- Different indicators have different frequencies (monthly, daily, quarterly).\n",
        "- We'll deal with alignment in later notebooks.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Your Turn (1): Define a basket of series IDs\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# TODO: Define a list of FRED series IDs (strings)\n",
        "# Suggested starters:\n",
        "# - UNRATE   (Unemployment rate, monthly)\n",
        "# - FEDFUNDS (Fed funds rate, monthly)\n",
        "# - CPIAUCSL (CPI, monthly)\n",
        "# - INDPRO   (Industrial Production, monthly)\n",
        "# - RSAFS    (Retail Sales, monthly)\n",
        "# - T10Y2Y   (10Y-2Y yield spread, daily)\n",
        "series_ids = [\n",
        "    ...,\n",
        "]\n",
        "\n",
        "# TODO: Basic validation\n",
        "assert isinstance(series_ids, list)\n",
        "assert all(isinstance(x, str) and x for x in series_ids)\n",
        "assert len(series_ids) == len(set(series_ids)), 'duplicate series IDs'\n",
        "series_ids\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"fetch-metadata\"></a>\n",
        "## Fetch metadata\n",
        "\n",
        "### Goal\n",
        "Metadata answers: what is this series, what are the units, and what is its native frequency?\n",
        "\n",
        "You will use metadata later to decide:\n",
        "- which features are meaningful,\n",
        "- how to align frequencies,\n",
        "- how to interpret coefficient units.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Your Turn (1): Fetch metadata for one series\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "from src import fred_api\n",
        "\n",
        "# TODO: Pick one series_id and fetch metadata\n",
        "sid = series_ids[0]\n",
        "meta = fred_api.fetch_series_meta(sid)\n",
        "\n",
        "# TODO: Print the most important fields (title, units, frequency)\n",
        "...\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Your Turn (2): Fetch metadata for all series and build a table\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from src import fred_api\n",
        "\n",
        "# TODO: Loop over series_ids and build a DataFrame of metadata.\n",
        "# Hint: meta is a dict; you can select keys you care about.\n",
        "rows = []\n",
        "for sid in series_ids:\n",
        "    meta = fred_api.fetch_series_meta(sid)\n",
        "    rows.append({\n",
        "        'id': sid,\n",
        "        'title': meta.get('title'),\n",
        "        'units': meta.get('units'),\n",
        "        'frequency': meta.get('frequency'),\n",
        "        'seasonal_adjustment': meta.get('seasonal_adjustment'),\n",
        "    })\n",
        "\n",
        "meta_df = pd.DataFrame(rows)\n",
        "meta_df\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"fetch-cache-observations\"></a>\n",
        "## Fetch + cache observations\n",
        "\n",
        "### Goal\n",
        "Download observations for each series and cache the raw JSON under `data/raw/fred/`.\n",
        "\n",
        "### Why cache raw JSON?\n",
        "- It's the exact raw record of what the API returned.\n",
        "- You can debug parsing issues later without re-downloading.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Your Turn (1): Fetch and cache JSON payloads\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "from src import data as data_utils\n",
        "from src import fred_api\n",
        "\n",
        "# We'll store raw API responses here\n",
        "raw_dir = RAW_DIR / 'fred'\n",
        "raw_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# TODO: For each series_id, cache JSON under data/raw/fred/<id>.json\n",
        "# Hint: data_utils.load_or_fetch_json(path, fetch_fn)\n",
        "...\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Your Turn (2): Convert cached payloads to a tidy DataFrame panel\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from src import data as data_utils\n",
        "from src import fred_api\n",
        "\n",
        "# TODO: For each series, load JSON and convert to a 1-column DataFrame\n",
        "# Hint: fred_api.observations_to_frame(payload, sid)\n",
        "frames = []\n",
        "for sid in series_ids:\n",
        "    payload = data_utils.load_json(raw_dir / f'{sid}.json')\n",
        "    frames.append(fred_api.observations_to_frame(payload, sid))\n",
        "\n",
        "panel = pd.concat(frames, axis=1).sort_index()\n",
        "panel.head()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Your Turn (3): Inspect missingness and basic ranges\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# TODO: Print missing values per column\n",
        "# TODO: Print min/max dates\n",
        "# TODO: Describe each column\n",
        "print('date range:', panel.index.min(), '->', panel.index.max())\n",
        "print(panel.isna().sum().sort_values(ascending=False))\n",
        "panel.describe().T\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Checkpoint (panel sanity)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# TODO: These checks should pass if you built a valid panel.\n",
        "assert isinstance(panel.index, pd.DatetimeIndex)\n",
        "assert panel.index.is_monotonic_increasing\n",
        "assert panel.shape[0] > 200\n",
        "assert panel.shape[1] == len(series_ids)\n",
        "...\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"fallback-to-sample\"></a>\n",
        "## Fallback to sample\n",
        "\n",
        "If you cannot fetch from the API (no key, no network), load the bundled sample panel.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# TODO: Implement a fallback:\n",
        "# - if FRED_API_KEY is missing, load data/sample/panel_monthly_sample.csv\n",
        "# - otherwise, keep using your freshly built panel\n",
        "if not os.getenv('FRED_API_KEY'):\n",
        "    panel = pd.read_csv(SAMPLE_DIR / 'panel_monthly_sample.csv', index_col=0, parse_dates=True)\n",
        "\n",
        "panel.head()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"checkpoint-self-check\"></a>\n",
        "## Checkpoint (Self-Check)\n",
        "Run a few asserts and write 2-3 sentences summarizing what you verified.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Expected file: (see notebook front matter)\n",
        "# TODO: After saving your processed dataset, load it and run checks.\n",
        "# df = pd.read_csv(PROCESSED_DIR / 'your_file.csv', index_col=0, parse_dates=True)\n",
        "# assert df.index.is_monotonic_increasing\n",
        "# assert df.shape[0] > 20\n",
        "# print(df.dtypes)\n",
        "...\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Extensions (Optional)\n",
        "- Try one additional variant beyond the main path (different features, different split, different model).\n",
        "- Write down what improved, what got worse, and your hypothesis for why.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Reflection\n",
        "- What did you assume implicitly (about timing, availability, stationarity, or costs)?\n",
        "- If you had to ship this model, what would you monitor?\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"solutions-reference\"></a>\n",
        "## Solutions (Reference)\n",
        "\n",
        "Try the TODOs first. Use these only to unblock yourself or to compare approaches.\n",
        "\n",
        "<details><summary>Solution: Choose series</summary>\n",
        "\n",
        "_One possible approach. Your variable names may differ; align them with the notebook._\n",
        "\n",
        "```python\n",
        "# Reference solution for 00_fred_api_and_caching \u2014 Choose series\n",
        "series_ids = ['UNRATE', 'FEDFUNDS', 'CPIAUCSL', 'INDPRO', 'RSAFS', 'T10Y2Y']\n",
        "series_ids\n",
        "```\n",
        "\n",
        "</details>\n",
        "\n",
        "<details><summary>Solution: Fetch metadata</summary>\n",
        "\n",
        "_One possible approach. Your variable names may differ; align them with the notebook._\n",
        "\n",
        "```python\n",
        "# Reference solution for 00_fred_api_and_caching \u2014 Fetch metadata\n",
        "from src import fred_api\n",
        "\n",
        "meta = fred_api.fetch_series_meta('UNRATE')\n",
        "meta\n",
        "```\n",
        "\n",
        "</details>\n",
        "\n",
        "<details><summary>Solution: Fetch + cache observations</summary>\n",
        "\n",
        "_One possible approach. Your variable names may differ; align them with the notebook._\n",
        "\n",
        "```python\n",
        "# Reference solution for 00_fred_api_and_caching \u2014 Fetch + cache observations\n",
        "from src import data as data_utils\n",
        "from src import fred_api\n",
        "\n",
        "raw_dir = RAW_DIR / 'fred'\n",
        "raw_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "frames = []\n",
        "for sid in series_ids:\n",
        "    payload = data_utils.load_or_fetch_json(\n",
        "        raw_dir / f'{sid}.json',\n",
        "        lambda sid=sid: fred_api.fetch_series_observations(sid, start_date='1980-01-01', end_date=None),\n",
        "    )\n",
        "    frames.append(fred_api.observations_to_frame(payload, sid))\n",
        "\n",
        "panel = pd.concat(frames, axis=1).sort_index()\n",
        "panel.head()\n",
        "```\n",
        "\n",
        "</details>\n",
        "\n",
        "<details><summary>Solution: Fallback to sample</summary>\n",
        "\n",
        "_One possible approach. Your variable names may differ; align them with the notebook._\n",
        "\n",
        "```python\n",
        "# Reference solution for 00_fred_api_and_caching \u2014 Fallback to sample\n",
        "import pandas as pd\n",
        "\n",
        "panel = pd.read_csv(SAMPLE_DIR / 'panel_monthly_sample.csv', index_col=0, parse_dates=True)\n",
        "panel.head()\n",
        "```\n",
        "\n",
        "</details>\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "python3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}