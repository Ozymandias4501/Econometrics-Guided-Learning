{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 04 Census API Microdata Fetch\n",
        "\n",
        "Fetch county-level ACS data and build a micro dataset.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Table of Contents\n",
        "- [Browse variables](#browse-variables)\n",
        "- [Fetch county data](#fetch-county-data)\n",
        "- [Derived rates](#derived-rates)\n",
        "- [Save processed data](#save-processed-data)\n",
        "- [Checkpoint (Self-Check)](#checkpoint-self-check)\n",
        "- [Solutions (Reference)](#solutions-reference)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Why This Notebook Matters\n",
        "Data notebooks build the datasets used everywhere else. If these steps are wrong, every model result is suspect.\n",
        "You will practice:\n",
        "- API ingestion and caching,\n",
        "- frequency alignment,\n",
        "- label construction.\n",
        "\n",
        "\n",
        "## What You Will Produce\n",
        "- data/processed/census_county_<year>.csv\n",
        "\n",
        "## Success Criteria\n",
        "- You can explain what you built and why each step exists.\n",
        "- You can run your work end-to-end without undefined variables.\n",
        "- You can point to the concrete deliverable(s) listed below and explain how they were produced.\n",
        "\n",
        "## Common Pitfalls\n",
        "- Running cells top-to-bottom without reading the instructions.\n",
        "- Leaving `...` placeholders in code cells.\n",
        "- Merging mixed-frequency series without explicit resampling/aggregation.\n",
        "- Forgetting to shift targets for forecasting tasks.\n",
        "\n",
        "## Matching Guide\n",
        "- `docs/guides/01_data/04_census_api_microdata_fetch.md`\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## How To Use This Notebook\n",
        "- This notebook is hands-on. Most code cells are incomplete on purpose.\n",
        "- Complete each TODO, then run the cell.\n",
        "- Use the matching guide (`docs/guides/01_data/04_census_api_microdata_fetch.md`) for deep explanations and alternative examples.\n",
        "- Write short interpretation notes as you go (what changed, why it matters).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"environment-bootstrap\"></a>\n",
        "## Environment Bootstrap\n",
        "Run this cell first. It makes the repo importable and defines common directories.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "from pathlib import Path\n",
        "import sys\n",
        "\n",
        "\n",
        "def find_repo_root(start: Path) -> Path:\n",
        "    p = start\n",
        "    for _ in range(8):\n",
        "        if (p / 'src').exists() and (p / 'docs').exists():\n",
        "            return p\n",
        "        p = p.parent\n",
        "    raise RuntimeError('Could not find repo root. Start Jupyter from the repo root.')\n",
        "\n",
        "\n",
        "PROJECT_ROOT = find_repo_root(Path.cwd())\n",
        "if str(PROJECT_ROOT) not in sys.path:\n",
        "    sys.path.append(str(PROJECT_ROOT))\n",
        "\n",
        "DATA_DIR = PROJECT_ROOT / 'data'\n",
        "RAW_DIR = DATA_DIR / 'raw'\n",
        "PROCESSED_DIR = DATA_DIR / 'processed'\n",
        "SAMPLE_DIR = DATA_DIR / 'sample'\n",
        "\n",
        "PROJECT_ROOT\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Goal\n",
        "Build a county-level micro dataset from the US Census ACS API.\n",
        "\n",
        "### Why this matters\n",
        "This micro track is deliberately different from macro time series:\n",
        "- observations are counties (not time)\n",
        "- regression interpretation focuses on cross-sectional relationships\n",
        "- robust SE (HC3) is usually more relevant than time-series HAC\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Primer: Paths, Files, and Environment Variables\n",
        "\n",
        "You will see a few patterns repeatedly in this repo.\n",
        "\n",
        "### Environment variables\n",
        "> **What this is:** Environment variables are key/value settings provided by your shell to your Python process.\n",
        "\n",
        "We use them for API keys and configuration defaults.\n",
        "\n",
        "```python\n",
        "import os\n",
        "\n",
        "# Reads an environment variable or returns None\n",
        "fred_key = os.getenv('FRED_API_KEY')\n",
        "print('FRED key set?', fred_key is not None)\n",
        "```\n",
        "\n",
        "If you're running from a terminal, you can set a key like this:\n",
        "\n",
        "```bash\n",
        "export FRED_API_KEY=\"your_key_here\"\n",
        "```\n",
        "\n",
        "Then restart the Jupyter kernel (so Python picks up the new env var).\n",
        "\n",
        "### Paths (why `pathlib.Path`)\n",
        "> **What this is:** A Path is a safe way to build file paths without worrying about OS-specific separators.\n",
        "\n",
        "```python\n",
        "from pathlib import Path\n",
        "\n",
        "p = Path('data') / 'sample' / 'macro_quarterly_sample.csv'\n",
        "print(p)\n",
        "print('exists?', p.exists())\n",
        "```\n",
        "\n",
        "In these notebooks, the bootstrap cell defines:\n",
        "- `PROJECT_ROOT` (repo root)\n",
        "- `DATA_DIR`, `RAW_DIR`, `PROCESSED_DIR`, `SAMPLE_DIR`\n",
        "\n",
        "Prefer those over hard-coding paths.\n",
        "\n",
        "### Reading and writing CSV files\n",
        "```python\n",
        "import pandas as pd\n",
        "\n",
        "# Read\n",
        "# df = pd.read_csv(p, index_col=0, parse_dates=True)\n",
        "\n",
        "# Write\n",
        "# out = Path('data') / 'processed' / 'my_dataset.csv'\n",
        "# out.parent.mkdir(parents=True, exist_ok=True)\n",
        "# df.to_csv(out)\n",
        "```\n",
        "\n",
        "### Tip\n",
        "If you get a \"file not found\" error:\n",
        "- `print(path)` to confirm you're reading what you think you're reading\n",
        "- `print(path.exists())` to confirm the file exists\n",
        "- if you're using a relative path, confirm your current working directory: `import os; print(os.getcwd())`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"browse-variables\"></a>\n",
        "## Browse variables\n",
        "\n",
        "### Goal\n",
        "Learn how ACS variable codes work and choose a starter set.\n",
        "\n",
        "We'll focus on a practical starter set:\n",
        "- population\n",
        "- median household income\n",
        "- median gross rent\n",
        "- median home value\n",
        "- poverty count (to build a poverty rate)\n",
        "- labor force / unemployment (to build an unemployment rate)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Your Turn (1): Fetch or load variables.json\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import json\n",
        "from src import census_api\n",
        "\n",
        "year = 2022  # TODO: change if you want a different year\n",
        "raw_dir = RAW_DIR / 'census'\n",
        "raw_dir.mkdir(parents=True, exist_ok=True)\n",
        "vars_path = raw_dir / f'variables_{year}.json'\n",
        "\n",
        "# TODO: Load variables metadata.\n",
        "# - If vars_path exists, load it from disk.\n",
        "# - Otherwise, fetch from the API and save it to vars_path.\n",
        "...\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Your Turn (2): Search for relevant variables\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# The variables metadata is a nested JSON structure.\n",
        "# TODO: Explore it and search for keywords like:\n",
        "# - 'Median household income'\n",
        "# - 'Median gross rent'\n",
        "# - 'Poverty'\n",
        "# - 'Labor force'\n",
        "\n",
        "# Hint: variables are typically under payload['variables'].\n",
        "...\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"fetch-county-data\"></a>\n",
        "## Fetch county data\n",
        "\n",
        "### Goal\n",
        "Fetch a county-level table for your chosen variables.\n",
        "\n",
        "Default geography:\n",
        "- all counties: `for=county:*`\n",
        "- within all states: `in=state:*`\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Your Turn (1): Choose a starter variable set\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# TODO: Use a starter set.\n",
        "# These are commonly-used ACS 5-year estimate codes:\n",
        "acs_vars = [\n",
        "    'NAME',\n",
        "    'B01003_001E',  # total population\n",
        "    'B19013_001E',  # median household income\n",
        "    'B25064_001E',  # median gross rent\n",
        "    'B25077_001E',  # median home value\n",
        "    'B17001_002E',  # count below poverty level\n",
        "    'B23025_002E',  # in labor force\n",
        "    'B23025_005E',  # unemployed\n",
        "]\n",
        "\n",
        "acs_vars\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Your Turn (2): Fetch the ACS table\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from src import census_api\n",
        "\n",
        "# TODO: Fetch the data from the API.\n",
        "# Hint: census_api.fetch_acs(year=..., get=..., for_geo='county:*', in_geo='state:*')\n",
        "try:\n",
        "    df_raw = census_api.fetch_acs(year=year, get=acs_vars, for_geo='county:*', in_geo='state:*')\n",
        "except Exception as exc:\n",
        "    df_raw = None\n",
        "    print('Fetch failed, will use sample. Error:', exc)\n",
        "\n",
        "df_raw.head() if df_raw is not None else None\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Your Turn (3): Fallback to sample\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# TODO: If df_raw is None, load the sample dataset.\n",
        "if df_raw is None:\n",
        "    df_raw = pd.read_csv(SAMPLE_DIR / 'census_county_sample.csv')\n",
        "\n",
        "df_raw.head()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"derived-rates\"></a>\n",
        "## Derived rates\n",
        "\n",
        "### Goal\n",
        "Turn raw counts into rates (more comparable across counties).\n",
        "\n",
        "You will build:\n",
        "- unemployment_rate = unemployed / labor_force\n",
        "- poverty_rate = below_poverty / population\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Your Turn (1): Cast numeric columns\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# TODO: Ensure numeric columns are numeric (some API returns strings).\n",
        "# Hint: pd.to_numeric(..., errors='coerce')\n",
        "...\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Your Turn (2): Build derived rates safely\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# TODO: Compute rates with safe division.\n",
        "# Replace division-by-zero with NaN.\n",
        "\n",
        "pop = df_raw['B01003_001E'].astype(float)\n",
        "labor_force = df_raw['B23025_002E'].astype(float)\n",
        "unemployed = df_raw['B23025_005E'].astype(float)\n",
        "below_pov = df_raw['B17001_002E'].astype(float)\n",
        "\n",
        "df_raw['unemployment_rate'] = unemployed / labor_force.replace({0: np.nan})\n",
        "df_raw['poverty_rate'] = below_pov / pop.replace({0: np.nan})\n",
        "\n",
        "df_raw[['unemployment_rate', 'poverty_rate']].describe()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"save-processed-data\"></a>\n",
        "## Save processed data\n",
        "\n",
        "### Goal\n",
        "Save a cleaned dataset to `data/processed/census_county_<year>.csv`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Your Turn (1): Save + reload\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "out_path = PROCESSED_DIR / f'census_county_{year}.csv'\n",
        "out_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# TODO: Select a useful subset of columns and save.\n",
        "# Suggested: NAME, state, county, raw vars, unemployment_rate, poverty_rate\n",
        "cols = ['NAME', 'state', 'county'] + [c for c in acs_vars if c not in {'NAME'}] + ['unemployment_rate', 'poverty_rate']\n",
        "df_out = df_raw[cols].copy()\n",
        "df_out.to_csv(out_path, index=False)\n",
        "\n",
        "df_check = pd.read_csv(out_path)\n",
        "df_check.head()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Checkpoint\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# TODO: Validate rates are in [0, 1] for most rows.\n",
        "assert (df_out['unemployment_rate'].dropna().between(0, 1).mean() > 0.95)\n",
        "assert (df_out['poverty_rate'].dropna().between(0, 1).mean() > 0.95)\n",
        "...\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"checkpoint-self-check\"></a>\n",
        "## Checkpoint (Self-Check)\n",
        "Run a few asserts and write 2-3 sentences summarizing what you verified.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Expected file: data/processed/census_county_<year>.csv\n",
        "# TODO: After saving your processed dataset, load it and run checks.\n",
        "# df = pd.read_csv(PROCESSED_DIR / 'your_file.csv', index_col=0, parse_dates=True)\n",
        "# assert df.index.is_monotonic_increasing\n",
        "# assert df.shape[0] > 20\n",
        "# print(df.dtypes)\n",
        "...\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Extensions (Optional)\n",
        "- Try one additional variant beyond the main path (different features, different split, different model).\n",
        "- Write down what improved, what got worse, and your hypothesis for why.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Reflection\n",
        "- What did you assume implicitly (about timing, availability, stationarity, or costs)?\n",
        "- If you had to ship this model, what would you monitor?\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"solutions-reference\"></a>\n",
        "## Solutions (Reference)\n",
        "\n",
        "Try the TODOs first. Use these only to unblock yourself or to compare approaches.\n",
        "\n",
        "<details><summary>Solution: Browse variables</summary>\n",
        "\n",
        "_One possible approach. Your variable names may differ; align them with the notebook._\n",
        "\n",
        "```python\n",
        "# Reference solution for 04_census_api_microdata_fetch \u2014 Browse variables\n",
        "import json\n",
        "\n",
        "# Offline default\n",
        "print('Open the Census variables metadata in data/raw/census/variables_<year>.json if available.')\n",
        "```\n",
        "\n",
        "</details>\n",
        "\n",
        "<details><summary>Solution: Fetch county data</summary>\n",
        "\n",
        "_One possible approach. Your variable names may differ; align them with the notebook._\n",
        "\n",
        "```python\n",
        "# Reference solution for 04_census_api_microdata_fetch \u2014 Fetch county data\n",
        "import pandas as pd\n",
        "\n",
        "# Offline default sample\n",
        "df = pd.read_csv(SAMPLE_DIR / 'census_county_sample.csv')\n",
        "df.head()\n",
        "```\n",
        "\n",
        "</details>\n",
        "\n",
        "<details><summary>Solution: Derived rates</summary>\n",
        "\n",
        "_One possible approach. Your variable names may differ; align them with the notebook._\n",
        "\n",
        "```python\n",
        "# Reference solution for 04_census_api_microdata_fetch \u2014 Derived rates\n",
        "df['unemployment_rate'] = df['B23025_005E'] / df['B23025_002E']\n",
        "df['poverty_rate'] = df['B17001_002E'] / df['B01003_001E']\n",
        "df[['unemployment_rate', 'poverty_rate']].describe()\n",
        "```\n",
        "\n",
        "</details>\n",
        "\n",
        "<details><summary>Solution: Save processed data</summary>\n",
        "\n",
        "_One possible approach. Your variable names may differ; align them with the notebook._\n",
        "\n",
        "```python\n",
        "# Reference solution for 04_census_api_microdata_fetch \u2014 Save processed data\n",
        "from src import data as data_utils\n",
        "year = 2022\n",
        "data_utils.save_csv(df.set_index(['state','county'], drop=False), PROCESSED_DIR / f'census_county_{year}.csv')\n",
        "print('saved')\n",
        "```\n",
        "\n",
        "</details>\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "python3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}