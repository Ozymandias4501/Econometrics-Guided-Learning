{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04 Census API Microdata Fetch\n",
    "\n",
    "Fetch county-level ACS data and build a micro dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "- [Browse variables](#browse-variables)\n",
    "- [Fetch county data](#fetch-county-data)\n",
    "- [Derived rates](#derived-rates)\n",
    "- [Save processed data](#save-processed-data)\n",
    "- [Checkpoint (Self-Check)](#checkpoint-self-check)\n",
    "- [Solutions (Reference)](#solutions-reference)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Why This Notebook Matters\nData notebooks build the datasets used everywhere else. If these steps are wrong, every model result is suspect.\nYou will practice:\n- fetching cross-sectional data from the Census API,\n- validating geographic identifiers (FIPS codes),\n- computing derived rates from raw counts.\n\n\n## Prerequisites (Quick Self-Check)\n- Completed Part 00 (foundations): environment setup and data loading patterns.\n- Census API key set (`CENSUS_API_KEY`) for live fetches (sample data works offline).\n\n## What You Will Produce\n- data/processed/census_county_<year>.csv\n\n## Success Criteria\n- You can explain what you built and why each step exists.\n- You can run your work end-to-end without undefined variables.\n- You can point to the concrete deliverable(s) listed below and explain how they were produced.\n\n## Common Pitfalls\n- Running cells top-to-bottom without reading the instructions.\n- Leaving `...` placeholders in code cells.\n- Storing FIPS codes as integers (drops leading zeros, breaks merges).\n- Mismatching numerator and denominator universes when computing rates (e.g., using total population instead of civilian non-institutionalized population for insurance rates).\n- Forgetting that Census API returns strings — cast to numeric with `pd.to_numeric(..., errors='coerce')`.\n\n## Quick Fixes (When You Get Stuck)\n- If you see `ModuleNotFoundError`, re-run the bootstrap cell and restart the kernel; make sure `PROJECT_ROOT` is the repo root.\n- If a `data/processed/*` file is missing, either run the matching build script (see guide) or use the notebook's `data/sample/*` fallback.\n- If a rate is outside [0, 1], check your numerator/denominator columns — you may have the wrong ACS variable code.\n- If a merge drops rows, check that FIPS codes are 5-character zero-padded strings in both DataFrames.\n\n## Matching Guide\n- `docs/guides/01_data/04_census_api_microdata_fetch.md`\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How To Use This Notebook\n",
    "- Work section-by-section; don’t skip the markdown.\n",
    "- Most code cells are incomplete on purpose: replace TODOs and `...`, then run.\n",
    "- After each section, write 2–4 sentences answering the interpretation prompts (what changed, why it matters).\n",
    "- Prefer `data/processed/*` if you have built the real datasets; otherwise use the bundled `data/sample/*` fallbacks.\n",
    "- Use the **Checkpoint (Self-Check)** section to catch mistakes early.\n",
    "- Use **Solutions (Reference)** only to unblock yourself; then re-implement without looking.\n",
    "- Use the matching guide (`docs/guides/01_data/04_census_api_microdata_fetch.md`) for the math, assumptions, and deeper context.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"environment-bootstrap\"></a>\n",
    "## Environment Bootstrap\n",
    "Run this cell first. It makes the repo importable and defines common directories.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "\n",
    "def find_repo_root(start: Path) -> Path:\n",
    "    p = start\n",
    "    for _ in range(8):\n",
    "        if (p / 'src').exists() and (p / 'docs').exists():\n",
    "            return p\n",
    "        p = p.parent\n",
    "    raise RuntimeError('Could not find repo root. Start Jupyter from the repo root.')\n",
    "\n",
    "\n",
    "PROJECT_ROOT = find_repo_root(Path.cwd())\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.append(str(PROJECT_ROOT))\n",
    "\n",
    "DATA_DIR = PROJECT_ROOT / 'data'\n",
    "RAW_DIR = DATA_DIR / 'raw'\n",
    "PROCESSED_DIR = DATA_DIR / 'processed'\n",
    "SAMPLE_DIR = DATA_DIR / 'sample'\n",
    "\n",
    "PROJECT_ROOT\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal\n",
    "Build a county-level micro dataset from the US Census ACS API.\n",
    "\n",
    "### Why this matters\n",
    "This micro track is deliberately different from macro time series:\n",
    "- observations are counties (not time)\n",
    "- regression interpretation focuses on cross-sectional relationships\n",
    "- robust SE (HC3) is usually more relevant than time-series HAC\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Primer: Working with Census ACS data (FIPS codes, variable naming, type casting)\n\nCensus ACS data has its own patterns that differ from macro time series.\n\n### 1) FIPS codes (the geographic key for everything)\n\nEvery county has a 5-digit FIPS code: 2-digit state + 3-digit county.\n\n```python\n# WRONG: FIPS as integer (drops leading zeros)\nfips_int = 1001   # intended: Autauga County, AL\n# Merge with another dataset that has \"01001\" → no match!\n\n# RIGHT: FIPS as zero-padded string\nfips_str = \"01001\"  # always 5 characters\n# Or from separate columns:\nfips = state_fips.str.zfill(2) + county_fips.str.zfill(3)\n```\n\n**Rule:** Always store FIPS as strings. After any load or merge, assert they are 5 characters.\n\n### 2) ACS variable naming convention\n\nVariables follow the pattern `TABLE_SEQE` or `TABLE_SEQM`:\n- `B01003_001E` → table B01003, sequence 001, **E**stimate\n- `B01003_001M` → same variable, **M**argin of error\n\nThe `E` suffix is the point estimate; the `M` suffix is the 90% margin of error.\n\n### 3) Type casting (the API returns strings)\n\nThe Census API returns all values as strings, including numeric ones. The sentinel value `-666666666` means suppressed/unavailable.\n\n```python\nimport pandas as pd\n\n# Cast to numeric, turning non-numeric strings (like sentinels) into NaN\ndf[\"B01003_001E\"] = pd.to_numeric(df[\"B01003_001E\"], errors=\"coerce\")\n```\n\n**Always** cast numeric columns immediately after loading. If you skip this, arithmetic operations will silently fail or produce wrong results.\n\n### 4) Derived rates: numerator ÷ denominator\n\nWhen computing rates (poverty rate, uninsured rate), check that:\n- numerator and denominator come from the same \"universe\" (e.g., civilian non-institutionalized population)\n- you handle division by zero (small counties may have zero in a denominator category)\n\n```python\nimport numpy as np\n\n# Safe division: replace 0 with NaN to avoid inf\nrate = numerator / denominator.replace({0: np.nan})\nassert (rate.dropna().between(0, 1)).all(), \"Rate out of bounds — check your variables\"\n```\n\n### 5) Merging ACS tables\n\nWhen combining variables from different ACS tables:\n```python\nmerged = table1.merge(table2, on=\"fips\", validate=\"1:1\")\nassert len(merged) == len(table1), \"Merge changed row count — check FIPS alignment\"\n```\n\nUse `validate=\"1:1\"` to catch unexpected duplicates or missing keys.\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"browse-variables\"></a>\n",
    "## Browse variables\n",
    "\n",
    "### Goal\n",
    "Learn how ACS variable codes work and choose a starter set.\n",
    "\n",
    "We'll focus on a practical starter set:\n",
    "- population\n",
    "- median household income\n",
    "- median gross rent\n",
    "- median home value\n",
    "- poverty count (to build a poverty rate)\n",
    "- labor force / unemployment (to build an unemployment rate)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your Turn (1): Fetch or load variables.json\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "import json\n",
    "from src import census_api\n",
    "\n",
    "year = 2022  # TODO: change if you want a different year\n",
    "raw_dir = RAW_DIR / 'census'\n",
    "raw_dir.mkdir(parents=True, exist_ok=True)\n",
    "vars_path = raw_dir / f'variables_{year}.json'\n",
    "\n",
    "# TODO: Load variables metadata.\n",
    "# - If vars_path exists, load it from disk.\n",
    "# - Otherwise, fetch from the API and save it to vars_path.\n",
    "...\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your Turn (2): Search for relevant variables\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# The variables metadata is a nested JSON structure.\n",
    "# TODO: Explore it and search for keywords like:\n",
    "# - 'Median household income'\n",
    "# - 'Median gross rent'\n",
    "# - 'Poverty'\n",
    "# - 'Labor force'\n",
    "\n",
    "# Hint: variables are typically under payload['variables'].\n",
    "...\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"fetch-county-data\"></a>\n",
    "## Fetch county data\n",
    "\n",
    "### Goal\n",
    "Fetch a county-level table for your chosen variables.\n",
    "\n",
    "Default geography:\n",
    "- all counties: `for=county:*`\n",
    "- within all states: `in=state:*`\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your Turn (1): Choose a starter variable set\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# TODO: Use a starter set.\n",
    "# These are commonly-used ACS 5-year estimate codes:\n",
    "acs_vars = [\n",
    "    'NAME',\n",
    "    'B01003_001E',  # total population\n",
    "    'B19013_001E',  # median household income\n",
    "    'B25064_001E',  # median gross rent\n",
    "    'B25077_001E',  # median home value\n",
    "    'B17001_002E',  # count below poverty level\n",
    "    'B23025_002E',  # in labor force\n",
    "    'B23025_005E',  # unemployed\n",
    "]\n",
    "\n",
    "acs_vars\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your Turn (2): Fetch the ACS table\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from src import census_api\n",
    "\n",
    "# TODO: Fetch the data from the API.\n",
    "# Hint: census_api.fetch_acs(year=..., get=..., for_geo='county:*', in_geo='state:*')\n",
    "try:\n",
    "    df_raw = census_api.fetch_acs(year=year, get=acs_vars, for_geo='county:*', in_geo='state:*')\n",
    "except Exception as exc:\n",
    "    df_raw = None\n",
    "    print('Fetch failed, will use sample. Error:', exc)\n",
    "\n",
    "df_raw.head() if df_raw is not None else None\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your Turn (3): Fallback to sample\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# TODO: If df_raw is None, load the sample dataset.\n",
    "if df_raw is None:\n",
    "    df_raw = pd.read_csv(SAMPLE_DIR / 'census_county_sample.csv')\n",
    "\n",
    "df_raw.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"derived-rates\"></a>\n",
    "## Derived rates\n",
    "\n",
    "### Goal\n",
    "Turn raw counts into rates (more comparable across counties).\n",
    "\n",
    "You will build:\n",
    "- unemployment_rate = unemployed / labor_force\n",
    "- poverty_rate = below_poverty / population\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your Turn (1): Cast numeric columns\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# TODO: Ensure numeric columns are numeric (some API returns strings).\n",
    "# Hint: pd.to_numeric(..., errors='coerce')\n",
    "...\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your Turn (2): Build derived rates safely\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# TODO: Compute rates with safe division.\n",
    "# Replace division-by-zero with NaN.\n",
    "\n",
    "pop = df_raw['B01003_001E'].astype(float)\n",
    "labor_force = df_raw['B23025_002E'].astype(float)\n",
    "unemployed = df_raw['B23025_005E'].astype(float)\n",
    "below_pov = df_raw['B17001_002E'].astype(float)\n",
    "\n",
    "df_raw['unemployment_rate'] = unemployed / labor_force.replace({0: np.nan})\n",
    "df_raw['poverty_rate'] = below_pov / pop.replace({0: np.nan})\n",
    "\n",
    "df_raw[['unemployment_rate', 'poverty_rate']].describe()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"save-processed-data\"></a>\n",
    "## Save processed data\n",
    "\n",
    "### Goal\n",
    "Save a cleaned dataset to `data/processed/census_county_<year>.csv`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your Turn (1): Save + reload\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "out_path = PROCESSED_DIR / f'census_county_{year}.csv'\n",
    "out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# TODO: Select a useful subset of columns and save.\n",
    "# Suggested: NAME, state, county, raw vars, unemployment_rate, poverty_rate\n",
    "cols = ['NAME', 'state', 'county'] + [c for c in acs_vars if c not in {'NAME'}] + ['unemployment_rate', 'poverty_rate']\n",
    "df_out = df_raw[cols].copy()\n",
    "df_out.to_csv(out_path, index=False)\n",
    "\n",
    "df_check = pd.read_csv(out_path)\n",
    "df_check.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checkpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# TODO: Validate rates are in [0, 1] for most rows.\n",
    "assert (df_out['unemployment_rate'].dropna().between(0, 1).mean() > 0.95)\n",
    "assert (df_out['poverty_rate'].dropna().between(0, 1).mean() > 0.95)\n",
    "...\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"checkpoint-self-check\"></a>\n",
    "## Checkpoint (Self-Check)\n",
    "Run a few asserts and write 2-3 sentences summarizing what you verified.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "import pandas as pd\n\n# Expected file: data/processed/census_county_<year>.csv\n# TODO: After saving your processed dataset, load it and run checks.\n# df = pd.read_csv(PROCESSED_DIR / f'census_county_{year}.csv')\n# assert df.shape[0] > 3000, \"Expected ~3,200 counties\"\n# assert all(df['state'].astype(str).str.len() == 2), \"State FIPS should be 2 chars\"\n# assert all(df['county'].astype(str).str.len() == 3), \"County FIPS should be 3 chars\"\n# assert df['poverty_rate'].dropna().between(0, 1).all(), \"Poverty rate out of bounds\"\n# print(df.dtypes)\n..."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Extensions (Optional)\n- Fetch an additional ACS table (e.g., B27001 for health insurance) and merge it with your county dataset on FIPS.\n- Compare 1-year vs 5-year estimates for a large county — how much do they differ?\n- Plot a choropleth or bar chart of poverty rates by state.\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Reflection\n- Which counties had the highest margins of error relative to their estimates? Why?\n- If you were merging this Census data with health outcomes (e.g., mortality rates), what FIPS code issues might you encounter?\n- How would you handle a county that was renamed or re-coded between ACS vintages?\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"solutions-reference\"></a>\n",
    "## Solutions (Reference)\n",
    "\n",
    "Try the TODOs first. Use these only to unblock yourself or to compare approaches.\n",
    "\n",
    "<details><summary>Solution: Browse variables</summary>\n",
    "\n",
    "_One possible approach. Your variable names may differ; align them with the notebook._\n",
    "\n",
    "```python\n",
    "# Reference solution for 04_census_api_microdata_fetch — Browse variables\n",
    "import json\n",
    "\n",
    "# Offline default\n",
    "print('Open the Census variables metadata in data/raw/census/variables_<year>.json if available.')\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "<details><summary>Solution: Fetch county data</summary>\n",
    "\n",
    "_One possible approach. Your variable names may differ; align them with the notebook._\n",
    "\n",
    "```python\n",
    "# Reference solution for 04_census_api_microdata_fetch — Fetch county data\n",
    "import pandas as pd\n",
    "\n",
    "# Offline default sample\n",
    "df = pd.read_csv(SAMPLE_DIR / 'census_county_sample.csv')\n",
    "df.head()\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "<details><summary>Solution: Derived rates</summary>\n",
    "\n",
    "_One possible approach. Your variable names may differ; align them with the notebook._\n",
    "\n",
    "```python\n",
    "# Reference solution for 04_census_api_microdata_fetch — Derived rates\n",
    "df['unemployment_rate'] = df['B23025_005E'] / df['B23025_002E']\n",
    "df['poverty_rate'] = df['B17001_002E'] / df['B01003_001E']\n",
    "df[['unemployment_rate', 'poverty_rate']].describe()\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "<details><summary>Solution: Save processed data</summary>\n",
    "\n",
    "_One possible approach. Your variable names may differ; align them with the notebook._\n",
    "\n",
    "```python\n",
    "# Reference solution for 04_census_api_microdata_fetch — Save processed data\n",
    "from src import data as data_utils\n",
    "year = 2022\n",
    "data_utils.save_csv(df.set_index(['state','county'], drop=False), PROCESSED_DIR / f'census_county_{year}.csv')\n",
    "print('saved')\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}