{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 03 Build Macro Quarterly Features\n",
        "\n",
        "Aggregate monthly predictors to quarterly, add lags, and merge with targets.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Table of Contents\n",
        "- [Aggregate monthly -> quarterly](#aggregate-monthly-quarterly)\n",
        "- [Add lags](#add-lags)\n",
        "- [Merge with GDP/labels](#merge-with-gdp-labels)\n",
        "- [Save macro_quarterly.csv](#save-macro-quarterly-csv)\n",
        "- [Checkpoint (Self-Check)](#checkpoint-self-check)\n",
        "- [Solutions (Reference)](#solutions-reference)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Why This Notebook Matters\n",
        "Data notebooks build the datasets used everywhere else. If these steps are wrong, every model result is suspect.\n",
        "You will practice:\n",
        "- API ingestion and caching,\n",
        "- frequency alignment,\n",
        "- label construction.\n",
        "\n",
        "\n",
        "## Prerequisites (Quick Self-Check)\n",
        "- Completed Part 00 (foundations) or equivalent time-series basics.\n",
        "- FRED API key set (`FRED_API_KEY`) for real data (sample data works offline).\n",
        "\n",
        "## What You Will Produce\n",
        "- data/processed/macro_quarterly.csv\n",
        "\n",
        "## Success Criteria\n",
        "- You can explain what you built and why each step exists.\n",
        "- You can run your work end-to-end without undefined variables.\n",
        "- You can point to the concrete deliverable(s) listed below and explain how they were produced.\n",
        "\n",
        "## Common Pitfalls\n",
        "- Running cells top-to-bottom without reading the instructions.\n",
        "- Leaving `...` placeholders in code cells.\n",
        "- Merging mixed-frequency series without explicit resampling/aggregation.\n",
        "- Forgetting to shift targets for forecasting tasks.\n",
        "\n",
        "## Quick Fixes (When You Get Stuck)\n",
        "- If you see `ModuleNotFoundError`, re-run the bootstrap cell and restart the kernel; make sure `PROJECT_ROOT` is the repo root.\n",
        "- If a `data/processed/*` file is missing, either run the matching build script (see guide) or use the notebook\u2019s `data/sample/*` fallback.\n",
        "- If results look \u201ctoo good,\u201d suspect leakage; re-check shifts, rolling windows, and time splits.\n",
        "- If a model errors, check dtypes (`astype(float)`) and missingness (`dropna()` on required columns).\n",
        "\n",
        "## Matching Guide\n",
        "- `docs/guides/01_data/03_build_macro_quarterly_features.md`\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## How To Use This Notebook\n",
        "- Work section-by-section; don\u2019t skip the markdown.\n",
        "- Most code cells are incomplete on purpose: replace TODOs and `...`, then run.\n",
        "- After each section, write 2\u20134 sentences answering the interpretation prompts (what changed, why it matters).\n",
        "- Prefer `data/processed/*` if you have built the real datasets; otherwise use the bundled `data/sample/*` fallbacks.\n",
        "- Use the **Checkpoint (Self-Check)** section to catch mistakes early.\n",
        "- Use **Solutions (Reference)** only to unblock yourself; then re-implement without looking.\n",
        "- Use the matching guide (`docs/guides/01_data/03_build_macro_quarterly_features.md`) for the math, assumptions, and deeper context.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"environment-bootstrap\"></a>\n",
        "## Environment Bootstrap\n",
        "Run this cell first. It makes the repo importable and defines common directories.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "from pathlib import Path\n",
        "import sys\n",
        "\n",
        "\n",
        "def find_repo_root(start: Path) -> Path:\n",
        "    p = start\n",
        "    for _ in range(8):\n",
        "        if (p / 'src').exists() and (p / 'docs').exists():\n",
        "            return p\n",
        "        p = p.parent\n",
        "    raise RuntimeError('Could not find repo root. Start Jupyter from the repo root.')\n",
        "\n",
        "\n",
        "PROJECT_ROOT = find_repo_root(Path.cwd())\n",
        "if str(PROJECT_ROOT) not in sys.path:\n",
        "    sys.path.append(str(PROJECT_ROOT))\n",
        "\n",
        "DATA_DIR = PROJECT_ROOT / 'data'\n",
        "RAW_DIR = DATA_DIR / 'raw'\n",
        "PROCESSED_DIR = DATA_DIR / 'processed'\n",
        "SAMPLE_DIR = DATA_DIR / 'sample'\n",
        "\n",
        "PROJECT_ROOT\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Goal\n",
        "Build a quarterly modeling table by:\n",
        "1) aggregating monthly predictors to quarterly features\n",
        "2) adding lagged predictors (past-only)\n",
        "3) merging with quarterly GDP growth + recession targets\n",
        "\n",
        "The output is `data/processed/macro_quarterly.csv`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Primer: pandas time series essentials (indexing, resampling, lags)\n",
        "\n",
        "Most \u201cmysterious bugs\u201d in time series work come from index and alignment mistakes. This primer gives you the minimum patterns to avoid them.\n",
        "\n",
        "### 1) DatetimeIndex (the first thing to verify)\n",
        "\n",
        "Most time-series operations assume a `DatetimeIndex`:\n",
        "\n",
        "```python\n",
        "import pandas as pd\n",
        "\n",
        "df = df.copy()\n",
        "df.index = pd.to_datetime(df.index)\n",
        "df = df.sort_index()\n",
        "assert isinstance(df.index, pd.DatetimeIndex)\n",
        "```\n",
        "\n",
        "**Expected output / sanity checks**\n",
        "- `df.index.min(), df.index.max()` look reasonable\n",
        "- `df.index.is_monotonic_increasing` is `True`\n",
        "\n",
        "### 2) Resampling (frequency alignment)\n",
        "\n",
        "Resampling converts one frequency to another. Choose the aggregation rule intentionally.\n",
        "\n",
        "```python\n",
        "# month-end last value (end-of-period)\n",
        "df_me_last = df.resample(\"ME\").last()\n",
        "\n",
        "# month-end mean (average-of-period)\n",
        "df_me_mean = df.resample(\"ME\").mean()\n",
        "\n",
        "# quarter-end mean\n",
        "df_q_mean = df.resample(\"QE\").mean()\n",
        "```\n",
        "\n",
        "**Interpretation matters**\n",
        "- `.last()` treats end-of-period value as \u201cthe period\u2019s value.\u201d\n",
        "- `.mean()` treats the period average as \u201cthe period\u2019s value.\u201d\n",
        "\n",
        "### 3) Alignment and merging\n",
        "\n",
        "When joining series, always check missingness after the join:\n",
        "\n",
        "```python\n",
        "merged = df1.join(df2, how=\"outer\").sort_index()\n",
        "print(merged.isna().sum().sort_values(ascending=False).head(10))\n",
        "```\n",
        "\n",
        "### 4) Lags and rolling windows (watch for leakage!)\n",
        "\n",
        "```python\n",
        "# lag 1 period (past-only)\n",
        "df[\"x_lag1\"] = df[\"x\"].shift(1)\n",
        "\n",
        "# rolling mean using past values ending at t\n",
        "df[\"x_roll12\"] = df[\"x\"].rolling(12).mean()\n",
        "```\n",
        "\n",
        "**Leakage pitfalls**\n",
        "- `shift(-1)` uses the future.\n",
        "- `rolling(..., center=True)` uses the future.\n",
        "\n",
        "### 5) A quick workflow you should repeat\n",
        "\n",
        "1) Set and verify DatetimeIndex.\n",
        "2) Resample intentionally (mean vs last).\n",
        "3) Join and inspect missingness.\n",
        "4) Add lags/rolls (past-only).\n",
        "5) `dropna()` to build a clean modeling table.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"aggregate-monthly-quarterly\"></a>\n",
        "## Aggregate monthly -> quarterly\n",
        "\n",
        "### Goal\n",
        "Convert the month-end panel into a quarterly feature table.\n",
        "\n",
        "You will try two aggregation rules:\n",
        "- quarter-end value (`last`)\n",
        "- quarter-average value (`mean`)\n",
        "\n",
        "Then you will choose one (or keep both with suffixes).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Your Turn (1): Load inputs\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# TODO: Load the processed monthly panel (or fallback to sample)\n",
        "panel_path = PROCESSED_DIR / 'panel_monthly.csv'\n",
        "if panel_path.exists():\n",
        "    panel_m = pd.read_csv(panel_path, index_col=0, parse_dates=True)\n",
        "else:\n",
        "    panel_m = pd.read_csv(SAMPLE_DIR / 'panel_monthly_sample.csv', index_col=0, parse_dates=True)\n",
        "\n",
        "# TODO: Load quarterly GDP/label table from the previous notebook\n",
        "gdp_path = PROCESSED_DIR / 'gdp_quarterly.csv'\n",
        "if gdp_path.exists():\n",
        "    gdp_q = pd.read_csv(gdp_path, index_col=0, parse_dates=True)\n",
        "else:\n",
        "    gdp_q = pd.read_csv(SAMPLE_DIR / 'gdp_quarterly_sample.csv', index_col=0, parse_dates=True)\n",
        "\n",
        "panel_m.head(), gdp_q.head()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Your Turn (2): Aggregate (mean vs last)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "from src import macro\n",
        "\n",
        "# TODO: Build quarterly versions of the monthly predictors.\n",
        "# Hint: macro.monthly_to_quarterly(panel_m, how='mean'|'last')\n",
        "panel_q_last = ...\n",
        "panel_q_mean = ...\n",
        "\n",
        "# TODO: Compare them (e.g., correlation of each column)\n",
        "...\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Your Turn (3): Choose a quarterly feature table\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# TODO: Choose which aggregation to use for modeling.\n",
        "# Option A: use quarter-end values\n",
        "# Option B: use quarter averages\n",
        "# Option C: keep both by adding suffixes\n",
        "\n",
        "Xq = ...\n",
        "Xq.head()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Checkpoint (quarterly index alignment)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# TODO: Confirm both Xq and gdp_q use quarter-end timestamps.\n",
        "assert isinstance(Xq.index, pd.DatetimeIndex)\n",
        "assert isinstance(gdp_q.index, pd.DatetimeIndex)\n",
        "assert Xq.index.is_monotonic_increasing\n",
        "assert gdp_q.index.is_monotonic_increasing\n",
        "...\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"add-lags\"></a>\n",
        "## Add lags\n",
        "\n",
        "### Goal\n",
        "Add lagged quarterly predictors so the model only uses information available *before* the target period.\n",
        "\n",
        "Typical lags to try:\n",
        "- 1 quarter\n",
        "- 2 quarters\n",
        "- 4 quarters (one year)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Your Turn (1): Add lag features\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "from src import features\n",
        "\n",
        "# TODO: Add lag features for all columns in Xq\n",
        "# Hint: features.add_lag_features(Xq, columns=Xq.columns, lags=[...])\n",
        "Xq_lagged = ...\n",
        "\n",
        "# TODO: Drop rows with NaNs created by lags\n",
        "Xq_lagged = Xq_lagged.dropna().copy()\n",
        "Xq_lagged.head()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Checkpoint (no future lags)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# TODO: Confirm you used ONLY positive lags.\n",
        "# features.add_lag_features will raise if lags <= 0.\n",
        "...\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"merge-with-gdp-labels\"></a>\n",
        "## Merge with GDP/labels\n",
        "\n",
        "### Goal\n",
        "Join lagged predictors with GDP growth and the next-quarter recession target.\n",
        "\n",
        "Key idea:\n",
        "- predictors at time t\n",
        "- target at time t (which is recession at t+1)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Your Turn (1): Merge and build the final table\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# TODO: Join on the quarterly index.\n",
        "# Keep at least:\n",
        "# - gdp growth columns\n",
        "# - recession label\n",
        "# - target_recession_next_q\n",
        "# - lagged predictors\n",
        "\n",
        "df_q = ...\n",
        "\n",
        "# Drop rows with missing target or predictors\n",
        "df_q = df_q.dropna().copy()\n",
        "df_q.head()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Checkpoint (target alignment)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# TODO: Confirm the target is 0/1 and shifted correctly.\n",
        "assert set(df_q['target_recession_next_q'].unique()).issubset({0, 1})\n",
        "...\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"save-macro-quarterly-csv\"></a>\n",
        "## Save macro_quarterly.csv\n",
        "\n",
        "### Goal\n",
        "Write the final modeling table to `data/processed/macro_quarterly.csv`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Your Turn (1): Save + reload\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "out_path = PROCESSED_DIR / 'macro_quarterly.csv'\n",
        "out_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# TODO: Save df_q\n",
        "...\n",
        "\n",
        "# Reload for sanity\n",
        "df_reload = pd.read_csv(out_path, index_col=0, parse_dates=True)\n",
        "assert df_reload.shape == df_q.shape\n",
        "df_reload.tail()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"checkpoint-self-check\"></a>\n",
        "## Checkpoint (Self-Check)\n",
        "Run a few asserts and write 2-3 sentences summarizing what you verified.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Expected file: data/processed/macro_quarterly.csv\n",
        "# TODO: After saving your processed dataset, load it and run checks.\n",
        "# df = pd.read_csv(PROCESSED_DIR / 'your_file.csv', index_col=0, parse_dates=True)\n",
        "# assert df.index.is_monotonic_increasing\n",
        "# assert df.shape[0] > 20\n",
        "# print(df.dtypes)\n",
        "...\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Extensions (Optional)\n",
        "- Try one additional variant beyond the main path (different features, different split, different model).\n",
        "- Write down what improved, what got worse, and your hypothesis for why.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Reflection\n",
        "- What did you assume implicitly (about timing, availability, stationarity, or costs)?\n",
        "- If you had to ship this model, what would you monitor?\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"solutions-reference\"></a>\n",
        "## Solutions (Reference)\n",
        "\n",
        "Try the TODOs first. Use these only to unblock yourself or to compare approaches.\n",
        "\n",
        "<details><summary>Solution: Aggregate monthly -> quarterly</summary>\n",
        "\n",
        "_One possible approach. Your variable names may differ; align them with the notebook._\n",
        "\n",
        "```python\n",
        "# Reference solution for 03_build_macro_quarterly_features \u2014 Aggregate monthly -> quarterly\n",
        "import pandas as pd\n",
        "from src import macro\n",
        "\n",
        "panel_monthly = pd.read_csv(SAMPLE_DIR / 'panel_monthly_sample.csv', index_col=0, parse_dates=True)\n",
        "q_mean = macro.monthly_to_quarterly(panel_monthly, how='mean')\n",
        "q_last = macro.monthly_to_quarterly(panel_monthly, how='last')\n",
        "q_mean.head(), q_last.head()\n",
        "```\n",
        "\n",
        "</details>\n",
        "\n",
        "<details><summary>Solution: Add lags</summary>\n",
        "\n",
        "_One possible approach. Your variable names may differ; align them with the notebook._\n",
        "\n",
        "```python\n",
        "# Reference solution for 03_build_macro_quarterly_features \u2014 Add lags\n",
        "q = q_mean.copy()\n",
        "for col in q.columns:\n",
        "    for lag in [1, 2, 4]:\n",
        "        q[f'{col}_lag{lag}'] = q[col].shift(lag)\n",
        "q = q.dropna()\n",
        "```\n",
        "\n",
        "</details>\n",
        "\n",
        "<details><summary>Solution: Merge with GDP/labels</summary>\n",
        "\n",
        "_One possible approach. Your variable names may differ; align them with the notebook._\n",
        "\n",
        "```python\n",
        "# Reference solution for 03_build_macro_quarterly_features \u2014 Merge with GDP/labels\n",
        "gdp = pd.read_csv(SAMPLE_DIR / 'gdp_quarterly_sample.csv', index_col=0, parse_dates=True)\n",
        "df = q.join(gdp, how='inner').dropna()\n",
        "df.head()\n",
        "```\n",
        "\n",
        "</details>\n",
        "\n",
        "<details><summary>Solution: Save macro_quarterly.csv</summary>\n",
        "\n",
        "_One possible approach. Your variable names may differ; align them with the notebook._\n",
        "\n",
        "```python\n",
        "# Reference solution for 03_build_macro_quarterly_features \u2014 Save macro_quarterly.csv\n",
        "from src import data as data_utils\n",
        "data_utils.save_csv(df, PROCESSED_DIR / 'macro_quarterly.csv')\n",
        "print('saved', PROCESSED_DIR / 'macro_quarterly.csv')\n",
        "```\n",
        "\n",
        "</details>\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "python3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}