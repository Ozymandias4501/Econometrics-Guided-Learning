{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01a Random Effects and the Hausman Test\n",
    "\n",
    "When to use FE vs RE, and how to decide."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "- [Review: Fixed Effects recap](#review-fixed-effects-recap)\n",
    "- [Random Effects model](#random-effects-model)\n",
    "- [Hausman test](#hausman-test)\n",
    "- [Practical comparison](#practical-comparison)\n",
    "- [When to use which](#when-to-use-which)\n",
    "- [Checkpoint (Self-Check)](#checkpoint-self-check)\n",
    "- [Solutions (Reference)](#solutions-reference)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why This Notebook Matters\n",
    "Causal notebooks focus on **identification**: what would have to be true for a coefficient to represent a causal effect.\n",
    "In the previous notebook you estimated fixed effects models that sweep out all time-invariant unobserved heterogeneity.\n",
    "But FE comes at a cost: it throws away all between-entity variation and cannot estimate coefficients on time-invariant regressors.\n",
    "Random Effects (RE) keeps that variation and is more efficient -- **if** its key assumption holds.\n",
    "\n",
    "You will practice:\n",
    "- fitting a Random Effects model with `linearmodels`,\n",
    "- implementing the Hausman test from scratch,\n",
    "- comparing FE and RE coefficient estimates side-by-side,\n",
    "- building a decision framework for when to use which estimator.\n",
    "\n",
    "\n",
    "## Prerequisites (Quick Self-Check)\n",
    "- Completed notebook `01_panel_fixed_effects_clustered_se`.\n",
    "- Understanding of entity fixed effects and the within estimator.\n",
    "- Basic familiarity with panels (same unit over time) and the idea of identification assumptions.\n",
    "\n",
    "## What You Will Produce\n",
    "- (no file output; learning/analysis notebook)\n",
    "\n",
    "## Success Criteria\n",
    "- You can explain what you built and why each step exists.\n",
    "- You can run your work end-to-end without undefined variables.\n",
    "- You can articulate the core assumption difference between FE and RE.\n",
    "- You can implement and interpret a Hausman test.\n",
    "\n",
    "## Common Pitfalls\n",
    "- Running cells top-to-bottom without reading the instructions.\n",
    "- Leaving `...` placeholders in code cells.\n",
    "- Treating regression output as causal without stating identification assumptions.\n",
    "- Confusing \"more efficient\" with \"more correct\" -- RE efficiency only matters if the assumption holds.\n",
    "- Using non-clustered SE when shocks are correlated within groups (e.g., states).\n",
    "\n",
    "## Quick Fixes (When You Get Stuck)\n",
    "- If you see `ModuleNotFoundError`, re-run the bootstrap cell and restart the kernel; make sure `PROJECT_ROOT` is the repo root.\n",
    "- If a `data/processed/*` file is missing, either run the matching build script (see guide) or use the notebook's `data/sample/*` fallback.\n",
    "- If results look \"too good,\" suspect leakage; re-check shifts, rolling windows, and time splits.\n",
    "- If a model errors, check dtypes (`astype(float)`) and missingness (`dropna()` on required columns).\n",
    "\n",
    "## Matching Guide\n",
    "- `docs/guides/07_causal/01_panel_fixed_effects_clustered_se.md`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How To Use This Notebook\n",
    "- Work section-by-section; don't skip the markdown.\n",
    "- Most code cells are incomplete on purpose: replace TODOs and `...`, then run.\n",
    "- After each section, write 2--4 sentences answering the interpretation prompts (what changed, why it matters).\n",
    "- Prefer `data/processed/*` if you have built the real datasets; otherwise use the bundled `data/sample/*` fallbacks.\n",
    "- Use the **Checkpoint (Self-Check)** section to catch mistakes early.\n",
    "- Use **Solutions (Reference)** only to unblock yourself; then re-implement without looking.\n",
    "- Use the matching guide (`docs/guides/07_causal/01_panel_fixed_effects_clustered_se.md`) for the math, assumptions, and deeper context.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"environment-bootstrap\"></a>\n",
    "## Environment Bootstrap\n",
    "Run this cell first. It makes the repo importable and defines common directories.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "\n",
    "def find_repo_root(start: Path) -> Path:\n",
    "    p = start\n",
    "    for _ in range(8):\n",
    "        if (p / 'src').exists() and (p / 'docs').exists():\n",
    "            return p\n",
    "        p = p.parent\n",
    "    raise RuntimeError('Could not find repo root. Start Jupyter from the repo root.')\n",
    "\n",
    "\n",
    "PROJECT_ROOT = find_repo_root(Path.cwd())\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.append(str(PROJECT_ROOT))\n",
    "\n",
    "DATA_DIR = PROJECT_ROOT / 'data'\n",
    "RAW_DIR = DATA_DIR / 'raw'\n",
    "PROCESSED_DIR = DATA_DIR / 'processed'\n",
    "SAMPLE_DIR = DATA_DIR / 'sample'\n",
    "\n",
    "PROJECT_ROOT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal\n",
    "Compare Fixed Effects and Random Effects estimators on the same county-year panel.\n",
    "Then use the Hausman test to decide which is appropriate.\n",
    "\n",
    "Key question: **is the unobserved county-level heterogeneity correlated with the regressors?**\n",
    "- If yes: FE is consistent, RE is not.\n",
    "- If no: both are consistent, but RE is more efficient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"review-fixed-effects-recap\"></a>\n",
    "## Review: Fixed Effects recap\n",
    "\n",
    "### Background\n",
    "In the previous notebook (`01_panel_fixed_effects_clustered_se`), you estimated models of the form:\n",
    "\n",
    "$$\n",
    "Y_{it} = X_{it}'\\beta + \\alpha_i + \\gamma_t + \\varepsilon_{it}\n",
    "$$\n",
    "\n",
    "where $\\alpha_i$ are entity (county) fixed effects and $\\gamma_t$ are time (year) fixed effects.\n",
    "\n",
    "The **key assumption** behind FE: unobserved heterogeneity $\\alpha_i$ may be **correlated** with the regressors $X_{it}$.\n",
    "FE handles this by demeaning within each entity, which eliminates $\\alpha_i$ entirely.\n",
    "\n",
    "**Cost of FE**:\n",
    "- Cannot estimate coefficients on time-invariant regressors (they get absorbed).\n",
    "- Uses only within-entity variation, discarding between-entity variation.\n",
    "- Less efficient than RE when the RE assumption actually holds.\n",
    "\n",
    "### What you should see\n",
    "- A loaded panel with MultiIndex `(fips, year)`.\n",
    "- An entity FE regression result to use as a baseline for comparison.\n",
    "\n",
    "### Interpretation prompts\n",
    "- What does entity demeaning do to a time-invariant variable?\n",
    "- Why is FE considered the \"safe default\" in applied work?\n",
    "\n",
    "### Goal\n",
    "Load the panel data and fit an entity FE model as a baseline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your Turn: Load panel and fit entity FE baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "path = PROCESSED_DIR / 'census_county_panel.csv'\n",
    "if path.exists():\n",
    "    df = pd.read_csv(path)\n",
    "else:\n",
    "    df = pd.read_csv(SAMPLE_DIR / 'census_county_panel_sample.csv')\n",
    "\n",
    "# TODO: Ensure fips/year exist and build a MultiIndex\n",
    "df['fips'] = df['fips'].astype(str)\n",
    "df['year'] = df['year'].astype(int)\n",
    "df = df.set_index(['fips', 'year'], drop=False).sort_index()\n",
    "\n",
    "# Starter transforms\n",
    "df['log_income'] = np.log(df['B19013_001E'].astype(float))\n",
    "df['log_rent'] = np.log(df['B25064_001E'].astype(float))\n",
    "\n",
    "df[['poverty_rate', 'unemployment_rate', 'log_income', 'log_rent']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.causal import fit_twfe_panel_ols\n",
    "\n",
    "y_col = 'poverty_rate'\n",
    "x_cols = ['log_income', 'unemployment_rate']\n",
    "\n",
    "# TODO: Fit entity FE model (entity_effects=True, time_effects=False for pure entity FE)\n",
    "res_fe = fit_twfe_panel_ols(\n",
    "    df,\n",
    "    y_col=y_col,\n",
    "    x_cols=x_cols,\n",
    "    entity_effects=True,\n",
    "    time_effects=False,\n",
    ")\n",
    "print(res_fe.summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"random-effects-model\"></a>\n",
    "## Random Effects model\n",
    "\n",
    "### Background\n",
    "The Random Effects (RE) model assumes:\n",
    "\n",
    "$$\n",
    "Y_{it} = X_{it}'\\beta + \\alpha_i + \\varepsilon_{it}, \\quad \\mathrm{Cov}(\\alpha_i, X_{it}) = 0\n",
    "$$\n",
    "\n",
    "The critical difference from FE: RE assumes the unobserved entity effect $\\alpha_i$ is **uncorrelated** with the regressors.\n",
    "\n",
    "Under this assumption, RE is a weighted average of the between and within estimators, and is **more efficient** than FE (smaller standard errors) because it uses both within-entity and between-entity variation.\n",
    "\n",
    "RE uses a GLS-type transformation: it partially demeans the data (by a fraction $\\theta$, estimated from the variance components) rather than fully demeaning like FE.\n",
    "\n",
    "Use `linearmodels.panel.RandomEffects`:\n",
    "```python\n",
    "from linearmodels.panel import RandomEffects\n",
    "res_re = RandomEffects(y, X).fit()\n",
    "```\n",
    "\n",
    "### What you should see\n",
    "- A `RandomEffects` summary with coefficient estimates.\n",
    "- Standard errors that are typically **smaller** than the FE standard errors (because RE is more efficient under its assumption).\n",
    "\n",
    "### Interpretation prompts\n",
    "- In words, what does $\\mathrm{Cov}(\\alpha_i, X_{it}) = 0$ mean for this county panel?\n",
    "- Why would RE standard errors be smaller than FE standard errors if the assumption holds?\n",
    "\n",
    "### Goal\n",
    "Fit a Random Effects model on the same outcome and regressors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your Turn: Fit Random Effects model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from linearmodels.panel import RandomEffects\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Build modeling table (drop missing, ensure float types)\n",
    "tmp = df[[y_col] + x_cols].dropna().copy()\n",
    "y = tmp[y_col].astype(float)\n",
    "X = tmp[x_cols].astype(float)\n",
    "\n",
    "# TODO: Fit the RandomEffects model and print the summary\n",
    "# Hint: RandomEffects(y, X).fit()\n",
    "res_re = ...\n",
    "print(res_re.summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"hausman-test\"></a>\n",
    "## Hausman test\n",
    "\n",
    "### Background\n",
    "The Hausman test checks whether the RE assumption ($\\mathrm{Cov}(\\alpha_i, X_{it}) = 0$) is plausible.\n",
    "\n",
    "**Intuition**: Under $H_0$ (RE is consistent), both FE and RE are consistent, but RE is more efficient.\n",
    "Under the alternative, FE is consistent but RE is not. So the coefficients should differ systematically.\n",
    "\n",
    "**Test statistic**:\n",
    "$$\n",
    "H = (\\hat{\\beta}_{FE} - \\hat{\\beta}_{RE})' \\left[\\widehat{\\mathrm{Var}}(\\hat{\\beta}_{FE}) - \\widehat{\\mathrm{Var}}(\\hat{\\beta}_{RE})\\right]^{-1} (\\hat{\\beta}_{FE} - \\hat{\\beta}_{RE})\n",
    "$$\n",
    "\n",
    "Under $H_0$, $H \\sim \\chi^2_k$ where $k$ is the number of regressors.\n",
    "\n",
    "**Decision rule**:\n",
    "- If $p < 0.05$: reject $H_0$ -- use FE (RE assumption likely violated).\n",
    "- If $p \\geq 0.05$: fail to reject $H_0$ -- RE may be appropriate.\n",
    "\n",
    "**Important caveat**: failing to reject does not prove the RE assumption is true. It could just be low power.\n",
    "\n",
    "### What you should see\n",
    "- A manually computed Hausman test statistic.\n",
    "- A p-value from the chi-squared distribution.\n",
    "- A clear conclusion: FE or RE.\n",
    "\n",
    "### Interpretation prompts\n",
    "- What does it mean, economically, if the test rejects?\n",
    "- Why might you still prefer FE even if the test fails to reject?\n",
    "\n",
    "### Goal\n",
    "Implement the Hausman test manually and interpret the result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your Turn: Manual Hausman test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from linearmodels.panel import PanelOLS, RandomEffects\n",
    "from scipy import stats\n",
    "\n",
    "# --- Step 1: Fit FE and RE on the same modeling table ---\n",
    "# We need both models estimated on identical observations.\n",
    "tmp = df[[y_col] + x_cols].dropna().copy()\n",
    "y = tmp[y_col].astype(float)\n",
    "X = tmp[x_cols].astype(float)\n",
    "\n",
    "# FE (entity effects, no constant -- FE absorbs it)\n",
    "res_fe_h = PanelOLS(y, X, entity_effects=True).fit()\n",
    "\n",
    "# RE\n",
    "res_re_h = RandomEffects(y, X).fit()\n",
    "\n",
    "# --- Step 2: Extract coefficients and covariance matrices ---\n",
    "# TODO: Get the coefficient vectors (as numpy arrays)\n",
    "b_fe = ...  # Hint: res_fe_h.params.values\n",
    "b_re = ...  # Hint: res_re_h.params.values\n",
    "\n",
    "# TODO: Get the covariance matrices (as numpy arrays)\n",
    "V_fe = ...  # Hint: res_fe_h.cov.values\n",
    "V_re = ...  # Hint: res_re_h.cov.values\n",
    "\n",
    "# --- Step 3: Align coefficients ---\n",
    "# RE may include a constant that FE does not. We compare only the\n",
    "# coefficients that appear in BOTH models (the x_cols regressors).\n",
    "common = [c for c in res_fe_h.params.index if c in res_re_h.params.index]\n",
    "b_fe = res_fe_h.params[common].values\n",
    "b_re = res_re_h.params[common].values\n",
    "V_fe = res_fe_h.cov.loc[common, common].values\n",
    "V_re = res_re_h.cov.loc[common, common].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 4: Compute the Hausman test statistic ---\n",
    "# H = (b_fe - b_re)' [V_fe - V_re]^{-1} (b_fe - b_re)\n",
    "\n",
    "# TODO: Compute the difference in coefficients\n",
    "b_diff = ...  # Hint: b_fe - b_re\n",
    "\n",
    "# TODO: Compute the difference in variance matrices\n",
    "V_diff = ...  # Hint: V_fe - V_re\n",
    "\n",
    "# TODO: Compute the test statistic\n",
    "# Hint: Use np.linalg.inv() for the matrix inverse\n",
    "# H = b_diff @ np.linalg.inv(V_diff) @ b_diff\n",
    "H = ...\n",
    "\n",
    "# --- Step 5: Compute p-value ---\n",
    "# TODO: degrees of freedom = number of common coefficients\n",
    "k = ...  # Hint: len(common)\n",
    "p_value = ...  # Hint: 1 - stats.chi2.cdf(H, df=k)\n",
    "\n",
    "print(f'Hausman test statistic: {H:.4f}')\n",
    "print(f'Degrees of freedom:     {k}')\n",
    "print(f'p-value:                {p_value:.6f}')\n",
    "print()\n",
    "if p_value < 0.05:\n",
    "    print('Reject H0: RE assumption likely violated. Use FE.')\n",
    "else:\n",
    "    print('Fail to reject H0: RE may be appropriate (but FE is still safe).')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"practical-comparison\"></a>\n",
    "## Practical comparison\n",
    "\n",
    "### Background\n",
    "Before relying on the Hausman test alone, it is useful to look at the FE and RE estimates side-by-side.\n",
    "If the coefficient estimates are very close, the choice between FE and RE may not matter much in practice.\n",
    "If they diverge substantially, that is itself a signal that unobserved heterogeneity may be correlated with the regressors.\n",
    "\n",
    "### What you should see\n",
    "- A table comparing FE vs RE: coefficients, standard errors, and the difference.\n",
    "- A visual sense of how much the estimates diverge.\n",
    "\n",
    "### Interpretation prompts\n",
    "- For which regressor do FE and RE disagree the most? What story could explain that?\n",
    "- If RE standard errors are smaller, does that automatically make RE better? Why or why not?\n",
    "\n",
    "### Goal\n",
    "Build a side-by-side comparison table of FE vs RE estimates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your Turn: Compare FE and RE side-by-side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# TODO: Build a comparison DataFrame with columns:\n",
    "#   'FE_coef', 'RE_coef', 'FE_se', 'RE_se', 'coef_diff'\n",
    "# Use only the common coefficients (the regressors shared by both models).\n",
    "\n",
    "comparison = pd.DataFrame({\n",
    "    'FE_coef': ...,   # Hint: res_fe_h.params[common]\n",
    "    'RE_coef': ...,   # Hint: res_re_h.params[common]\n",
    "    'FE_se':   ...,   # Hint: res_fe_h.std_errors[common]\n",
    "    'RE_se':   ...,   # Hint: res_re_h.std_errors[common]\n",
    "})\n",
    "comparison['coef_diff'] = comparison['FE_coef'] - comparison['RE_coef']\n",
    "\n",
    "comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# TODO: Create a visual comparison (bar chart or coefficient plot)\n",
    "# Hint: Plot FE and RE coefficients side by side with error bars\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "x_pos = np.arange(len(common))\n",
    "width = 0.35\n",
    "\n",
    "ax.bar(x_pos - width/2, ..., width, yerr=..., label='FE', alpha=0.8, capsize=4)\n",
    "ax.bar(x_pos + width/2, ..., width, yerr=..., label='RE', alpha=0.8, capsize=4)\n",
    "\n",
    "ax.set_xticks(x_pos)\n",
    "ax.set_xticklabels(common, rotation=15)\n",
    "ax.set_ylabel('Coefficient estimate')\n",
    "ax.set_title('FE vs RE coefficient estimates (with SE error bars)')\n",
    "ax.legend()\n",
    "ax.axhline(0, color='gray', linestyle='--', linewidth=0.8)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"when-to-use-which\"></a>\n",
    "## When to use which\n",
    "\n",
    "### Decision framework\n",
    "\n",
    "| Criterion | Fixed Effects (FE) | Random Effects (RE) |\n",
    "|---|---|---|\n",
    "| **Core assumption** | $\\alpha_i$ may be correlated with $X_{it}$ | $\\mathrm{Cov}(\\alpha_i, X_{it}) = 0$ |\n",
    "| **Consistency** | Always consistent (under strict exogeneity of $\\varepsilon$) | Only consistent if the uncorrelation assumption holds |\n",
    "| **Efficiency** | Less efficient (uses only within variation) | More efficient (uses within + between variation) |\n",
    "| **Time-invariant regressors** | Cannot estimate (absorbed by FE) | Can estimate |\n",
    "| **Hausman test rejects** | Use FE | Do not use RE |\n",
    "| **Hausman test fails to reject** | Still safe to use FE | RE is a valid (and more efficient) choice |\n",
    "\n",
    "### Practical guidance\n",
    "\n",
    "1. **FE is the safe default.** In most applied economics, researchers worry about endogeneity (omitted variables correlated with regressors). FE is robust to this.\n",
    "\n",
    "2. **RE is more efficient** if you genuinely believe that unobserved county-level factors (culture, geography, institutions) are uncorrelated with your regressors. This is a strong assumption.\n",
    "\n",
    "3. **In practice**: most applied work defaults to FE when there is any worry about endogeneity. RE is more common in fields where the uncorrelation assumption is more defensible (e.g., randomized experiments with clustering, some clinical trial designs).\n",
    "\n",
    "4. **The Hausman test is a guide, not a guarantee.** Failure to reject could reflect low power rather than a true lack of correlation. When in doubt, report both and discuss.\n",
    "\n",
    "5. **Mundlak (1978) compromise**: add group means of time-varying regressors to the RE model. This nests FE within RE and can be tested directly. This is an extension for further study."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your Turn: Summarize your decision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Write 3-5 sentences summarizing your results.\n",
    "# Address:\n",
    "# 1. What did the Hausman test say?\n",
    "# 2. How different were the FE and RE coefficients?\n",
    "# 3. Which estimator would you recommend for this panel and why?\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"checkpoint-self-check\"></a>\n",
    "## Checkpoint (Self-Check)\n",
    "Run a few asserts and write 2-3 sentences summarizing what you verified.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Expected output: (see notebook front matter)\n",
    "# TODO: Verify your panel indexing and model results.\n",
    "# Example (adjust variable names):\n",
    "# assert isinstance(df.index, pd.MultiIndex)\n",
    "# assert df.index.names[:2] == ['fips', 'year']\n",
    "# assert res_fe_h is not None, 'FE model not fitted'\n",
    "# assert res_re_h is not None, 'RE model not fitted'\n",
    "# assert H > 0, 'Hausman statistic should be positive'\n",
    "# assert 0 <= p_value <= 1, 'p-value out of range'\n",
    "# assert len(common) == len(x_cols), 'Common coefficients should match x_cols'\n",
    "#\n",
    "# TODO: Write 2-3 sentences:\n",
    "# - What is the key assumption you are testing with the Hausman test?\n",
    "# - What did you conclude?\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extensions (Optional)\n",
    "- Try one additional variant beyond the main path (different features, different split, different model).\n",
    "- Write down what improved, what got worse, and your hypothesis for why.\n",
    "\n",
    "Suggestions:\n",
    "- **Mundlak approach**: Add within-entity means of time-varying regressors to the RE model. Does the Hausman test result change? (This is the Mundlak (1978) device that nests FE within RE.)\n",
    "- **Different regressors**: Swap in `log_rent` or add additional controls. How sensitive is the Hausman result?\n",
    "- **Two-way FE vs entity-only FE**: Compare the Hausman test using entity-only FE vs TWFE (with time effects). Which comparison is more appropriate?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reflection\n",
    "- What did you assume implicitly (about timing, availability, stationarity, or costs)?\n",
    "- If you had to ship this model, what would you monitor?\n",
    "- Under what real-world conditions might you prefer RE over FE despite the Hausman test?\n",
    "- How does the FE vs RE decision relate to the broader theme of the bias-variance tradeoff?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"solutions-reference\"></a>\n",
    "## Solutions (Reference)\n",
    "\n",
    "Try the TODOs first. Use these only to unblock yourself or to compare approaches.\n",
    "\n",
    "<details><summary>Solution: Load panel and fit entity FE baseline</summary>\n",
    "\n",
    "_One possible approach. Your variable names may differ; align them with the notebook._\n",
    "\n",
    "```python\n",
    "# Reference solution for 01a_random_effects_hausman -- Load panel and FE baseline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from src.causal import fit_twfe_panel_ols\n",
    "\n",
    "path = PROCESSED_DIR / 'census_county_panel.csv'\n",
    "if path.exists():\n",
    "    df = pd.read_csv(path)\n",
    "else:\n",
    "    df = pd.read_csv(SAMPLE_DIR / 'census_county_panel_sample.csv')\n",
    "\n",
    "df['fips'] = df['fips'].astype(str)\n",
    "df['year'] = df['year'].astype(int)\n",
    "df = df.set_index(['fips', 'year'], drop=False).sort_index()\n",
    "\n",
    "df['log_income'] = np.log(df['B19013_001E'].astype(float))\n",
    "df['log_rent'] = np.log(df['B25064_001E'].astype(float))\n",
    "\n",
    "y_col = 'poverty_rate'\n",
    "x_cols = ['log_income', 'unemployment_rate']\n",
    "\n",
    "res_fe = fit_twfe_panel_ols(\n",
    "    df,\n",
    "    y_col=y_col,\n",
    "    x_cols=x_cols,\n",
    "    entity_effects=True,\n",
    "    time_effects=False,\n",
    ")\n",
    "print(res_fe.summary)\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "<details><summary>Solution: Fit Random Effects model</summary>\n",
    "\n",
    "_One possible approach. Your variable names may differ; align them with the notebook._\n",
    "\n",
    "```python\n",
    "# Reference solution for 01a_random_effects_hausman -- Random Effects model\n",
    "from linearmodels.panel import RandomEffects\n",
    "\n",
    "tmp = df[[y_col] + x_cols].dropna().copy()\n",
    "y = tmp[y_col].astype(float)\n",
    "X = tmp[x_cols].astype(float)\n",
    "\n",
    "res_re = RandomEffects(y, X).fit()\n",
    "print(res_re.summary)\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "<details><summary>Solution: Manual Hausman test</summary>\n",
    "\n",
    "_One possible approach. Your variable names may differ; align them with the notebook._\n",
    "\n",
    "```python\n",
    "# Reference solution for 01a_random_effects_hausman -- Hausman test\n",
    "from linearmodels.panel import PanelOLS, RandomEffects\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "\n",
    "tmp = df[[y_col] + x_cols].dropna().copy()\n",
    "y = tmp[y_col].astype(float)\n",
    "X = tmp[x_cols].astype(float)\n",
    "\n",
    "res_fe_h = PanelOLS(y, X, entity_effects=True).fit()\n",
    "res_re_h = RandomEffects(y, X).fit()\n",
    "\n",
    "# Align on common coefficients\n",
    "common = [c for c in res_fe_h.params.index if c in res_re_h.params.index]\n",
    "b_fe = res_fe_h.params[common].values\n",
    "b_re = res_re_h.params[common].values\n",
    "V_fe = res_fe_h.cov.loc[common, common].values\n",
    "V_re = res_re_h.cov.loc[common, common].values\n",
    "\n",
    "b_diff = b_fe - b_re\n",
    "V_diff = V_fe - V_re\n",
    "H = b_diff @ np.linalg.inv(V_diff) @ b_diff\n",
    "\n",
    "k = len(common)\n",
    "p_value = 1 - stats.chi2.cdf(H, df=k)\n",
    "\n",
    "print(f'Hausman test statistic: {H:.4f}')\n",
    "print(f'Degrees of freedom:     {k}')\n",
    "print(f'p-value:                {p_value:.6f}')\n",
    "print()\n",
    "if p_value < 0.05:\n",
    "    print('Reject H0: RE assumption likely violated. Use FE.')\n",
    "else:\n",
    "    print('Fail to reject H0: RE may be appropriate (but FE is still safe).')\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "<details><summary>Solution: Compare FE and RE side-by-side</summary>\n",
    "\n",
    "_One possible approach. Your variable names may differ; align them with the notebook._\n",
    "\n",
    "```python\n",
    "# Reference solution for 01a_random_effects_hausman -- Practical comparison\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "comparison = pd.DataFrame({\n",
    "    'FE_coef': res_fe_h.params[common],\n",
    "    'RE_coef': res_re_h.params[common],\n",
    "    'FE_se':   res_fe_h.std_errors[common],\n",
    "    'RE_se':   res_re_h.std_errors[common],\n",
    "})\n",
    "comparison['coef_diff'] = comparison['FE_coef'] - comparison['RE_coef']\n",
    "print(comparison)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "x_pos = np.arange(len(common))\n",
    "width = 0.35\n",
    "\n",
    "ax.bar(x_pos - width/2, comparison['FE_coef'], width,\n",
    "       yerr=comparison['FE_se'], label='FE', alpha=0.8, capsize=4)\n",
    "ax.bar(x_pos + width/2, comparison['RE_coef'], width,\n",
    "       yerr=comparison['RE_se'], label='RE', alpha=0.8, capsize=4)\n",
    "\n",
    "ax.set_xticks(x_pos)\n",
    "ax.set_xticklabels(common, rotation=15)\n",
    "ax.set_ylabel('Coefficient estimate')\n",
    "ax.set_title('FE vs RE coefficient estimates (with SE error bars)')\n",
    "ax.legend()\n",
    "ax.axhline(0, color='gray', linestyle='--', linewidth=0.8)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "<details><summary>Solution: Summarize your decision</summary>\n",
    "\n",
    "_One possible approach._\n",
    "\n",
    "```python\n",
    "# Example summary (replace with your own words):\n",
    "#\n",
    "# The Hausman test statistic was [value] with p-value [value].\n",
    "# Since we [reject / fail to reject] H0, this suggests that the\n",
    "# unobserved county effects [are / may not be] correlated with\n",
    "# the regressors (log_income, unemployment_rate).\n",
    "#\n",
    "# The FE and RE coefficients [were close / diverged], particularly\n",
    "# for [regressor]. This is consistent with [the Hausman result].\n",
    "#\n",
    "# For this panel, I would recommend [FE / RE] because [reasoning].\n",
    "# In general, FE is the safer default for observational county data\n",
    "# where unobserved county characteristics (geography, institutions)\n",
    "# are plausibly correlated with income and employment.\n",
    "```\n",
    "\n",
    "</details>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbformat_minor": 4,
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}