{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02 Difference-in-Differences + Event Study\n",
    "\n",
    "TWFE DiD and event studies with synthetic adoption and diagnostics.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "- [Synthetic adoption + treatment](#synthetic-adoption-treatment)\n",
    "- [TWFE DiD](#twfe-did)\n",
    "- [Event study (leads/lags)](#event-study-leads-lags)\n",
    "- [Diagnostics: pre-trends + placebo](#diagnostics-pre-trends-placebo)\n",
    "- [Checkpoint (Self-Check)](#checkpoint-self-check)\n",
    "- [Solutions (Reference)](#solutions-reference)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why This Notebook Matters\n",
    "Causal notebooks focus on **identification**: what would have to be true for a coefficient to represent a causal effect.\n",
    "You will practice:\n",
    "- building a county-year panel,\n",
    "- fixed effects (TWFE),\n",
    "- clustered standard errors,\n",
    "- DiD + event studies,\n",
    "- IV/2SLS.\n",
    "\n",
    "\n",
    "## Prerequisites (Quick Self-Check)\n",
    "- Completed Part 02 (regression + robust SE).\n",
    "- Basic familiarity with panels (same unit over time) and the idea of identification assumptions.\n",
    "\n",
    "## What You Will Produce\n",
    "- (no file output; learning/analysis notebook)\n",
    "\n",
    "## Success Criteria\n",
    "- You can explain what you built and why each step exists.\n",
    "- You can run your work end-to-end without undefined variables.\n",
    "\n",
    "## Common Pitfalls\n",
    "- Running cells top-to-bottom without reading the instructions.\n",
    "- Leaving `...` placeholders in code cells.\n",
    "- Treating regression output as causal without stating identification assumptions.\n",
    "- Using non-clustered SE when shocks are correlated within groups (e.g., states).\n",
    "\n",
    "## Quick Fixes (When You Get Stuck)\n",
    "- If you see `ModuleNotFoundError`, re-run the bootstrap cell and restart the kernel; make sure `PROJECT_ROOT` is the repo root.\n",
    "- If a `data/processed/*` file is missing, either run the matching build script (see guide) or use the notebook’s `data/sample/*` fallback.\n",
    "- If results look “too good,” suspect leakage; re-check shifts, rolling windows, and time splits.\n",
    "- If a model errors, check dtypes (`astype(float)`) and missingness (`dropna()` on required columns).\n",
    "\n",
    "## Matching Guide\n",
    "- `docs/guides/07_causal/02_difference_in_differences_event_study.md`\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How To Use This Notebook\n",
    "- Work section-by-section; don’t skip the markdown.\n",
    "- Most code cells are incomplete on purpose: replace TODOs and `...`, then run.\n",
    "- After each section, write 2–4 sentences answering the interpretation prompts (what changed, why it matters).\n",
    "- Prefer `data/processed/*` if you have built the real datasets; otherwise use the bundled `data/sample/*` fallbacks.\n",
    "- Use the **Checkpoint (Self-Check)** section to catch mistakes early.\n",
    "- Use **Solutions (Reference)** only to unblock yourself; then re-implement without looking.\n",
    "- Use the matching guide (`docs/guides/07_causal/02_difference_in_differences_event_study.md`) for the math, assumptions, and deeper context.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"environment-bootstrap\"></a>\n",
    "## Environment Bootstrap\n",
    "Run this cell first. It makes the repo importable and defines common directories.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "\n",
    "def find_repo_root(start: Path) -> Path:\n",
    "    p = start\n",
    "    for _ in range(8):\n",
    "        if (p / 'src').exists() and (p / 'docs').exists():\n",
    "            return p\n",
    "        p = p.parent\n",
    "    raise RuntimeError('Could not find repo root. Start Jupyter from the repo root.')\n",
    "\n",
    "\n",
    "PROJECT_ROOT = find_repo_root(Path.cwd())\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.append(str(PROJECT_ROOT))\n",
    "\n",
    "DATA_DIR = PROJECT_ROOT / 'data'\n",
    "RAW_DIR = DATA_DIR / 'raw'\n",
    "PROCESSED_DIR = DATA_DIR / 'processed'\n",
    "SAMPLE_DIR = DATA_DIR / 'sample'\n",
    "\n",
    "PROJECT_ROOT\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal\n",
    "Practice DiD and event studies using:\n",
    "- a real county-year outcome (poverty rate)\n",
    "- a **synthetic**, deterministic adoption schedule by state\n",
    "- a **semi-synthetic** outcome with a known injected treatment effect\n",
    "\n",
    "This is a method exercise, not a real policy evaluation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Primer: Panel + IV regression with `linearmodels` (FE, clustered SE, 2SLS)\n",
    "\n",
    "This repo uses:\n",
    "- `statsmodels` for classic OLS inference patterns, and\n",
    "- `linearmodels` for **panel fixed effects** and **instrumental variables** (IV/2SLS).\n",
    "\n",
    "The goal of this primer is to make you productive quickly (with the *minimum* theory needed to use the tools correctly). Deep math lives in the guides.\n",
    "\n",
    "### Why `linearmodels`?\n",
    "\n",
    "`linearmodels` provides clean APIs for:\n",
    "- `PanelOLS`: fixed effects / TWFE\n",
    "- `IV2SLS`: two-stage least squares\n",
    "\n",
    "and it handles some panel-specific details (like absorbing FE) more naturally than `statsmodels`.\n",
    "\n",
    "### Panel data shape (the #1 requirement)\n",
    "\n",
    "Most panel estimators expect a **MultiIndex**:\n",
    "- level 0: entity (e.g., county `fips`)\n",
    "- level 1: time (e.g., `year`)\n",
    "\n",
    "```python\n",
    "# df has columns: fips, year, y, x1, x2, state, ...\n",
    "df = df.copy()\n",
    "df[\"fips\"] = df[\"fips\"].astype(str)\n",
    "df[\"year\"] = df[\"year\"].astype(int)\n",
    "df = df.set_index([\"fips\", \"year\"]).sort_index()\n",
    "```\n",
    "\n",
    "**Expected output / sanity check**\n",
    "- `df.index.nlevels == 2`\n",
    "- `df.index.is_monotonic_increasing` is `True`\n",
    "- no duplicate index pairs: `df.index.duplicated().any()` is `False`\n",
    "\n",
    "### TWFE model (PanelOLS)\n",
    "\n",
    "Econometric form:\n",
    "\n",
    "$$\n",
    "Y_{it} = X_{it}'\\\\beta + \\\\alpha_i + \\\\gamma_t + \\\\varepsilon_{it}\n",
    "$$\n",
    "\n",
    "In code:\n",
    "\n",
    "```python\n",
    "from linearmodels.panel import PanelOLS\n",
    "import statsmodels.api as sm\n",
    "\n",
    "y = df[\"y\"].astype(float)\n",
    "X = df[[\"x1\", \"x2\"]].astype(float)\n",
    "X = sm.add_constant(X, has_constant=\"add\")\n",
    "\n",
    "res = PanelOLS(y, X, entity_effects=True, time_effects=True).fit(cov_type=\"robust\")\n",
    "print(res.summary)\n",
    "```\n",
    "\n",
    "### Clustered SE (common in applied panel/DiD work)\n",
    "\n",
    "If errors are correlated within clusters (e.g., state-level shocks), use clustered SE:\n",
    "\n",
    "```python\n",
    "clusters = df[\"state\"]  # must align row-for-row with y/X index\n",
    "\n",
    "res_cl = PanelOLS(y, X, entity_effects=True, time_effects=True).fit(\n",
    "  cov_type=\"clustered\",\n",
    "  clusters=clusters,\n",
    ")\n",
    "```\n",
    "\n",
    "**Expected output / sanity check**\n",
    "- clustered SE are often larger than robust SE (not guaranteed, but common)\n",
    "- always report the number of clusters: `clusters.nunique()`\n",
    "\n",
    "### IV / 2SLS (IV2SLS)\n",
    "\n",
    "Structural equation (endogeneity motivation):\n",
    "$$\n",
    "Y = \\\\beta X + W'\\\\delta + u, \\\\quad \\\\mathrm{Cov}(X,u)\\\\neq 0\n",
    "$$\n",
    "\n",
    "In code (one endogenous regressor):\n",
    "\n",
    "```python\n",
    "from linearmodels.iv import IV2SLS\n",
    "import statsmodels.api as sm\n",
    "\n",
    "y = df[\"y\"].astype(float)\n",
    "endog = df[[\"x_endog\"]].astype(float)\n",
    "exog = sm.add_constant(df[[\"x_exog1\", \"x_exog2\"]].astype(float), has_constant=\"add\")\n",
    "instr = df[[\"z1\", \"z2\"]].astype(float)\n",
    "\n",
    "res_iv = IV2SLS(y, exog, endog, instr).fit(cov_type=\"robust\")\n",
    "print(res_iv.summary)\n",
    "```\n",
    "\n",
    "**Expected output / sanity check**\n",
    "- `res_iv.params` contains coefficients for exog + endogenous variables\n",
    "- `res_iv.first_stage` (if printed) shows instrument relevance diagnostics\n",
    "\n",
    "### Common pitfalls (and quick fixes)\n",
    "\n",
    "- **MultiIndex mismatch:** if `clusters` is not aligned to the same index as `y/X`, you’ll get errors or wrong results.\n",
    "  - Fix: construct clusters from the same `df` after indexing/sorting.\n",
    "- **Non-numeric dtypes:** strings in `X` silently break models.\n",
    "  - Fix: `astype(float)` on model columns.\n",
    "- **Missing data:** panels often have missing rows after merges/transforms.\n",
    "  - Fix: build a modeling table with `.dropna()` for required columns.\n",
    "- **Too few clusters:** cluster-robust inference is fragile with very small cluster counts.\n",
    "  - Fix: treat p-values as fragile; report cluster count; consider alternative designs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"synthetic-adoption-treatment\"></a>\n",
    "## Synthetic adoption + treatment\n",
    "\n",
    "### Background\n",
    "A real DiD design needs a real policy change and careful context.\n",
    "Here we use a **synthetic adoption schedule** so you can focus on mechanics:\n",
    "- how to build treatment indicators,\n",
    "- how to think about identification (parallel trends),\n",
    "- and how to diagnose pre-trends.\n",
    "\n",
    "We also create a **semi-synthetic outcome** by injecting a known post-treatment effect into a real outcome.\n",
    "That gives you a ground truth target for checking the estimator.\n",
    "\n",
    "### What you should see\n",
    "- `treated` equals 1 only for treated states in post-adoption years.\n",
    "- `poverty_rate_semi` differs from `poverty_rate_real` by about `true_effect` when treated.\n",
    "\n",
    "### Interpretation prompts\n",
    "- In one sentence, define the causal question this notebook is pretending to answer.\n",
    "- What assumption would be needed for the TWFE DiD coefficient to be causal on the real outcome?\n",
    "\n",
    "### Goal\n",
    "Define a deterministic adoption year by state and build:\n",
    "- `treated_it`\n",
    "- `poverty_rate_semi` (known post-treatment effect)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your Turn: Load panel and create synthetic adoption\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "path = PROCESSED_DIR / 'census_county_panel.csv'\n",
    "if path.exists():\n",
    "    df = pd.read_csv(path)\n",
    "else:\n",
    "    df = pd.read_csv(SAMPLE_DIR / 'census_county_panel_sample.csv')\n",
    "\n",
    "df['fips'] = df['fips'].astype(str)\n",
    "df['year'] = df['year'].astype(int)\n",
    "df['state'] = df['state'].astype(str).str.zfill(2)\n",
    "\n",
    "states = sorted(df['state'].unique())\n",
    "# Deterministic adoption schedule (edit if you want):\n",
    "adopt = {states[0]: 2018, states[1]: 2020}  # remaining states are never-treated\n",
    "\n",
    "df['adopt_year'] = df['state'].map(adopt)\n",
    "df['ever_treated'] = df['adopt_year'].notna().astype(int)\n",
    "df['post'] = ((df['year'] >= df['adopt_year']).fillna(False)).astype(int)\n",
    "df['treated'] = df['ever_treated'] * df['post']\n",
    "\n",
    "true_effect = -0.02\n",
    "df['poverty_rate_real'] = df['poverty_rate'].astype(float)\n",
    "df['poverty_rate_semi'] = (df['poverty_rate_real'] + true_effect * df['treated']).clip(0, 1)\n",
    "\n",
    "df[['state', 'year', 'treated', 'poverty_rate_real', 'poverty_rate_semi']].head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"twfe-did\"></a>\n",
    "## TWFE DiD\n",
    "\n",
    "### Background\n",
    "The simplest multi-period DiD estimator is a TWFE regression with a treatment indicator.\n",
    "Under parallel trends (and related assumptions), the coefficient on `treated` can be interpreted as an average treatment effect.\n",
    "\n",
    "### What you should see\n",
    "- On the semi-synthetic outcome, the estimated `treated` coefficient should be in the neighborhood of `true_effect`.\n",
    "- Standard errors should be clustered by state (treatment assignment/shocks).\n",
    "\n",
    "### Interpretation prompts\n",
    "- Compare the estimate to `true_effect`. Is it close? If not, why might it differ (small sample, noise, design)?\n",
    "- Write the parallel trends assumption in words for this setting.\n",
    "\n",
    "### Goal\n",
    "Estimate the effect of treatment with TWFE DiD:\n",
    "- county FE\n",
    "- year FE\n",
    "- clustered SE by state (common)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your Turn: Fit TWFE DiD\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "from src.causal import fit_twfe_panel_ols\n",
    "\n",
    "# Panel index\n",
    "df = df.set_index(['fips', 'year'], drop=False).sort_index()\n",
    "\n",
    "# TODO: Fit DiD on semi-synthetic outcome\n",
    "res_did = fit_twfe_panel_ols(\n",
    "    df,\n",
    "    y_col='poverty_rate_semi',\n",
    "    x_cols=['treated'],\n",
    "    entity_effects=True,\n",
    "    time_effects=True,\n",
    "    cluster_col='state',\n",
    ")\n",
    "\n",
    "res_did.params\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"event-study-leads-lags\"></a>\n",
    "## Event study (leads/lags)\n",
    "\n",
    "### Background\n",
    "An event study replaces a single post indicator with a set of lead/lag indicators.\n",
    "This lets you:\n",
    "- visualize dynamics after adoption, and\n",
    "- test for pre-trends using lead coefficients.\n",
    "\n",
    "### What you should see\n",
    "- lead coefficients (k<0) near 0 on the semi-synthetic outcome.\n",
    "- post coefficients (k>=0) around the injected effect.\n",
    "\n",
    "### Interpretation prompts\n",
    "- Which lead coefficients would worry you most, and why?\n",
    "- Explain what the base period means (why one event-time dummy is omitted).\n",
    "\n",
    "### Goal\n",
    "Estimate dynamic effects around adoption and inspect pre-trends.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your Turn: Build leads/lags and fit\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df_es = df.reset_index(drop=True).copy()\n",
    "df_es['event_time'] = df_es['year'] - df_es['adopt_year']\n",
    "\n",
    "window = list(range(-3, 4))\n",
    "base = -1\n",
    "event_cols = []\n",
    "for k in window:\n",
    "    if k == base:\n",
    "        continue\n",
    "    col = f'event_{k}'\n",
    "    df_es[col] = ((df_es['ever_treated'] == 1) & (df_es['event_time'] == k)).astype(int)\n",
    "    event_cols.append(col)\n",
    "\n",
    "df_es = df_es.set_index(['fips', 'year'], drop=False).sort_index()\n",
    "\n",
    "res_es = fit_twfe_panel_ols(\n",
    "    df_es,\n",
    "    y_col='poverty_rate_semi',\n",
    "    x_cols=event_cols,\n",
    "    entity_effects=True,\n",
    "    time_effects=True,\n",
    "    cluster_col='state',\n",
    ")\n",
    "\n",
    "coefs = res_es.params.filter(like='event_')\n",
    "ses = res_es.std_errors.filter(like='event_')\n",
    "out = coefs.to_frame('coef').join(ses.to_frame('se'))\n",
    "out['k'] = out.index.str.replace('event_', '').astype(int)\n",
    "out = out.sort_values('k')\n",
    "\n",
    "# TODO: Plot coefficient path with 95% CI\n",
    "plt.errorbar(out['k'], out['coef'], yerr=1.96*out['se'], fmt='o-')\n",
    "plt.axhline(0, color='gray', linestyle='--')\n",
    "plt.axvline(base, color='gray', linestyle=':')\n",
    "plt.xlabel('Event time (years relative to adoption)')\n",
    "plt.ylabel('Effect')\n",
    "plt.title('Event study (semi-synthetic)')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"diagnostics-pre-trends-placebo\"></a>\n",
    "## Diagnostics: pre-trends + placebo\n",
    "\n",
    "### Background\n",
    "DiD is only as credible as its diagnostics.\n",
    "In real research, this is where most of the work lives:\n",
    "- are treated and control trending similarly before treatment?\n",
    "- are results robust to reasonable specification changes?\n",
    "- do placebo tests behave as expected?\n",
    "\n",
    "### What you should see\n",
    "- a short diagnostic result (table/plot) and a written interpretation.\n",
    "\n",
    "### Interpretation prompts\n",
    "- If the placebo finds a large effect, what does that suggest about the design?\n",
    "- Why is the real outcome analysis explicitly **not** a real policy evaluation here?\n",
    "\n",
    "### Goal\n",
    "Run at least one falsification / diagnostic.\n",
    "\n",
    "Suggestions:\n",
    "- Pre-trends: are lead coefficients near 0?\n",
    "- Placebo: shift adoption years earlier for treated states.\n",
    "- Re-run on the real outcome (`poverty_rate_real`) and reflect on why it is not causal.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your Turn: One diagnostic\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# TODO: Implement one diagnostic and summarize what you found.\n",
    "...\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ozly31lplp",
   "source": "### Note: Staggered treatment timing and recent DiD literature\n\nThe TWFE DiD estimator used here assumes a **single adoption time** or that treatment effects are homogeneous across cohorts. Recent econometrics research has shown that standard TWFE can produce biased estimates under **staggered adoption** with **heterogeneous treatment effects**:\n\n- **Callaway & Sant'Anna (2021)**: proposes group-time ATTs that avoid \"forbidden comparisons\" (using already-treated units as controls).\n- **Sun & Abraham (2021)**: shows TWFE event studies can be contaminated by treatment effect heterogeneity across cohorts.\n- **de Chaisemartin & D'Haultfoeuille (2020)**: demonstrates when TWFE gives a weighted average with potentially negative weights.\n\n**Practical implication**: In this notebook's synthetic setup (only 2 adoption years), the issue is limited. But in real research with many adoption dates, consider using robust DiD estimators (e.g., `did` package in R, or the `pydid` Python package).\n\n**Key takeaway**: Always check whether your setting involves staggered adoption and heterogeneous effects. If so, standard TWFE may not give you what you think.",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"checkpoint-self-check\"></a>\n",
    "## Checkpoint (Self-Check)\n",
    "Run a few asserts and write 2-3 sentences summarizing what you verified.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Expected output: (see notebook front matter)\n",
    "# TODO: If you created a panel DataFrame, verify the indexing + core columns.\n",
    "# Example (adjust variable names):\n",
    "# assert isinstance(panel.index, pd.MultiIndex)\n",
    "# assert panel.index.names[:2] == ['fips', 'year']\n",
    "# assert panel['year'].astype(int).between(1900, 2100).all()\n",
    "# assert panel['fips'].astype(str).str.len().eq(5).all()\n",
    "#\n",
    "# TODO: Write 2-3 sentences:\n",
    "# - What is the identification assumption for your causal estimate?\n",
    "# - What diagnostic/falsification did you run?\n",
    "...\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extensions (Optional)\n",
    "- Try one additional variant beyond the main path (different features, different split, different model).\n",
    "- Write down what improved, what got worse, and your hypothesis for why.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reflection\n",
    "- What did you assume implicitly (about timing, availability, stationarity, or costs)?\n",
    "- If you had to ship this model, what would you monitor?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"solutions-reference\"></a>\n",
    "## Solutions (Reference)\n",
    "\n",
    "Try the TODOs first. Use these only to unblock yourself or to compare approaches.\n",
    "\n",
    "<details><summary>Solution: Synthetic adoption + treatment</summary>\n",
    "\n",
    "_One possible approach. Your variable names may differ; align them with the notebook._\n",
    "\n",
    "```python\n",
    "# Reference solution for 02_difference_in_differences_event_study — Synthetic adoption + treatment\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(SAMPLE_DIR / 'census_county_panel_sample.csv')\n",
    "df['fips'] = df['fips'].astype(str)\n",
    "df['year'] = df['year'].astype(int)\n",
    "\n",
    "states = sorted(df['state'].astype(str).unique())\n",
    "# Deterministic synthetic adoption schedule\n",
    "adopt = {states[0]: 2018, states[1]: 2020}  # states[2] is never-treated\n",
    "\n",
    "df['adopt_year'] = df['state'].astype(str).map(adopt)\n",
    "df['ever_treated'] = df['adopt_year'].notna().astype(int)\n",
    "df['post'] = ((df['year'] >= df['adopt_year']).fillna(False)).astype(int)\n",
    "df['treated'] = df['ever_treated'] * df['post']\n",
    "\n",
    "# Semi-synthetic outcome: add a known post effect.\n",
    "true_effect = -0.02\n",
    "df['poverty_rate_real'] = df['poverty_rate'].astype(float)\n",
    "df['poverty_rate_semi'] = (df['poverty_rate_real'] + true_effect * df['treated']).clip(0, 1)\n",
    "\n",
    "df[['state', 'year', 'treated', 'poverty_rate_real', 'poverty_rate_semi']].head()\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "<details><summary>Solution: TWFE DiD</summary>\n",
    "\n",
    "_One possible approach. Your variable names may differ; align them with the notebook._\n",
    "\n",
    "```python\n",
    "# Reference solution for 02_difference_in_differences_event_study — TWFE DiD\n",
    "from src.causal import fit_twfe_panel_ols\n",
    "\n",
    "df = df.set_index(['fips', 'year'], drop=False).sort_index()\n",
    "\n",
    "res = fit_twfe_panel_ols(\n",
    "    df,\n",
    "    y_col='poverty_rate_semi',\n",
    "    x_cols=['treated'],\n",
    "    entity_effects=True,\n",
    "    time_effects=True,\n",
    "    cluster_col='state',\n",
    ")\n",
    "res.params\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "<details><summary>Solution: Event study (leads/lags)</summary>\n",
    "\n",
    "_One possible approach. Your variable names may differ; align them with the notebook._\n",
    "\n",
    "```python\n",
    "# Reference solution for 02_difference_in_differences_event_study — Event study (leads/lags)\n",
    "import numpy as np\n",
    "\n",
    "df_es = df.reset_index(drop=True).copy()\n",
    "df_es['event_time'] = df_es['year'] - df_es['adopt_year']\n",
    "\n",
    "window = list(range(-3, 4))\n",
    "base = -1\n",
    "event_cols = []\n",
    "for k in window:\n",
    "    if k == base:\n",
    "        continue\n",
    "    col = f'event_{k}'\n",
    "    df_es[col] = ((df_es['ever_treated'] == 1) & (df_es['event_time'] == k)).astype(int)\n",
    "    event_cols.append(col)\n",
    "\n",
    "df_es = df_es.set_index(['fips', 'year'], drop=False).sort_index()\n",
    "\n",
    "res_es = fit_twfe_panel_ols(\n",
    "    df_es,\n",
    "    y_col='poverty_rate_semi',\n",
    "    x_cols=event_cols,\n",
    "    entity_effects=True,\n",
    "    time_effects=True,\n",
    "    cluster_col='state',\n",
    ")\n",
    "\n",
    "coefs = res_es.params.filter(like='event_')\n",
    "ses = res_es.std_errors.filter(like='event_')\n",
    "out = (coefs.to_frame('coef').join(ses.to_frame('se')))\n",
    "out\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "<details><summary>Solution: Diagnostics: pre-trends + placebo</summary>\n",
    "\n",
    "_One possible approach. Your variable names may differ; align them with the notebook._\n",
    "\n",
    "```python\n",
    "# Reference solution for 02_difference_in_differences_event_study — Diagnostics: pre-trends + placebo\n",
    "# Pre-trends: inspect lead coefficients (event_-3, event_-2).\n",
    "# Placebo: shift adoption earlier and confirm estimated effect shrinks toward 0.\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}