{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 01 Cointegration and Error Correction\n",
        "\n",
        "Engle-Granger cointegration and error correction models (ECM).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Table of Contents\n",
        "- [Construct cointegrated pair](#construct-cointegrated-pair)\n",
        "- [Engle-Granger test](#engle-granger-test)\n",
        "- [Error correction model](#error-correction-model)\n",
        "- [Interpretation](#interpretation)\n",
        "- [Checkpoint (Self-Check)](#checkpoint-self-check)\n",
        "- [Solutions (Reference)](#solutions-reference)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Why This Notebook Matters\n",
        "Time-series econometrics notebooks build the classical toolkit you need before trusting macro regressions:\n",
        "- stationarity + unit roots,\n",
        "- cointegration + error correction,\n",
        "- VAR dynamics and impulse responses.\n",
        "\n",
        "\n",
        "## What You Will Produce\n",
        "- (no file output; learning/analysis notebook)\n",
        "\n",
        "## Success Criteria\n",
        "- You can explain what you built and why each step exists.\n",
        "- You can run your work end-to-end without undefined variables.\n",
        "\n",
        "## Common Pitfalls\n",
        "- Running cells top-to-bottom without reading the instructions.\n",
        "- Leaving `...` placeholders in code cells.\n",
        "- Running tests without plotting or transforming the series first.\n",
        "- Treating impulse responses as structural causality without an identification story.\n",
        "\n",
        "## Matching Guide\n",
        "- `docs/guides/08_time_series_econ/01_cointegration_error_correction.md`\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## How To Use This Notebook\n",
        "- This notebook is hands-on. Most code cells are incomplete on purpose.\n",
        "- Complete each TODO, then run the cell.\n",
        "- Use the matching guide (`docs/guides/08_time_series_econ/01_cointegration_error_correction.md`) for deep explanations and alternative examples.\n",
        "- Write short interpretation notes as you go (what changed, why it matters).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"environment-bootstrap\"></a>\n",
        "## Environment Bootstrap\n",
        "Run this cell first. It makes the repo importable and defines common directories.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "from pathlib import Path\n",
        "import sys\n",
        "\n",
        "\n",
        "def find_repo_root(start: Path) -> Path:\n",
        "    p = start\n",
        "    for _ in range(8):\n",
        "        if (p / 'src').exists() and (p / 'docs').exists():\n",
        "            return p\n",
        "        p = p.parent\n",
        "    raise RuntimeError('Could not find repo root. Start Jupyter from the repo root.')\n",
        "\n",
        "\n",
        "PROJECT_ROOT = find_repo_root(Path.cwd())\n",
        "if str(PROJECT_ROOT) not in sys.path:\n",
        "    sys.path.append(str(PROJECT_ROOT))\n",
        "\n",
        "DATA_DIR = PROJECT_ROOT / 'data'\n",
        "RAW_DIR = DATA_DIR / 'raw'\n",
        "PROCESSED_DIR = DATA_DIR / 'processed'\n",
        "SAMPLE_DIR = DATA_DIR / 'sample'\n",
        "\n",
        "PROJECT_ROOT\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Goal\n",
        "Learn cointegration and error correction models (ECM):\n",
        "- long-run equilibrium relationship\n",
        "- short-run dynamics that correct deviations\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Primer: Classical time-series econometrics with statsmodels (ADF/KPSS, VAR)\n",
        "\n",
        "This repo already uses time-aware evaluation for ML.\n",
        "This primer introduces the \u201cclassical\u201d time-series econometrics toolkit in `statsmodels`.\n",
        "\n",
        "### Stationarity and unit roots (ADF / KPSS)\n",
        "Two common tests:\n",
        "- **ADF**: null = unit root (nonstationary)\n",
        "- **KPSS**: null = stationary\n",
        "\n",
        "```python\n",
        "from statsmodels.tsa.stattools import adfuller, kpss\n",
        "\n",
        "# x is a 1D array-like (no missing)\n",
        "# adf_stat, adf_p, *_ = adfuller(x)\n",
        "# kpss_stat, kpss_p, *_ = kpss(x, regression='c', nlags='auto')\n",
        "```\n",
        "\n",
        "Interpretation habit:\n",
        "- If ADF p-value is small \u2192 evidence against unit root.\n",
        "- If KPSS p-value is small \u2192 evidence against stationarity.\n",
        "\n",
        "### VAR: multivariate autoregression\n",
        "VAR models multiple series together:\n",
        "```python\n",
        "from statsmodels.tsa.api import VAR\n",
        "\n",
        "# df: DataFrame of stationary-ish series with a DatetimeIndex\n",
        "# model = VAR(df)\n",
        "# res = model.fit(maxlags=8, ic='aic')  # or choose lags manually\n",
        "# print(res.summary())\n",
        "```\n",
        "\n",
        "Useful tools:\n",
        "```python\n",
        "# res.test_causality('y', ['x1', 'x2'])      # Granger causality tests\n",
        "# irf = res.irf(12)                         # impulse responses to 12 steps\n",
        "# irf.plot(orth=True)                       # orthogonalized (ordering matters)\n",
        "```\n",
        "\n",
        "### Practical cautions\n",
        "- Nonstationary series can create **spurious regression** results.\n",
        "- IRFs depend on identification choices (e.g., Cholesky ordering).\n",
        "- Macro series are revised and can have structural breaks; treat results as conditional and fragile.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"construct-cointegrated-pair\"></a>\n",
        "## Construct cointegrated pair\n",
        "\n",
        "### Goal\n",
        "Construct a pair of series that are individually nonstationary but cointegrated.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Your Turn: Simulate a cointegrated pair\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "rng = np.random.default_rng(0)\n",
        "n = 240\n",
        "idx = pd.date_range('2000-01-31', periods=n, freq='ME')\n",
        "\n",
        "x = rng.normal(size=n).cumsum()\n",
        "y = 1.0 * x + rng.normal(scale=0.5, size=n)\n",
        "\n",
        "df = pd.DataFrame({'x': x, 'y': y}, index=idx)\n",
        "df.head()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"engle-granger-test\"></a>\n",
        "## Engle-Granger test\n",
        "\n",
        "### Goal\n",
        "Run a cointegration test and interpret the p-value carefully.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Your Turn: Cointegration test\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "from statsmodels.tsa.stattools import coint\n",
        "\n",
        "t_stat, p_val, _ = coint(df['y'], df['x'])\n",
        "{'t': t_stat, 'p': p_val}\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"error-correction-model\"></a>\n",
        "## Error correction model\n",
        "\n",
        "### Goal\n",
        "Fit an ECM:\n",
        "- short-run changes depend on long-run disequilibrium (lagged residual)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Your Turn: Fit ECM\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import statsmodels.api as sm\n",
        "\n",
        "# Long-run regression\n",
        "lr = sm.OLS(df['y'], sm.add_constant(df[['x']], has_constant='add')).fit()\n",
        "df['u'] = lr.resid\n",
        "\n",
        "# ECM regression\n",
        "ecm = pd.DataFrame({\n",
        "    'dy': df['y'].diff(),\n",
        "    'dx': df['x'].diff(),\n",
        "    'u_lag1': df['u'].shift(1),\n",
        "}).dropna()\n",
        "\n",
        "res = sm.OLS(ecm['dy'], sm.add_constant(ecm[['dx', 'u_lag1']], has_constant='add')).fit()\n",
        "res.params\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"interpretation\"></a>\n",
        "## Interpretation\n",
        "\n",
        "Write 5-8 sentences:\n",
        "- What does the error-correction coefficient mean?\n",
        "- What would you expect if there were no cointegration?\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"checkpoint-self-check\"></a>\n",
        "## Checkpoint (Self-Check)\n",
        "Run a few asserts and write 2-3 sentences summarizing what you verified.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# TODO: Validate your time series table is well-formed.\n",
        "# Example (adjust variable names):\n",
        "# assert isinstance(df.index, pd.DatetimeIndex)\n",
        "# assert df.index.is_monotonic_increasing\n",
        "# assert df.shape[0] > 30\n",
        "#\n",
        "# TODO: If you built transformed series (diff/logdiff), confirm no future leakage.\n",
        "# Hint: transformations should only use past/current values (shift/diff), never future.\n",
        "...\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Extensions (Optional)\n",
        "- Try one additional variant beyond the main path (different features, different split, different model).\n",
        "- Write down what improved, what got worse, and your hypothesis for why.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Reflection\n",
        "- What did you assume implicitly (about timing, availability, stationarity, or costs)?\n",
        "- If you had to ship this model, what would you monitor?\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"solutions-reference\"></a>\n",
        "## Solutions (Reference)\n",
        "\n",
        "Try the TODOs first. Use these only to unblock yourself or to compare approaches.\n",
        "\n",
        "<details><summary>Solution: Construct cointegrated pair</summary>\n",
        "\n",
        "_One possible approach. Your variable names may differ; align them with the notebook._\n",
        "\n",
        "```python\n",
        "# Reference solution for 01_cointegration_error_correction \u2014 Construct cointegrated pair\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "rng = np.random.default_rng(0)\n",
        "n = 240\n",
        "idx = pd.date_range('2000-01-31', periods=n, freq='ME')\n",
        "\n",
        "x = rng.normal(size=n).cumsum()  # random walk\n",
        "y = 1.0 * x + rng.normal(scale=0.5, size=n)  # cointegrated with x\n",
        "\n",
        "df = pd.DataFrame({'x': x, 'y': y}, index=idx)\n",
        "df.head()\n",
        "```\n",
        "\n",
        "</details>\n",
        "\n",
        "<details><summary>Solution: Engle-Granger test</summary>\n",
        "\n",
        "_One possible approach. Your variable names may differ; align them with the notebook._\n",
        "\n",
        "```python\n",
        "# Reference solution for 01_cointegration_error_correction \u2014 Engle-Granger test\n",
        "from statsmodels.tsa.stattools import coint\n",
        "\n",
        "t_stat, p_val, _ = coint(df['y'], df['x'])\n",
        "{'t': t_stat, 'p': p_val}\n",
        "```\n",
        "\n",
        "</details>\n",
        "\n",
        "<details><summary>Solution: Error correction model</summary>\n",
        "\n",
        "_One possible approach. Your variable names may differ; align them with the notebook._\n",
        "\n",
        "```python\n",
        "# Reference solution for 01_cointegration_error_correction \u2014 Error correction model\n",
        "import statsmodels.api as sm\n",
        "\n",
        "# Step 1: long-run relationship\n",
        "lr = sm.OLS(df['y'], sm.add_constant(df[['x']], has_constant='add')).fit()\n",
        "df['u'] = lr.resid\n",
        "\n",
        "# Step 2: ECM\n",
        "ecm = pd.DataFrame({\n",
        "    'dy': df['y'].diff(),\n",
        "    'dx': df['x'].diff(),\n",
        "    'u_lag1': df['u'].shift(1),\n",
        "}).dropna()\n",
        "\n",
        "res = sm.OLS(ecm['dy'], sm.add_constant(ecm[['dx', 'u_lag1']], has_constant='add')).fit()\n",
        "res.params\n",
        "```\n",
        "\n",
        "</details>\n",
        "\n",
        "<details><summary>Solution: Interpretation</summary>\n",
        "\n",
        "_One possible approach. Your variable names may differ; align them with the notebook._\n",
        "\n",
        "```python\n",
        "# Reference solution for 01_cointegration_error_correction \u2014 Interpretation\n",
        "# Explain what the error-correction coefficient implies about mean reversion.\n",
        "```\n",
        "\n",
        "</details>\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "python3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}