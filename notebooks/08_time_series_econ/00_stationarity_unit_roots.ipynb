{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 00 Stationarity and Unit Roots\n",
        "\n",
        "ADF/KPSS, differencing, and spurious regression intuition.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Table of Contents\n",
        "- [Load macro series](#load-macro-series)\n",
        "- [Transformations](#transformations)\n",
        "- [ADF/KPSS tests](#adf-kpss-tests)\n",
        "- [Spurious regression demo](#spurious-regression-demo)\n",
        "- [Checkpoint (Self-Check)](#checkpoint-self-check)\n",
        "- [Solutions (Reference)](#solutions-reference)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Why This Notebook Matters\n",
        "Time-series econometrics notebooks build the classical toolkit you need before trusting macro regressions:\n",
        "- stationarity + unit roots,\n",
        "- cointegration + error correction,\n",
        "- VAR dynamics and impulse responses.\n",
        "\n",
        "\n",
        "## What You Will Produce\n",
        "- (no file output; learning/analysis notebook)\n",
        "\n",
        "## Success Criteria\n",
        "- You can explain what you built and why each step exists.\n",
        "- You can run your work end-to-end without undefined variables.\n",
        "\n",
        "## Common Pitfalls\n",
        "- Running cells top-to-bottom without reading the instructions.\n",
        "- Leaving `...` placeholders in code cells.\n",
        "- Running tests without plotting or transforming the series first.\n",
        "- Treating impulse responses as structural causality without an identification story.\n",
        "\n",
        "## Matching Guide\n",
        "- `docs/guides/08_time_series_econ/00_stationarity_unit_roots.md`\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## How To Use This Notebook\n",
        "- This notebook is hands-on. Most code cells are incomplete on purpose.\n",
        "- Complete each TODO, then run the cell.\n",
        "- Use the matching guide (`docs/guides/08_time_series_econ/00_stationarity_unit_roots.md`) for deep explanations and alternative examples.\n",
        "- Write short interpretation notes as you go (what changed, why it matters).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"environment-bootstrap\"></a>\n",
        "## Environment Bootstrap\n",
        "Run this cell first. It makes the repo importable and defines common directories.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "from pathlib import Path\n",
        "import sys\n",
        "\n",
        "\n",
        "def find_repo_root(start: Path) -> Path:\n",
        "    p = start\n",
        "    for _ in range(8):\n",
        "        if (p / 'src').exists() and (p / 'docs').exists():\n",
        "            return p\n",
        "        p = p.parent\n",
        "    raise RuntimeError('Could not find repo root. Start Jupyter from the repo root.')\n",
        "\n",
        "\n",
        "PROJECT_ROOT = find_repo_root(Path.cwd())\n",
        "if str(PROJECT_ROOT) not in sys.path:\n",
        "    sys.path.append(str(PROJECT_ROOT))\n",
        "\n",
        "DATA_DIR = PROJECT_ROOT / 'data'\n",
        "RAW_DIR = DATA_DIR / 'raw'\n",
        "PROCESSED_DIR = DATA_DIR / 'processed'\n",
        "SAMPLE_DIR = DATA_DIR / 'sample'\n",
        "\n",
        "PROJECT_ROOT\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Goal\n",
        "Learn the stationarity toolkit that prevents common macro mistakes:\n",
        "- spurious regression\n",
        "- over-trusting p-values on trending series\n",
        "- misinterpreting dynamics\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Primer: pandas Time Series Essentials\n",
        "\n",
        "### DatetimeIndex\n",
        "Most time series work in pandas assumes your DataFrame is indexed by time.\n",
        "\n",
        "```python\n",
        "import pandas as pd\n",
        "\n",
        "# idx = pd.to_datetime(df['date'])\n",
        "# df = df.set_index(idx).sort_index()\n",
        "# assert isinstance(df.index, pd.DatetimeIndex)\n",
        "```\n",
        "\n",
        "If you see weird behavior (resample errors, merges not aligning), check:\n",
        "- `df.index.dtype`\n",
        "- `df.index.min(), df.index.max()`\n",
        "- `df.index.is_monotonic_increasing`\n",
        "\n",
        "### Resampling\n",
        "> **Goal:** convert one frequency to another.\n",
        "\n",
        "Common examples:\n",
        "- daily -> month-end\n",
        "- monthly -> quarter-end\n",
        "\n",
        "```python\n",
        "# month-end last value\n",
        "# df_me_last = df.resample('ME').last()\n",
        "\n",
        "# month-end mean\n",
        "# df_me_mean = df.resample('ME').mean()\n",
        "\n",
        "# quarter-end mean\n",
        "# df_q_mean = df.resample('QE').mean()\n",
        "```\n",
        "\n",
        "**Interpretation matters.** For economic series:\n",
        "- using `.last()` treats the end-of-period value as \u201cthe period\u2019s value\u201d\n",
        "- using `.mean()` treats the period average as \u201cthe period\u2019s value\u201d\n",
        "\n",
        "Neither is universally correct; you should choose based on measurement and use case.\n",
        "\n",
        "### Alignment and merging\n",
        "When joining multiple time series, you need to ensure they share:\n",
        "- the same index type (`DatetimeIndex`)\n",
        "- the same frequency convention (month-end vs month-start; quarter-end vs quarter-start)\n",
        "\n",
        "```python\n",
        "# Example: join two series and inspect missingness\n",
        "# df = df1.join(df2, how='outer').sort_index()\n",
        "# print(df.isna().sum())\n",
        "```\n",
        "\n",
        "### Lags and rolling windows\n",
        "> **Lag:** use past values as features.\n",
        "\n",
        "```python\n",
        "# lag 1 period\n",
        "# df['x_lag1'] = df['x'].shift(1)\n",
        "\n",
        "# rolling mean (past-only)\n",
        "# df['x_roll12'] = df['x'].rolling(12).mean()\n",
        "```\n",
        "\n",
        "### Common gotchas\n",
        "- `shift(-1)` uses the future (leakage for forecasting).\n",
        "- `rolling(..., center=True)` uses future values.\n",
        "- Always `dropna()` after creating lags/rolls to get clean modeling rows.\n",
        "\n",
        "One more gotcha:\n",
        "- If you resample daily -> monthly and then create lags, your lag is \u201cone month\u201d (not one day). Lags are measured in the current index frequency.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Primer: Classical time-series econometrics with statsmodels (ADF/KPSS, VAR)\n",
        "\n",
        "This repo already uses time-aware evaluation for ML.\n",
        "This primer introduces the \u201cclassical\u201d time-series econometrics toolkit in `statsmodels`.\n",
        "\n",
        "### Stationarity and unit roots (ADF / KPSS)\n",
        "Two common tests:\n",
        "- **ADF**: null = unit root (nonstationary)\n",
        "- **KPSS**: null = stationary\n",
        "\n",
        "```python\n",
        "from statsmodels.tsa.stattools import adfuller, kpss\n",
        "\n",
        "# x is a 1D array-like (no missing)\n",
        "# adf_stat, adf_p, *_ = adfuller(x)\n",
        "# kpss_stat, kpss_p, *_ = kpss(x, regression='c', nlags='auto')\n",
        "```\n",
        "\n",
        "Interpretation habit:\n",
        "- If ADF p-value is small \u2192 evidence against unit root.\n",
        "- If KPSS p-value is small \u2192 evidence against stationarity.\n",
        "\n",
        "### VAR: multivariate autoregression\n",
        "VAR models multiple series together:\n",
        "```python\n",
        "from statsmodels.tsa.api import VAR\n",
        "\n",
        "# df: DataFrame of stationary-ish series with a DatetimeIndex\n",
        "# model = VAR(df)\n",
        "# res = model.fit(maxlags=8, ic='aic')  # or choose lags manually\n",
        "# print(res.summary())\n",
        "```\n",
        "\n",
        "Useful tools:\n",
        "```python\n",
        "# res.test_causality('y', ['x1', 'x2'])      # Granger causality tests\n",
        "# irf = res.irf(12)                         # impulse responses to 12 steps\n",
        "# irf.plot(orth=True)                       # orthogonalized (ordering matters)\n",
        "```\n",
        "\n",
        "### Practical cautions\n",
        "- Nonstationary series can create **spurious regression** results.\n",
        "- IRFs depend on identification choices (e.g., Cholesky ordering).\n",
        "- Macro series are revised and can have structural breaks; treat results as conditional and fragile.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"load-macro-series\"></a>\n",
        "## Load macro series\n",
        "\n",
        "### Goal\n",
        "Load the macro monthly panel.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Your Turn: Load panel_monthly.csv (or sample)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "path = PROCESSED_DIR / 'panel_monthly.csv'\n",
        "if path.exists():\n",
        "    df = pd.read_csv(path, index_col=0, parse_dates=True)\n",
        "else:\n",
        "    df = pd.read_csv(SAMPLE_DIR / 'panel_monthly_sample.csv', index_col=0, parse_dates=True)\n",
        "\n",
        "df = df.dropna().copy()\n",
        "df.head()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"transformations\"></a>\n",
        "## Transformations\n",
        "\n",
        "### Goal\n",
        "Create stationary-ish transformations (diff, pct change, log diff).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Your Turn: Differences and growth rates\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# TODO: Pick a few series and create transformations\n",
        "tmp = df[['CPIAUCSL', 'UNRATE', 'INDPRO']].astype(float).copy()\n",
        "tmp['dCPI'] = tmp['CPIAUCSL'].diff()\n",
        "tmp['dUNRATE'] = tmp['UNRATE'].diff()\n",
        "\n",
        "# log-diff for industrial production (example)\n",
        "x = tmp['INDPRO'].where(tmp['INDPRO'] > 0)\n",
        "tmp['dlog_INDPRO'] = np.log(x).diff()\n",
        "\n",
        "tmp = tmp.dropna()\n",
        "tmp.head()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"adf-kpss-tests\"></a>\n",
        "## ADF/KPSS tests\n",
        "\n",
        "### Goal\n",
        "Run stationarity diagnostics on levels vs transformed series.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Your Turn: ADF and KPSS\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "from statsmodels.tsa.stattools import adfuller, kpss\n",
        "\n",
        "# TODO: Choose one series and compare levels vs diff\n",
        "x = df['CPIAUCSL'].astype(float).dropna()\n",
        "dx = x.diff().dropna()\n",
        "\n",
        "out = {\n",
        "    'adf_p_level': adfuller(x)[1],\n",
        "    'adf_p_diff': adfuller(dx)[1],\n",
        "    'kpss_p_level': kpss(x, regression='c', nlags='auto')[1],\n",
        "    'kpss_p_diff': kpss(dx, regression='c', nlags='auto')[1],\n",
        "}\n",
        "out\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"spurious-regression-demo\"></a>\n",
        "## Spurious regression demo\n",
        "\n",
        "### Goal\n",
        "Show how levels-on-levels regressions can look good for the wrong reasons.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Your Turn: Levels vs differences\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import statsmodels.api as sm\n",
        "\n",
        "tmp2 = df[['CPIAUCSL', 'INDPRO']].astype(float).dropna()\n",
        "\n",
        "# Levels regression\n",
        "res_lvl = sm.OLS(tmp2['CPIAUCSL'], sm.add_constant(tmp2[['INDPRO']], has_constant='add')).fit()\n",
        "\n",
        "# Differences regression\n",
        "d = tmp2.diff().dropna()\n",
        "res_diff = sm.OLS(d['CPIAUCSL'], sm.add_constant(d[['INDPRO']], has_constant='add')).fit()\n",
        "\n",
        "print('R2 levels:', res_lvl.rsquared)\n",
        "print('R2 diffs :', res_diff.rsquared)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"checkpoint-self-check\"></a>\n",
        "## Checkpoint (Self-Check)\n",
        "Run a few asserts and write 2-3 sentences summarizing what you verified.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# TODO: Validate your time series table is well-formed.\n",
        "# Example (adjust variable names):\n",
        "# assert isinstance(df.index, pd.DatetimeIndex)\n",
        "# assert df.index.is_monotonic_increasing\n",
        "# assert df.shape[0] > 30\n",
        "#\n",
        "# TODO: If you built transformed series (diff/logdiff), confirm no future leakage.\n",
        "# Hint: transformations should only use past/current values (shift/diff), never future.\n",
        "...\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Extensions (Optional)\n",
        "- Try one additional variant beyond the main path (different features, different split, different model).\n",
        "- Write down what improved, what got worse, and your hypothesis for why.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Reflection\n",
        "- What did you assume implicitly (about timing, availability, stationarity, or costs)?\n",
        "- If you had to ship this model, what would you monitor?\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"solutions-reference\"></a>\n",
        "## Solutions (Reference)\n",
        "\n",
        "Try the TODOs first. Use these only to unblock yourself or to compare approaches.\n",
        "\n",
        "<details><summary>Solution: Load macro series</summary>\n",
        "\n",
        "_One possible approach. Your variable names may differ; align them with the notebook._\n",
        "\n",
        "```python\n",
        "# Reference solution for 00_stationarity_unit_roots \u2014 Load macro series\n",
        "import pandas as pd\n",
        "\n",
        "path = PROCESSED_DIR / 'panel_monthly.csv'\n",
        "if path.exists():\n",
        "    df = pd.read_csv(path, index_col=0, parse_dates=True)\n",
        "else:\n",
        "    df = pd.read_csv(SAMPLE_DIR / 'panel_monthly_sample.csv', index_col=0, parse_dates=True)\n",
        "\n",
        "df = df.dropna().copy()\n",
        "df.head()\n",
        "```\n",
        "\n",
        "</details>\n",
        "\n",
        "<details><summary>Solution: Transformations</summary>\n",
        "\n",
        "_One possible approach. Your variable names may differ; align them with the notebook._\n",
        "\n",
        "```python\n",
        "# Reference solution for 00_stationarity_unit_roots \u2014 Transformations\n",
        "# Example: difference CPI and unemployment\n",
        "df_t = df[['CPIAUCSL', 'UNRATE']].astype(float).copy()\n",
        "df_t['dCPI'] = df_t['CPIAUCSL'].diff()\n",
        "df_t['dUNRATE'] = df_t['UNRATE'].diff()\n",
        "df_t = df_t.dropna()\n",
        "df_t.head()\n",
        "```\n",
        "\n",
        "</details>\n",
        "\n",
        "<details><summary>Solution: ADF/KPSS tests</summary>\n",
        "\n",
        "_One possible approach. Your variable names may differ; align them with the notebook._\n",
        "\n",
        "```python\n",
        "# Reference solution for 00_stationarity_unit_roots \u2014 ADF/KPSS tests\n",
        "from statsmodels.tsa.stattools import adfuller, kpss\n",
        "\n",
        "x = df['CPIAUCSL'].astype(float).dropna()\n",
        "dx = x.diff().dropna()\n",
        "\n",
        "adf_p_level = adfuller(x)[1]\n",
        "adf_p_diff = adfuller(dx)[1]\n",
        "kpss_p_level = kpss(x, regression='c', nlags='auto')[1]\n",
        "kpss_p_diff = kpss(dx, regression='c', nlags='auto')[1]\n",
        "\n",
        "{'adf_p_level': adf_p_level, 'adf_p_diff': adf_p_diff, 'kpss_p_level': kpss_p_level, 'kpss_p_diff': kpss_p_diff}\n",
        "```\n",
        "\n",
        "</details>\n",
        "\n",
        "<details><summary>Solution: Spurious regression demo</summary>\n",
        "\n",
        "_One possible approach. Your variable names may differ; align them with the notebook._\n",
        "\n",
        "```python\n",
        "# Reference solution for 00_stationarity_unit_roots \u2014 Spurious regression demo\n",
        "import statsmodels.api as sm\n",
        "\n",
        "# Levels-on-levels can look 'significant' even when dynamics are mis-specified.\n",
        "tmp = df[['CPIAUCSL', 'INDPRO']].astype(float).dropna()\n",
        "res_lvl = sm.OLS(tmp['CPIAUCSL'], sm.add_constant(tmp[['INDPRO']], has_constant='add')).fit()\n",
        "res_diff = sm.OLS(tmp['CPIAUCSL'].diff().dropna(), sm.add_constant(tmp['INDPRO'].diff().dropna(), has_constant='add')).fit()\n",
        "\n",
        "(res_lvl.rsquared, res_diff.rsquared)\n",
        "```\n",
        "\n",
        "</details>\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "python3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}