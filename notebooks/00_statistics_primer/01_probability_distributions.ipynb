{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-title",
   "metadata": {},
   "source": [
    "# 01 Probability Distributions\n",
    "\n",
    "The building blocks of statistical inference: understanding, visualizing, and simulating the distributions you will encounter throughout this project."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-toc",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "- [What is a probability distribution?](#what-is-a-probability-distribution)\n",
    "- [The Normal distribution](#the-normal-distribution)\n",
    "- [The t-distribution](#the-t-distribution)\n",
    "- [The Chi-Squared distribution](#the-chi-squared-distribution)\n",
    "- [The F-distribution](#the-f-distribution)\n",
    "- [Discrete distributions: Binomial and Poisson](#discrete-distributions)\n",
    "- [Comparing distributions with real data](#comparing-distributions-with-real-data)\n",
    "- [Checkpoint (Self-Check)](#checkpoint-self-check)\n",
    "- [Solutions (Reference)](#solutions-reference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-why",
   "metadata": {},
   "source": [
    "## Why This Notebook Matters\n",
    "Every hypothesis test, confidence interval, and p-value in this project relies on an assumed\n",
    "probability distribution. If you don't understand where these distributions come from and\n",
    "what they look like, statistical inference becomes a black box. This notebook makes the\n",
    "distributions concrete through simulation and visualization.\n",
    "\n",
    "## Prerequisites (Quick Self-Check)\n",
    "- Completed notebook 00 (descriptive statistics).\n",
    "- Comfort with histograms and basic plotting.\n",
    "\n",
    "## What You Will Produce\n",
    "- (no file output; learning/analysis notebook)\n",
    "\n",
    "## Success Criteria\n",
    "- You can describe the shape and parameters of the normal, t, chi-squared, F, binomial, and Poisson distributions.\n",
    "- You can simulate data from each and visualize PDFs/PMFs and CDFs.\n",
    "- You can explain when each distribution arises in econometric practice.\n",
    "\n",
    "## Common Pitfalls\n",
    "- Assuming all data is normally distributed without checking.\n",
    "- Confusing PDF (density, for continuous) with PMF (probability, for discrete).\n",
    "- Forgetting that the t-distribution has heavier tails than the normal.\n",
    "- Treating distribution parameters as fixed truths rather than estimated quantities.\n",
    "\n",
    "## Quick Fixes (When You Get Stuck)\n",
    "- If `scipy.stats` functions confuse you, remember: `.pdf(x)` for density, `.cdf(x)` for cumulative probability, `.rvs(size=n)` to simulate.\n",
    "- If plots look empty, check your x-axis range.\n",
    "- If you see `ModuleNotFoundError`, re-run the bootstrap cell.\n",
    "\n",
    "## Matching Guide\n",
    "- `docs/guides/00_statistics_primer/01_probability_distributions.md`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-howto",
   "metadata": {},
   "source": [
    "## How To Use This Notebook\n",
    "- Work section-by-section; don't skip the markdown.\n",
    "- Most code cells are incomplete on purpose: replace TODOs and `...`, then run.\n",
    "- After each section, write 2\u20134 sentences answering the interpretation prompts (what changed, why it matters).\n",
    "- Prefer `data/processed/*` if you have built the real datasets; otherwise use the bundled `data/sample/*` fallbacks.\n",
    "- Use the **Checkpoint (Self-Check)** section to catch mistakes early.\n",
    "- Use **Solutions (Reference)** only to unblock yourself; then re-implement without looking.\n",
    "- Use the matching guide (`docs/guides/00_statistics_primer/01_probability_distributions.md`) for the math, assumptions, and deeper context."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-bootstrap-header",
   "metadata": {},
   "source": [
    "<a id=\"environment-bootstrap\"></a>\n",
    "## Environment Bootstrap\n",
    "Run this cell first. It makes the repo importable and defines common directories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-bootstrap",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "\n",
    "def find_repo_root(start: Path) -> Path:\n",
    "    p = start\n",
    "    for _ in range(8):\n",
    "        if (p / 'src').exists() and (p / 'docs').exists():\n",
    "            return p\n",
    "        p = p.parent\n",
    "    raise RuntimeError('Could not find repo root. Start Jupyter from the repo root.')\n",
    "\n",
    "\n",
    "PROJECT_ROOT = find_repo_root(Path.cwd())\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.append(str(PROJECT_ROOT))\n",
    "\n",
    "DATA_DIR = PROJECT_ROOT / 'data'\n",
    "RAW_DIR = DATA_DIR / 'raw'\n",
    "PROCESSED_DIR = DATA_DIR / 'processed'\n",
    "SAMPLE_DIR = DATA_DIR / 'sample'\n",
    "\n",
    "PROJECT_ROOT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-imports-header",
   "metadata": {},
   "source": [
    "### Common imports for this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (8, 4)\n",
    "plt.rcParams['figure.dpi'] = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-sec1-header",
   "metadata": {},
   "source": [
    "---\n",
    "<a id=\"what-is-a-probability-distribution\"></a>\n",
    "## What is a probability distribution?\n",
    "\n",
    "### Goal\n",
    "Build a mental model for what a distribution is, and distinguish the key vocabulary: PMF vs PDF, CDF, discrete vs continuous, and parameters.\n",
    "\n",
    "### Why this matters in economics\n",
    "Every econometric test implicitly assumes a probability distribution for the data or for a test statistic. When you run an OLS regression and look at p-values, you are assuming that the test statistic follows a t-distribution (or approximately a normal). If the assumption is wrong, the p-values lie."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-sec1-primer",
   "metadata": {},
   "source": [
    "### Primer\n",
    "\n",
    "A **probability distribution** is a recipe for generating random data. Think of it as a machine: you turn the crank, and it spits out a number. The distribution tells you *which numbers are likely* and *which are rare*.\n",
    "\n",
    "**Discrete vs Continuous**\n",
    "- **Discrete**: the random variable can only take specific values (e.g., counts: 0, 1, 2, ...). Described by a **PMF** (probability mass function): $P(X = k)$.\n",
    "- **Continuous**: the random variable can take any value in an interval (e.g., GDP growth: 2.31%, -0.47%). Described by a **PDF** (probability density function): $f(x)$. Note that $P(X = x) = 0$ for any single point; probabilities are areas under the curve.\n",
    "\n",
    "**CDF (Cumulative Distribution Function)**\n",
    "- Works for both discrete and continuous: $F(x) = P(X \\le x)$.\n",
    "- Always non-decreasing, from 0 to 1.\n",
    "\n",
    "**Parameters**\n",
    "- Most distributions are families indexed by parameters. The normal has $\\mu$ (mean) and $\\sigma$ (standard deviation). The t-distribution has $\\nu$ (degrees of freedom). Changing parameters changes the shape.\n",
    "\n",
    "**Intuition**: A distribution is not a single dataset. It is the *process* that could have generated many datasets. When we fit a distribution to data, we are guessing which machine produced our observations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-sec1-visual",
   "metadata": {},
   "source": [
    "### Quick visual: PMF vs PDF vs CDF\n",
    "\n",
    "The following cell plots a discrete PMF (Binomial) and a continuous PDF (Normal) side-by-side so you can see the difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-sec1-demo",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(14, 4))\n",
    "\n",
    "# --- PMF: Binomial(n=10, p=0.3) ---\n",
    "k = np.arange(0, 11)\n",
    "pmf_vals = stats.binom.pmf(k, n=10, p=0.3)\n",
    "axes[0].bar(k, pmf_vals, color='steelblue', edgecolor='black', alpha=0.8)\n",
    "axes[0].set_title('PMF: Binomial(n=10, p=0.3)')\n",
    "axes[0].set_xlabel('k')\n",
    "axes[0].set_ylabel('P(X = k)')\n",
    "\n",
    "# --- PDF: Normal(mu=0, sigma=1) ---\n",
    "x = np.linspace(-4, 4, 200)\n",
    "axes[1].plot(x, stats.norm.pdf(x), color='darkred', lw=2)\n",
    "axes[1].fill_between(x, stats.norm.pdf(x), alpha=0.15, color='darkred')\n",
    "axes[1].set_title('PDF: Normal(0, 1)')\n",
    "axes[1].set_xlabel('x')\n",
    "axes[1].set_ylabel('f(x)')\n",
    "\n",
    "# --- CDF comparison ---\n",
    "axes[2].step(k, stats.binom.cdf(k, n=10, p=0.3), where='mid',\n",
    "             label='Binomial CDF', color='steelblue', lw=2)\n",
    "axes[2].plot(x, stats.norm.cdf(x), label='Normal CDF', color='darkred', lw=2)\n",
    "axes[2].set_title('CDF comparison')\n",
    "axes[2].set_xlabel('x')\n",
    "axes[2].set_ylabel('F(x)')\n",
    "axes[2].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-sec1-interp",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "\n",
    "**Write 2\u20134 sentences:**\n",
    "1. What is the key visual difference between a PMF (left) and a PDF (center)?\n",
    "2. For the CDF plot (right), how do you read off $P(X \\le 2)$ for the Binomial? For the Normal?\n",
    "\n",
    "*Your answer:*\n",
    "\n",
    "(write here)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-sec2-header",
   "metadata": {},
   "source": [
    "---\n",
    "<a id=\"the-normal-distribution\"></a>\n",
    "## The Normal (Gaussian) Distribution\n",
    "\n",
    "### Goal\n",
    "Simulate normal data, visualize the PDF, and learn to check whether real economic data is approximately normal.\n",
    "\n",
    "### Why this matters in economics\n",
    "The Central Limit Theorem (CLT) says that sample means become approximately normal as $n$ grows, which justifies many inference procedures. But the underlying data itself is often *not* normal (e.g., income distributions are right-skewed, asset returns have fat tails). Knowing when normality holds and when it breaks is essential."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-sec2-primer",
   "metadata": {},
   "source": [
    "### Primer\n",
    "\n",
    "The **Normal distribution** $N(\\mu, \\sigma^2)$ has two parameters:\n",
    "- $\\mu$: the mean (center of the bell curve)\n",
    "- $\\sigma$: the standard deviation (spread)\n",
    "\n",
    "Its PDF is:\n",
    "$$\n",
    "f(x) = \\frac{1}{\\sigma\\sqrt{2\\pi}} \\exp\\left(-\\frac{(x - \\mu)^2}{2\\sigma^2}\\right)\n",
    "$$\n",
    "\n",
    "Key properties:\n",
    "- Symmetric around $\\mu$.\n",
    "- About 68% of the data falls within $\\mu \\pm \\sigma$, 95% within $\\mu \\pm 2\\sigma$.\n",
    "- Fully characterized by its first two moments (mean and variance)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-sec2-turn1",
   "metadata": {},
   "source": [
    "### Your Turn (1): Simulate and visualize Normal data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-sec2-code1",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(42)\n",
    "\n",
    "# TODO: Simulate 5000 draws from N(mu=2, sigma=1.5)\n",
    "mu, sigma = 2, 1.5\n",
    "normal_data = ...  # rng.normal(...)\n",
    "\n",
    "# TODO: Plot a histogram (density=True) and overlay the theoretical PDF\n",
    "x = np.linspace(mu - 4 * sigma, mu + 4 * sigma, 200)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "# Histogram\n",
    "ax.hist(...)  # TODO: fill in arguments (bins=50, density=True, alpha=0.5)\n",
    "# PDF overlay\n",
    "ax.plot(...)  # TODO: use stats.norm.pdf(x, loc=mu, scale=sigma)\n",
    "ax.set_title('Normal Distribution: Simulated vs Theoretical')\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('Density')\n",
    "ax.legend(['Theoretical PDF', 'Simulated data'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-sec2-turn2",
   "metadata": {},
   "source": [
    "### Your Turn (2): Is GDP growth normally distributed?\n",
    "\n",
    "Load the sample macro data and check whether quarterly GDP growth looks normal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-sec2-code2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(SAMPLE_DIR / 'macro_quarterly_sample.csv', index_col=0, parse_dates=True)\n",
    "\n",
    "gdp_growth = df['gdp_growth_qoq'].dropna()\n",
    "\n",
    "# TODO: Plot a histogram of gdp_growth with a fitted normal overlay\n",
    "mu_hat = ...  # sample mean\n",
    "sigma_hat = ...  # sample std\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.hist(gdp_growth, bins=20, density=True, alpha=0.5, color='steelblue',\n",
    "        edgecolor='black', label='GDP growth (QoQ)')\n",
    "\n",
    "x_range = np.linspace(gdp_growth.min() - 1, gdp_growth.max() + 1, 200)\n",
    "ax.plot(...)  # TODO: overlay fitted normal PDF\n",
    "\n",
    "ax.set_title('GDP Growth (QoQ) vs Fitted Normal')\n",
    "ax.set_xlabel('Growth rate')\n",
    "ax.set_ylabel('Density')\n",
    "ax.legend()\n",
    "plt.show()\n",
    "\n",
    "print(f'Mean: {mu_hat:.4f}, Std: {sigma_hat:.4f}')\n",
    "print(f'Skewness: {gdp_growth.skew():.4f}')\n",
    "print(f'Kurtosis: {gdp_growth.kurtosis():.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-sec2-turn3",
   "metadata": {},
   "source": [
    "### Your Turn (3): QQ Plot\n",
    "\n",
    "A **QQ (quantile-quantile) plot** compares the quantiles of your data to the quantiles of a theoretical distribution. If the data is normal, points fall on a straight line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-sec2-code3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create a QQ plot of GDP growth against the normal distribution\n",
    "fig, ax = plt.subplots()\n",
    "stats.probplot(...)  # TODO: pass gdp_growth and plot=ax\n",
    "ax.set_title('QQ Plot: GDP Growth vs Normal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-sec2-interp",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "\n",
    "**Write 2\u20134 sentences:**\n",
    "1. Does GDP growth appear normally distributed? What does the histogram tell you? What does the QQ plot tell you?\n",
    "2. If the data has excess kurtosis (fat tails), what does that mean for inference based on the normal assumption?\n",
    "\n",
    "*Your answer:*\n",
    "\n",
    "(write here)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-sec3-header",
   "metadata": {},
   "source": [
    "---\n",
    "<a id=\"the-t-distribution\"></a>\n",
    "## The t-Distribution\n",
    "\n",
    "### Goal\n",
    "Understand why we use the t-distribution instead of the normal for small-sample inference, and see how it converges to the normal as degrees of freedom increase.\n",
    "\n",
    "### Why this matters in economics\n",
    "Every coefficient t-test in a regression uses the t-distribution. With macroeconomic data you often have small samples (e.g., 80 quarters of GDP data). Using the normal when you should use the t-distribution understates uncertainty and produces overconfident p-values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-sec3-primer",
   "metadata": {},
   "source": [
    "### Primer\n",
    "\n",
    "The **t-distribution** with $\\nu$ degrees of freedom arises when you estimate the mean of a normal population but also have to estimate the variance from the same sample:\n",
    "\n",
    "$$\n",
    "t = \\frac{\\bar{X} - \\mu}{s / \\sqrt{n}} \\sim t_{n-1}\n",
    "$$\n",
    "\n",
    "Key properties:\n",
    "- Looks like a normal but with **heavier tails** (more probability in the extremes).\n",
    "- One parameter: $\\nu$ (degrees of freedom).\n",
    "- As $\\nu \\to \\infty$, the t-distribution converges to the standard normal.\n",
    "- For $\\nu > 30$, the difference is small but still matters for precise inference."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-sec3-turn1",
   "metadata": {},
   "source": [
    "### Your Turn (1): Compare t-distributions with different df to the Normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-sec3-code1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(-5, 5, 300)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(9, 5))\n",
    "\n",
    "# TODO: Plot the standard normal PDF\n",
    "ax.plot(x, stats.norm.pdf(x), 'k-', lw=2, label='Normal(0,1)')\n",
    "\n",
    "# TODO: Overlay t-distributions with df = 2, 5, 10, 30\n",
    "for df in [2, 5, 10, 30]:\n",
    "    ax.plot(...)  # TODO: stats.t.pdf(x, df=df), with label\n",
    "\n",
    "ax.set_title('t-Distributions vs Standard Normal')\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('Density')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-sec3-turn2",
   "metadata": {},
   "source": [
    "### Your Turn (2): Tail probabilities\n",
    "\n",
    "How much more probability mass is in the tails of a t-distribution compared to the normal?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-sec3-code2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Compute P(|X| > 2) for the normal and for t with df = 5, 10, 30\n",
    "# Hint: P(|X| > 2) = 2 * (1 - CDF(2))\n",
    "\n",
    "print('P(|X| > 2):')\n",
    "print(f'  Normal:    {2 * (1 - stats.norm.cdf(2)):.4f}')\n",
    "\n",
    "for df in [5, 10, 30]:\n",
    "    p = ...  # TODO: compute for t-distribution\n",
    "    print(f'  t(df={df:2d}):  {p:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-sec3-turn3",
   "metadata": {},
   "source": [
    "### Your Turn (3): Simulate convergence to Normal\n",
    "\n",
    "Draw many samples from a t-distribution with increasing df and compare histograms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-sec3-code3",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(42)\n",
    "n_samples = 10_000\n",
    "\n",
    "fig, axes = plt.subplots(1, 4, figsize=(16, 4), sharey=True)\n",
    "x_range = np.linspace(-5, 5, 200)\n",
    "\n",
    "for ax, df in zip(axes, [3, 10, 30, 100]):\n",
    "    # TODO: Simulate n_samples draws from t(df) and plot histogram\n",
    "    samples = ...  # stats.t.rvs(df=df, size=n_samples, random_state=rng)\n",
    "    ax.hist(samples, bins=60, density=True, alpha=0.5, color='steelblue')\n",
    "    # Overlay normal PDF for comparison\n",
    "    ax.plot(x_range, stats.norm.pdf(x_range), 'r-', lw=1.5, label='Normal')\n",
    "    ax.set_title(f't(df={df})')\n",
    "    ax.set_xlim(-5, 5)\n",
    "    ax.legend(fontsize=8)\n",
    "\n",
    "plt.suptitle('t-Distribution converges to Normal as df increases', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-sec3-interp",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "\n",
    "**Write 2\u20134 sentences:**\n",
    "1. At what df does the t-distribution become nearly indistinguishable from the normal?\n",
    "2. If you have 20 quarterly observations and 3 regressors (df = 16), how much wider would a 95% confidence interval be using the t-distribution compared to the normal?\n",
    "\n",
    "*Your answer:*\n",
    "\n",
    "(write here)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-sec4-header",
   "metadata": {},
   "source": [
    "---\n",
    "<a id=\"the-chi-squared-distribution\"></a>\n",
    "## The Chi-Squared Distribution\n",
    "\n",
    "### Goal\n",
    "Build intuition for the $\\chi^2$ distribution by constructing it from squared standard normals, and connect it to econometric tests.\n",
    "\n",
    "### Why this matters in economics\n",
    "The $\\chi^2$ distribution appears in:\n",
    "- **Breusch-Pagan test** for heteroskedasticity (non-constant error variance).\n",
    "- **Likelihood ratio tests** for nested model comparisons.\n",
    "- **Goodness-of-fit tests** for distributional assumptions.\n",
    "\n",
    "If you don't know what a $\\chi^2$ distribution looks like, these test statistics are just numbers without intuition."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-sec4-primer",
   "metadata": {},
   "source": [
    "### Primer\n",
    "\n",
    "If $Z_1, Z_2, \\ldots, Z_k$ are independent standard normals ($Z_i \\sim N(0,1)$), then:\n",
    "\n",
    "$$\n",
    "Q = Z_1^2 + Z_2^2 + \\cdots + Z_k^2 \\sim \\chi^2_k\n",
    "$$\n",
    "\n",
    "Key properties:\n",
    "- One parameter: $k$ (degrees of freedom).\n",
    "- Always non-negative (it is a sum of squares).\n",
    "- Mean = $k$, Variance = $2k$.\n",
    "- Right-skewed for small $k$; becomes more symmetric as $k$ grows."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-sec4-turn1",
   "metadata": {},
   "source": [
    "### Your Turn (1): Build $\\chi^2$ from squared normals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-sec4-code1",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(42)\n",
    "n_sims = 50_000\n",
    "k = 5  # degrees of freedom\n",
    "\n",
    "# TODO: Simulate k independent standard normals and sum their squares\n",
    "# Step 1: Generate a (n_sims, k) matrix of standard normals\n",
    "Z = ...  # rng.normal(size=(n_sims, k))\n",
    "\n",
    "# Step 2: Square each element and sum across columns\n",
    "Q = ...  # (Z ** 2).sum(axis=1)\n",
    "\n",
    "# Plot the simulated distribution against the theoretical chi-squared PDF\n",
    "fig, ax = plt.subplots()\n",
    "ax.hist(Q, bins=80, density=True, alpha=0.5, color='seagreen',\n",
    "        edgecolor='black', label=f'Simulated sum of {k} squared normals')\n",
    "\n",
    "x = np.linspace(0, 25, 200)\n",
    "ax.plot(x, stats.chi2.pdf(x, df=k), 'k-', lw=2,\n",
    "        label=f'$\\\\chi^2$({k}) PDF')\n",
    "\n",
    "ax.set_title(f'Chi-Squared from Squared Normals (k={k})')\n",
    "ax.set_xlabel('Q')\n",
    "ax.set_ylabel('Density')\n",
    "ax.legend()\n",
    "plt.show()\n",
    "\n",
    "print(f'Simulated mean: {Q.mean():.2f} (theoretical: {k})')\n",
    "print(f'Simulated var:  {Q.var():.2f} (theoretical: {2 * k})')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-sec4-turn2",
   "metadata": {},
   "source": [
    "### Your Turn (2): Different degrees of freedom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-sec4-code2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0, 30, 300)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(9, 5))\n",
    "\n",
    "# TODO: Plot chi-squared PDFs for df = 1, 2, 5, 10, 15\n",
    "for df in [1, 2, 5, 10, 15]:\n",
    "    ax.plot(...)  # TODO: stats.chi2.pdf(x, df=df), with label\n",
    "\n",
    "ax.set_title('Chi-Squared Distribution for Different df')\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('Density')\n",
    "ax.set_ylim(0, 0.5)\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-sec4-interp",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "\n",
    "**Write 2\u20134 sentences:**\n",
    "1. How does the shape of the $\\chi^2$ distribution change as df increases?\n",
    "2. In a Breusch-Pagan test with 3 regressors, the test statistic follows $\\chi^2(3)$. Looking at the plot, what values would you consider \"extreme\" (in the right tail)?\n",
    "\n",
    "*Your answer:*\n",
    "\n",
    "(write here)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-sec5-header",
   "metadata": {},
   "source": [
    "---\n",
    "<a id=\"the-f-distribution\"></a>\n",
    "## The F-Distribution\n",
    "\n",
    "### Goal\n",
    "Understand the F-distribution as a ratio of chi-squared variables and connect it to joint significance tests in regression.\n",
    "\n",
    "### Why this matters in economics\n",
    "The F-distribution appears whenever you test whether a *group* of coefficients are jointly zero:\n",
    "- The overall F-test in `statsmodels` output: \"Are all slope coefficients jointly zero?\"\n",
    "- Comparing nested models: \"Does adding these 3 variables significantly improve fit?\"\n",
    "- ANOVA tables.\n",
    "\n",
    "Understanding the F-distribution helps you interpret these tests rather than blindly trusting a p-value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-sec5-primer",
   "metadata": {},
   "source": [
    "### Primer\n",
    "\n",
    "If $U \\sim \\chi^2_{d_1}$ and $V \\sim \\chi^2_{d_2}$ are independent, then:\n",
    "\n",
    "$$\n",
    "F = \\frac{U / d_1}{V / d_2} \\sim F_{d_1, d_2}\n",
    "$$\n",
    "\n",
    "Key properties:\n",
    "- Two parameters: $d_1$ (numerator df) and $d_2$ (denominator df).\n",
    "- Always non-negative.\n",
    "- Right-skewed; becomes more symmetric as both df grow.\n",
    "- When $d_1 = 1$, the F-test is equivalent to a two-sided t-test (since $F = t^2$)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-sec5-turn1",
   "metadata": {},
   "source": [
    "### Your Turn (1): Simulate the F-distribution from chi-squared ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-sec5-code1",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(42)\n",
    "n_sims = 50_000\n",
    "d1, d2 = 3, 20  # numerator df, denominator df\n",
    "\n",
    "# TODO: Simulate chi-squared variables and compute their ratio\n",
    "U = ...  # stats.chi2.rvs(df=d1, size=n_sims, random_state=rng)\n",
    "V = ...  # stats.chi2.rvs(df=d2, size=n_sims, random_state=...)\n",
    "\n",
    "F_sim = ...  # (U / d1) / (V / d2)\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots()\n",
    "ax.hist(F_sim, bins=100, density=True, alpha=0.5, color='goldenrod',\n",
    "        edgecolor='black', label='Simulated F', range=(0, 8))\n",
    "\n",
    "x = np.linspace(0, 8, 300)\n",
    "ax.plot(x, stats.f.pdf(x, dfn=d1, dfd=d2), 'k-', lw=2,\n",
    "        label=f'F({d1},{d2}) PDF')\n",
    "\n",
    "ax.set_title(f'F-Distribution from Chi-Squared Ratio (d1={d1}, d2={d2})')\n",
    "ax.set_xlabel('F')\n",
    "ax.set_ylabel('Density')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-sec5-turn2",
   "metadata": {},
   "source": [
    "### Your Turn (2): F-distributions with different parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-sec5-code2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0.01, 5, 300)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(9, 5))\n",
    "\n",
    "# TODO: Plot F-distribution PDFs for different (d1, d2) combinations\n",
    "params = [(1, 10), (3, 20), (5, 50), (10, 100)]\n",
    "for d1, d2 in params:\n",
    "    ax.plot(...)  # TODO: stats.f.pdf(x, dfn=d1, dfd=d2), with label\n",
    "\n",
    "ax.set_title('F-Distributions with Different Parameters')\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('Density')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-sec5-turn3",
   "metadata": {},
   "source": [
    "### Your Turn (3): Critical values\n",
    "\n",
    "In regression output, you reject the null if the F-statistic exceeds a critical value. Find the 95th percentile (critical value at $\\alpha = 0.05$) for different F-distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-sec5-code3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Compute the 95th percentile of F(d1, d2) for several (d1, d2) pairs\n",
    "print('F critical values (alpha = 0.05):')\n",
    "for d1, d2 in [(1, 50), (3, 50), (5, 50), (3, 20), (3, 100)]:\n",
    "    cv = ...  # stats.f.ppf(0.95, dfn=d1, dfd=d2)\n",
    "    print(f'  F({d1:2d}, {d2:3d}): {cv:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-sec5-interp",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "\n",
    "**Write 2\u20134 sentences:**\n",
    "1. How does increasing the denominator df (more observations) affect the critical value?\n",
    "2. Why does the F-test become harder to reject (larger critical value) when you add more restrictions (larger $d_1$)?\n",
    "\n",
    "*Your answer:*\n",
    "\n",
    "(write here)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-sec6-header",
   "metadata": {},
   "source": [
    "---\n",
    "<a id=\"discrete-distributions\"></a>\n",
    "## Discrete Distributions: Binomial and Poisson\n",
    "\n",
    "### Goal\n",
    "Understand two important discrete distributions and connect them to economic counting problems.\n",
    "\n",
    "### Why this matters in economics\n",
    "- **Binomial**: How many quarters in a decade are recessions? If each quarter has probability $p$ of being a recession, the count follows $\\text{Binomial}(n, p)$.\n",
    "- **Poisson**: How many Federal Reserve rate changes occur per year? How many financial crises per decade? Count data in a fixed interval often follows a Poisson distribution.\n",
    "\n",
    "These distributions underpin count-data regression models (Poisson regression, logistic regression) that appear later in the project."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-sec6-primer",
   "metadata": {},
   "source": [
    "### Primer\n",
    "\n",
    "**Binomial$(n, p)$**:\n",
    "- $n$ independent trials, each with success probability $p$.\n",
    "- $X$ = number of successes.\n",
    "- PMF: $P(X = k) = \\binom{n}{k} p^k (1-p)^{n-k}$\n",
    "- Mean = $np$, Variance = $np(1-p)$.\n",
    "\n",
    "**Poisson$(\\lambda)$**:\n",
    "- Counts events in a fixed interval when events occur independently at rate $\\lambda$.\n",
    "- PMF: $P(X = k) = \\frac{\\lambda^k e^{-\\lambda}}{k!}$\n",
    "- Mean = $\\lambda$, Variance = $\\lambda$ (mean equals variance).\n",
    "- The Poisson approximates $\\text{Binomial}(n, p)$ when $n$ is large and $p$ is small, with $\\lambda = np$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-sec6-turn1",
   "metadata": {},
   "source": [
    "### Your Turn (1): Binomial -- recession quarters in a decade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-sec6-code1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A decade has 40 quarters. Historically, about 15% of quarters are recessions.\n",
    "n_quarters = 40\n",
    "p_recession = 0.15\n",
    "\n",
    "rng = np.random.default_rng(42)\n",
    "\n",
    "# TODO: Simulate 10,000 decades and count recession quarters in each\n",
    "sim_counts = ...  # rng.binomial(n=n_quarters, p=p_recession, size=10_000)\n",
    "\n",
    "# TODO: Plot the PMF (theoretical) and the simulated histogram\n",
    "k = np.arange(0, 20)\n",
    "pmf_vals = ...  # stats.binom.pmf(k, n=n_quarters, p=p_recession)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.bar(k - 0.2, pmf_vals, width=0.4, color='steelblue', alpha=0.8,\n",
    "       edgecolor='black', label='Theoretical PMF')\n",
    "\n",
    "# Simulated (normalized to compare with PMF)\n",
    "counts, edges = np.histogram(sim_counts, bins=np.arange(-0.5, 20.5, 1), density=True)\n",
    "ax.bar(np.arange(0, 20) + 0.2, counts, width=0.4, color='coral', alpha=0.8,\n",
    "       edgecolor='black', label='Simulated')\n",
    "\n",
    "ax.set_title(f'Recession Quarters per Decade: Binomial({n_quarters}, {p_recession})')\n",
    "ax.set_xlabel('Number of recession quarters')\n",
    "ax.set_ylabel('Probability')\n",
    "ax.legend()\n",
    "plt.show()\n",
    "\n",
    "print(f'Expected: {n_quarters * p_recession:.1f} recession quarters per decade')\n",
    "print(f'Simulated mean: {sim_counts.mean():.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-sec6-turn2",
   "metadata": {},
   "source": [
    "### Your Turn (2): Poisson -- rate changes per year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-sec6-code2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppose the Fed changes rates on average 4 times per year.\n",
    "lam = 4\n",
    "\n",
    "rng = np.random.default_rng(42)\n",
    "\n",
    "# TODO: Simulate 10,000 years of rate-change counts\n",
    "sim_poisson = ...  # rng.poisson(lam=lam, size=10_000)\n",
    "\n",
    "# TODO: Plot PMF and simulated histogram\n",
    "k = np.arange(0, 15)\n",
    "pmf_vals = ...  # stats.poisson.pmf(k, mu=lam)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.bar(k - 0.2, pmf_vals, width=0.4, color='steelblue', alpha=0.8,\n",
    "       edgecolor='black', label='Theoretical PMF')\n",
    "\n",
    "counts, _ = np.histogram(sim_poisson, bins=np.arange(-0.5, 15.5, 1), density=True)\n",
    "ax.bar(np.arange(0, 15) + 0.2, counts[:15], width=0.4, color='coral', alpha=0.8,\n",
    "       edgecolor='black', label='Simulated')\n",
    "\n",
    "ax.set_title(f'Fed Rate Changes per Year: Poisson($\\\\lambda$={lam})')\n",
    "ax.set_xlabel('Number of rate changes')\n",
    "ax.set_ylabel('Probability')\n",
    "ax.legend()\n",
    "plt.show()\n",
    "\n",
    "print(f'Mean = Variance = {lam}')\n",
    "print(f'Simulated mean: {sim_poisson.mean():.2f}, variance: {sim_poisson.var():.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-sec6-turn3",
   "metadata": {},
   "source": [
    "### Your Turn (3): Poisson as limit of Binomial\n",
    "\n",
    "Show that $\\text{Binomial}(n, p)$ with $n$ large and $p$ small approaches $\\text{Poisson}(\\lambda = np)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-sec6-code3",
   "metadata": {},
   "outputs": [],
   "source": [
    "lam = 3\n",
    "k = np.arange(0, 15)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# TODO: Plot Poisson(3) PMF\n",
    "ax.plot(k, stats.poisson.pmf(k, mu=lam), 'ko-', ms=6, lw=2,\n",
    "        label=f'Poisson({lam})', zorder=5)\n",
    "\n",
    "# TODO: Overlay Binomial(n, p) with n = 10, 30, 100, 500 (keeping np = 3)\n",
    "for n_val in [10, 30, 100, 500]:\n",
    "    p_val = ...  # lam / n_val\n",
    "    ax.plot(...)  # TODO: stats.binom.pmf(k, n=n_val, p=p_val)\n",
    "\n",
    "ax.set_title('Binomial approaches Poisson as n grows (np = 3)')\n",
    "ax.set_xlabel('k')\n",
    "ax.set_ylabel('P(X = k)')\n",
    "ax.legend(fontsize=9)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-sec6-interp",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "\n",
    "**Write 2\u20134 sentences:**\n",
    "1. In the Binomial recession example, what is the probability of having zero recession quarters in a decade? Is that surprising?\n",
    "2. For the Poisson, the mean equals the variance. If you observed that the variance of rate changes was much larger than the mean, what would that suggest about the Poisson assumption?\n",
    "\n",
    "*Your answer:*\n",
    "\n",
    "(write here)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-sec7-header",
   "metadata": {},
   "source": [
    "---\n",
    "<a id=\"comparing-distributions-with-real-data\"></a>\n",
    "## Comparing Distributions with Real Data\n",
    "\n",
    "### Goal\n",
    "Practice fitting distributions to real economic data and evaluating goodness of fit.\n",
    "\n",
    "### Why this matters in economics\n",
    "In practice, you rarely know the true distribution. You observe data and ask: \"Which distribution does this most resemble?\" This skill is essential for choosing the right model and understanding when standard assumptions (like normality) are violated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-sec7-turn1",
   "metadata": {},
   "source": [
    "### Your Turn (1): Load data and explore candidate columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-sec7-code1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(SAMPLE_DIR / 'macro_quarterly_sample.csv', index_col=0, parse_dates=True)\n",
    "\n",
    "# Preview the data\n",
    "print('Columns:', list(df.columns))\n",
    "print(f'Shape: {df.shape}')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-sec7-turn2",
   "metadata": {},
   "source": [
    "### Your Turn (2): Fit and compare distributions on a chosen variable\n",
    "\n",
    "Pick a column (e.g., `UNRATE`, `FEDFUNDS`, `gdp_growth_qoq`, or `gdp_growth_yoy`) and overlay fitted normal and t-distribution PDFs on its histogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-sec7-code2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Choose a column to analyze\n",
    "col = ...  # e.g., 'gdp_growth_yoy'\n",
    "series = df[col].dropna()\n",
    "\n",
    "# TODO: Fit a normal distribution to the data\n",
    "mu_fit, sigma_fit = ...  # stats.norm.fit(series)\n",
    "\n",
    "# TODO: Fit a t-distribution to the data\n",
    "df_fit, loc_fit, scale_fit = ...  # stats.t.fit(series)\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(9, 5))\n",
    "ax.hist(series, bins=25, density=True, alpha=0.5, color='steelblue',\n",
    "        edgecolor='black', label=f'{col} (data)')\n",
    "\n",
    "x = np.linspace(series.min() - 1, series.max() + 1, 200)\n",
    "\n",
    "# TODO: Overlay normal fit\n",
    "ax.plot(...)  # stats.norm.pdf(x, loc=mu_fit, scale=sigma_fit)\n",
    "\n",
    "# TODO: Overlay t-distribution fit\n",
    "ax.plot(...)  # stats.t.pdf(x, df=df_fit, loc=loc_fit, scale=scale_fit)\n",
    "\n",
    "ax.set_title(f'Distribution Fits: {col}')\n",
    "ax.set_xlabel(col)\n",
    "ax.set_ylabel('Density')\n",
    "ax.legend()\n",
    "plt.show()\n",
    "\n",
    "print(f'Normal fit: mu={mu_fit:.3f}, sigma={sigma_fit:.3f}')\n",
    "print(f't fit: df={df_fit:.1f}, loc={loc_fit:.3f}, scale={scale_fit:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-sec7-turn3",
   "metadata": {},
   "source": [
    "### Your Turn (3): QQ plots for both fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-sec7-code3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# TODO: QQ plot against normal\n",
    "stats.probplot(...)  # series, dist='norm', plot=axes[0]\n",
    "axes[0].set_title(f'{col}: QQ vs Normal')\n",
    "\n",
    "# TODO: QQ plot against t-distribution (use fitted df)\n",
    "stats.probplot(...)  # series, dist=stats.t, sparams=(df_fit,), plot=axes[1]\n",
    "axes[1].set_title(f'{col}: QQ vs t(df={df_fit:.0f})')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-sec7-interp",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "\n",
    "**Write 2\u20134 sentences:**\n",
    "1. Which distribution (normal or t) fits the data better? How can you tell from the histogram and QQ plots?\n",
    "2. If neither fits well, what features of the data (skewness, multiple modes, outliers) might explain the poor fit?\n",
    "\n",
    "*Your answer:*\n",
    "\n",
    "(write here)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-later",
   "metadata": {},
   "source": [
    "---\n",
    "## Where This Shows Up Later\n",
    "\n",
    "The distributions you studied in this notebook are not abstract -- they appear throughout the rest of the project:\n",
    "\n",
    "| Distribution | Where it appears | Notebook |\n",
    "|---|---|---|\n",
    "| **Normal** | CLT justification for large-sample inference; assumed error distribution in OLS | Throughout `02_regression/` |\n",
    "| **t-distribution** | Coefficient t-tests, confidence intervals for individual parameters | `02_regression/04_inference_time_series_hac` |\n",
    "| **Chi-squared** | Breusch-Pagan test for heteroskedasticity, White test, likelihood ratio tests | `02_regression/04a_residual_diagnostics` |\n",
    "| **F-distribution** | Overall regression F-test, nested model comparisons, joint significance | F-tests throughout `02_regression/` |\n",
    "| **Binomial** | Recession classification (binary outcomes) | `03_classification/01_logistic_recession_classifier` |\n",
    "| **Poisson** | Count-data modeling (if extended) | Optional extensions |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-checkpoint",
   "metadata": {},
   "source": [
    "---\n",
    "<a id=\"checkpoint-self-check\"></a>\n",
    "## Checkpoint (Self-Check)\n",
    "\n",
    "Run the cell below to verify you completed the key exercises. Then answer the questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-checkpoint-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick sanity checks -- these should pass if you completed the notebook.\n",
    "# Uncomment and adapt as needed.\n",
    "\n",
    "# assert 'normal_data' in dir(), 'Did you simulate normal data in Section 2?'\n",
    "# assert len(normal_data) == 5000, 'Expected 5000 draws.'\n",
    "# assert 'Q' in dir(), 'Did you simulate chi-squared in Section 4?'\n",
    "# assert Q.mean() > 3 and Q.mean() < 7, 'Chi-squared mean should be near k=5.'\n",
    "# assert 'sim_counts' in dir(), 'Did you simulate Binomial in Section 6?'\n",
    "# assert 'sim_poisson' in dir(), 'Did you simulate Poisson in Section 6?'\n",
    "\n",
    "print('All checkpoint assertions passed (uncomment them first).')\n",
    "\n",
    "# TODO: Write 2\u20133 sentences:\n",
    "# - Can you name all six distributions covered and one econometric context for each?\n",
    "# - Which distribution surprised you the most and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-extensions",
   "metadata": {},
   "source": [
    "---\n",
    "## Extensions (Optional)\n",
    "- **Shapiro-Wilk test**: Use `stats.shapiro()` to formally test normality of GDP growth. Compare the p-value with your visual assessment from the QQ plot.\n",
    "- **Log-normal distribution**: Many economic variables (income, firm size, stock prices) follow a log-normal rather than a normal. Try `stats.lognorm` on unemployment or CPI levels.\n",
    "- **Kolmogorov-Smirnov test**: Use `stats.kstest()` to compare your data against a fitted distribution. This generalizes beyond normality.\n",
    "- **Mixture distributions**: Real macro data often looks like it comes from two regimes (expansion vs recession). Simulate a mixture of two normals and see how the histogram looks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-reflection",
   "metadata": {},
   "source": [
    "---\n",
    "## Reflection\n",
    "\n",
    "**Write 2\u20134 sentences for each:**\n",
    "\n",
    "1. Which distribution assumption do you think is most commonly violated in macroeconomic data, and what are the consequences for inference?\n",
    "\n",
    "2. If you had to explain to a non-technical colleague why we use the t-distribution instead of the normal for small samples, how would you phrase it?\n",
    "\n",
    "3. What did you learn in this notebook that changes how you will interpret regression output going forward?\n",
    "\n",
    "*Your answers:*\n",
    "\n",
    "(write here)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-solutions",
   "metadata": {},
   "source": [
    "---\n",
    "<a id=\"solutions-reference\"></a>\n",
    "## Solutions (Reference)\n",
    "\n",
    "Try the TODOs first. Use these only to unblock yourself or to compare approaches.\n",
    "\n",
    "<details><summary>Solution: The Normal distribution</summary>\n",
    "\n",
    "_One possible approach. Your variable names may differ; align them with the notebook._\n",
    "\n",
    "```python\n",
    "# --- Your Turn (1): Simulate and visualize Normal data ---\n",
    "rng = np.random.default_rng(42)\n",
    "mu, sigma = 2, 1.5\n",
    "normal_data = rng.normal(loc=mu, scale=sigma, size=5000)\n",
    "\n",
    "x = np.linspace(mu - 4 * sigma, mu + 4 * sigma, 200)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.hist(normal_data, bins=50, density=True, alpha=0.5, color='steelblue',\n",
    "        edgecolor='black', label='Simulated data')\n",
    "ax.plot(x, stats.norm.pdf(x, loc=mu, scale=sigma), 'darkred', lw=2,\n",
    "        label='Theoretical PDF')\n",
    "ax.set_title('Normal Distribution: Simulated vs Theoretical')\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('Density')\n",
    "ax.legend()\n",
    "plt.show()\n",
    "\n",
    "# --- Your Turn (2): GDP growth ---\n",
    "import pandas as pd\n",
    "df = pd.read_csv(SAMPLE_DIR / 'macro_quarterly_sample.csv', index_col=0, parse_dates=True)\n",
    "gdp_growth = df['gdp_growth_qoq'].dropna()\n",
    "\n",
    "mu_hat = gdp_growth.mean()\n",
    "sigma_hat = gdp_growth.std()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.hist(gdp_growth, bins=20, density=True, alpha=0.5, color='steelblue',\n",
    "        edgecolor='black', label='GDP growth (QoQ)')\n",
    "x_range = np.linspace(gdp_growth.min() - 1, gdp_growth.max() + 1, 200)\n",
    "ax.plot(x_range, stats.norm.pdf(x_range, loc=mu_hat, scale=sigma_hat),\n",
    "        'darkred', lw=2, label='Fitted Normal')\n",
    "ax.set_title('GDP Growth (QoQ) vs Fitted Normal')\n",
    "ax.set_xlabel('Growth rate')\n",
    "ax.set_ylabel('Density')\n",
    "ax.legend()\n",
    "plt.show()\n",
    "\n",
    "# --- Your Turn (3): QQ plot ---\n",
    "fig, ax = plt.subplots()\n",
    "stats.probplot(gdp_growth, dist='norm', plot=ax)\n",
    "ax.set_title('QQ Plot: GDP Growth vs Normal')\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "<details><summary>Solution: The t-distribution</summary>\n",
    "\n",
    "_One possible approach. Your variable names may differ; align them with the notebook._\n",
    "\n",
    "```python\n",
    "# --- Your Turn (1): Compare t-distributions to Normal ---\n",
    "x = np.linspace(-5, 5, 300)\n",
    "fig, ax = plt.subplots(figsize=(9, 5))\n",
    "ax.plot(x, stats.norm.pdf(x), 'k-', lw=2, label='Normal(0,1)')\n",
    "for df in [2, 5, 10, 30]:\n",
    "    ax.plot(x, stats.t.pdf(x, df=df), '--', lw=1.5, label=f't(df={df})')\n",
    "ax.set_title('t-Distributions vs Standard Normal')\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('Density')\n",
    "ax.legend()\n",
    "plt.show()\n",
    "\n",
    "# --- Your Turn (2): Tail probabilities ---\n",
    "print('P(|X| > 2):')\n",
    "print(f'  Normal:    {2 * (1 - stats.norm.cdf(2)):.4f}')\n",
    "for df in [5, 10, 30]:\n",
    "    p = 2 * (1 - stats.t.cdf(2, df=df))\n",
    "    print(f'  t(df={df:2d}):  {p:.4f}')\n",
    "\n",
    "# --- Your Turn (3): Simulate convergence ---\n",
    "rng = np.random.default_rng(42)\n",
    "n_samples = 10_000\n",
    "fig, axes = plt.subplots(1, 4, figsize=(16, 4), sharey=True)\n",
    "x_range = np.linspace(-5, 5, 200)\n",
    "for ax, df in zip(axes, [3, 10, 30, 100]):\n",
    "    samples = stats.t.rvs(df=df, size=n_samples, random_state=rng)\n",
    "    ax.hist(samples, bins=60, density=True, alpha=0.5, color='steelblue')\n",
    "    ax.plot(x_range, stats.norm.pdf(x_range), 'r-', lw=1.5, label='Normal')\n",
    "    ax.set_title(f't(df={df})')\n",
    "    ax.set_xlim(-5, 5)\n",
    "    ax.legend(fontsize=8)\n",
    "plt.suptitle('t-Distribution converges to Normal as df increases', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "<details><summary>Solution: The Chi-Squared distribution</summary>\n",
    "\n",
    "_One possible approach. Your variable names may differ; align them with the notebook._\n",
    "\n",
    "```python\n",
    "# --- Your Turn (1): Build chi-squared from squared normals ---\n",
    "rng = np.random.default_rng(42)\n",
    "n_sims = 50_000\n",
    "k = 5\n",
    "Z = rng.normal(size=(n_sims, k))\n",
    "Q = (Z ** 2).sum(axis=1)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.hist(Q, bins=80, density=True, alpha=0.5, color='seagreen',\n",
    "        edgecolor='black', label=f'Simulated sum of {k} squared normals')\n",
    "x = np.linspace(0, 25, 200)\n",
    "ax.plot(x, stats.chi2.pdf(x, df=k), 'k-', lw=2, label=f'chi2({k}) PDF')\n",
    "ax.set_title(f'Chi-Squared from Squared Normals (k={k})')\n",
    "ax.set_xlabel('Q')\n",
    "ax.set_ylabel('Density')\n",
    "ax.legend()\n",
    "plt.show()\n",
    "\n",
    "# --- Your Turn (2): Different degrees of freedom ---\n",
    "x = np.linspace(0, 30, 300)\n",
    "fig, ax = plt.subplots(figsize=(9, 5))\n",
    "for df in [1, 2, 5, 10, 15]:\n",
    "    ax.plot(x, stats.chi2.pdf(x, df=df), lw=2, label=f'chi2(df={df})')\n",
    "ax.set_title('Chi-Squared Distribution for Different df')\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('Density')\n",
    "ax.set_ylim(0, 0.5)\n",
    "ax.legend()\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "<details><summary>Solution: The F-distribution</summary>\n",
    "\n",
    "_One possible approach. Your variable names may differ; align them with the notebook._\n",
    "\n",
    "```python\n",
    "# --- Your Turn (1): Simulate F from chi-squared ratios ---\n",
    "rng = np.random.default_rng(42)\n",
    "n_sims = 50_000\n",
    "d1, d2 = 3, 20\n",
    "U = stats.chi2.rvs(df=d1, size=n_sims, random_state=rng)\n",
    "V = stats.chi2.rvs(df=d2, size=n_sims, random_state=np.random.default_rng(99))\n",
    "F_sim = (U / d1) / (V / d2)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.hist(F_sim, bins=100, density=True, alpha=0.5, color='goldenrod',\n",
    "        edgecolor='black', label='Simulated F', range=(0, 8))\n",
    "x = np.linspace(0, 8, 300)\n",
    "ax.plot(x, stats.f.pdf(x, dfn=d1, dfd=d2), 'k-', lw=2,\n",
    "        label=f'F({d1},{d2}) PDF')\n",
    "ax.set_title(f'F-Distribution from Chi-Squared Ratio (d1={d1}, d2={d2})')\n",
    "ax.set_xlabel('F')\n",
    "ax.set_ylabel('Density')\n",
    "ax.legend()\n",
    "plt.show()\n",
    "\n",
    "# --- Your Turn (2): Different parameters ---\n",
    "x = np.linspace(0.01, 5, 300)\n",
    "fig, ax = plt.subplots(figsize=(9, 5))\n",
    "for d1, d2 in [(1, 10), (3, 20), (5, 50), (10, 100)]:\n",
    "    ax.plot(x, stats.f.pdf(x, dfn=d1, dfd=d2), lw=2,\n",
    "            label=f'F({d1},{d2})')\n",
    "ax.set_title('F-Distributions with Different Parameters')\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('Density')\n",
    "ax.legend()\n",
    "plt.show()\n",
    "\n",
    "# --- Your Turn (3): Critical values ---\n",
    "print('F critical values (alpha = 0.05):')\n",
    "for d1, d2 in [(1, 50), (3, 50), (5, 50), (3, 20), (3, 100)]:\n",
    "    cv = stats.f.ppf(0.95, dfn=d1, dfd=d2)\n",
    "    print(f'  F({d1:2d}, {d2:3d}): {cv:.3f}')\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "<details><summary>Solution: Discrete distributions (Binomial and Poisson)</summary>\n",
    "\n",
    "_One possible approach. Your variable names may differ; align them with the notebook._\n",
    "\n",
    "```python\n",
    "# --- Your Turn (1): Binomial ---\n",
    "n_quarters = 40\n",
    "p_recession = 0.15\n",
    "rng = np.random.default_rng(42)\n",
    "sim_counts = rng.binomial(n=n_quarters, p=p_recession, size=10_000)\n",
    "\n",
    "k = np.arange(0, 20)\n",
    "pmf_vals = stats.binom.pmf(k, n=n_quarters, p=p_recession)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.bar(k - 0.2, pmf_vals, width=0.4, color='steelblue', alpha=0.8,\n",
    "       edgecolor='black', label='Theoretical PMF')\n",
    "counts, edges = np.histogram(sim_counts, bins=np.arange(-0.5, 20.5, 1), density=True)\n",
    "ax.bar(np.arange(0, 20) + 0.2, counts, width=0.4, color='coral', alpha=0.8,\n",
    "       edgecolor='black', label='Simulated')\n",
    "ax.set_title(f'Recession Quarters per Decade: Binomial({n_quarters}, {p_recession})')\n",
    "ax.set_xlabel('Number of recession quarters')\n",
    "ax.set_ylabel('Probability')\n",
    "ax.legend()\n",
    "plt.show()\n",
    "\n",
    "# --- Your Turn (2): Poisson ---\n",
    "lam = 4\n",
    "rng = np.random.default_rng(42)\n",
    "sim_poisson = rng.poisson(lam=lam, size=10_000)\n",
    "\n",
    "k = np.arange(0, 15)\n",
    "pmf_vals = stats.poisson.pmf(k, mu=lam)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.bar(k - 0.2, pmf_vals, width=0.4, color='steelblue', alpha=0.8,\n",
    "       edgecolor='black', label='Theoretical PMF')\n",
    "counts, _ = np.histogram(sim_poisson, bins=np.arange(-0.5, 15.5, 1), density=True)\n",
    "ax.bar(np.arange(0, 15) + 0.2, counts[:15], width=0.4, color='coral', alpha=0.8,\n",
    "       edgecolor='black', label='Simulated')\n",
    "ax.set_title(f'Fed Rate Changes per Year: Poisson(lambda={lam})')\n",
    "ax.set_xlabel('Number of rate changes')\n",
    "ax.set_ylabel('Probability')\n",
    "ax.legend()\n",
    "plt.show()\n",
    "\n",
    "# --- Your Turn (3): Poisson as limit of Binomial ---\n",
    "lam = 3\n",
    "k = np.arange(0, 15)\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(k, stats.poisson.pmf(k, mu=lam), 'ko-', ms=6, lw=2,\n",
    "        label=f'Poisson({lam})', zorder=5)\n",
    "for n_val in [10, 30, 100, 500]:\n",
    "    p_val = lam / n_val\n",
    "    ax.plot(k, stats.binom.pmf(k, n=n_val, p=p_val), 'o--', ms=4,\n",
    "            label=f'Binom({n_val}, {p_val:.3f})')\n",
    "ax.set_title('Binomial approaches Poisson as n grows (np = 3)')\n",
    "ax.set_xlabel('k')\n",
    "ax.set_ylabel('P(X = k)')\n",
    "ax.legend(fontsize=9)\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "<details><summary>Solution: Comparing distributions with real data</summary>\n",
    "\n",
    "_One possible approach. Your variable names may differ; align them with the notebook._\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "df = pd.read_csv(SAMPLE_DIR / 'macro_quarterly_sample.csv', index_col=0, parse_dates=True)\n",
    "\n",
    "col = 'gdp_growth_yoy'\n",
    "series = df[col].dropna()\n",
    "\n",
    "# Fit normal\n",
    "mu_fit, sigma_fit = stats.norm.fit(series)\n",
    "\n",
    "# Fit t-distribution\n",
    "df_fit, loc_fit, scale_fit = stats.t.fit(series)\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(9, 5))\n",
    "ax.hist(series, bins=25, density=True, alpha=0.5, color='steelblue',\n",
    "        edgecolor='black', label=f'{col} (data)')\n",
    "x = np.linspace(series.min() - 1, series.max() + 1, 200)\n",
    "ax.plot(x, stats.norm.pdf(x, loc=mu_fit, scale=sigma_fit),\n",
    "        'darkred', lw=2, label=f'Normal(mu={mu_fit:.2f}, sigma={sigma_fit:.2f})')\n",
    "ax.plot(x, stats.t.pdf(x, df=df_fit, loc=loc_fit, scale=scale_fit),\n",
    "        'darkblue', lw=2, ls='--',\n",
    "        label=f't(df={df_fit:.1f}, loc={loc_fit:.2f}, scale={scale_fit:.2f})')\n",
    "ax.set_title(f'Distribution Fits: {col}')\n",
    "ax.set_xlabel(col)\n",
    "ax.set_ylabel('Density')\n",
    "ax.legend()\n",
    "plt.show()\n",
    "\n",
    "# QQ plots\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "stats.probplot(series, dist='norm', plot=axes[0])\n",
    "axes[0].set_title(f'{col}: QQ vs Normal')\n",
    "stats.probplot(series, dist=stats.t, sparams=(df_fit,), plot=axes[1])\n",
    "axes[1].set_title(f'{col}: QQ vs t(df={df_fit:.0f})')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "</details>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
