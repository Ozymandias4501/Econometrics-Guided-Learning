{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-title",
   "metadata": {},
   "source": [
    "# 04 Confidence Intervals\n",
    "\n",
    "Quantifying uncertainty: how to construct, interpret, and visualize confidence intervals correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-toc",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "- [What is a confidence interval?](#what-is-a-confidence-interval)\n",
    "- [Constructing a CI for the mean](#constructing-a-ci-for-the-mean)\n",
    "- [Visualizing the repeated sampling interpretation](#visualizing-the-repeated-sampling-interpretation)\n",
    "- [Effect of sample size on CI width](#effect-of-sample-size-on-ci-width)\n",
    "- [Effect of confidence level on CI width](#effect-of-confidence-level-on-ci-width)\n",
    "- [Confidence intervals for regression coefficients](#confidence-intervals-for-regression-coefficients)\n",
    "- [Margin of error and practical significance](#margin-of-error-and-practical-significance)\n",
    "- [Checkpoint (Self-Check)](#checkpoint-self-check)\n",
    "- [Solutions (Reference)](#solutions-reference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-why",
   "metadata": {},
   "source": [
    "## Why This Notebook Matters\n",
    "Confidence intervals appear in every regression table, every policy report, and every\n",
    "empirical paper. They are arguably more useful than p-values because they convey both\n",
    "the direction and magnitude of uncertainty. Yet they are among the most commonly\n",
    "misinterpreted statistics. This notebook builds the correct intuition through simulation.\n",
    "\n",
    "## Prerequisites (Quick Self-Check)\n",
    "- Completed notebooks 00-03 (descriptive stats, distributions, CLT, z-scores).\n",
    "- Understanding of the normal and t-distributions.\n",
    "- Understanding of the standard error of the mean.\n",
    "\n",
    "## What You Will Produce\n",
    "- (no file output; learning/analysis notebook)\n",
    "\n",
    "## Success Criteria\n",
    "- You can construct a confidence interval for a mean using both z and t approaches.\n",
    "- You can correctly state what a 95% CI means (and what it does NOT mean).\n",
    "- You can explain how sample size and confidence level affect CI width.\n",
    "- You can interpret CIs for regression coefficients.\n",
    "\n",
    "## Common Pitfalls\n",
    "- Saying \"there is a 95% probability the true mean is in this interval\" (WRONG).\n",
    "- Using z-critical values when the sample is small (use t instead).\n",
    "- Ignoring CI width and focusing only on whether it contains zero.\n",
    "- Confusing statistical precision (narrow CI) with practical importance.\n",
    "\n",
    "## Quick Fixes (When You Get Stuck)\n",
    "- For a 95% CI, the t-critical value with large n is approximately 1.96.\n",
    "- `scipy.stats.t.interval(confidence, df, loc, scale)` computes the interval directly.\n",
    "- In statsmodels: `res.conf_int(alpha=0.05)` gives 95% CIs for all coefficients.\n",
    "- If you see `ModuleNotFoundError`, re-run the bootstrap cell.\n",
    "\n",
    "## Matching Guide\n",
    "- `docs/guides/00_statistics_primer/04_confidence_intervals.md`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-howto",
   "metadata": {},
   "source": [
    "## How To Use This Notebook\n",
    "- Work section-by-section; don't skip the markdown.\n",
    "- Most code cells are incomplete on purpose: replace TODOs and `...`, then run.\n",
    "- After each section, write 2\u20134 sentences answering the interpretation prompts (what changed, why it matters).\n",
    "- Prefer `data/processed/*` if you have built the real datasets; otherwise use the bundled `data/sample/*` fallbacks.\n",
    "- Use the **Checkpoint (Self-Check)** section to catch mistakes early.\n",
    "- Use **Solutions (Reference)** only to unblock yourself; then re-implement without looking.\n",
    "- Use the matching guide (`docs/guides/00_statistics_primer/04_confidence_intervals.md`) for the math, assumptions, and deeper context."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-bootstrap-header",
   "metadata": {},
   "source": [
    "<a id=\"environment-bootstrap\"></a>\n",
    "## Environment Bootstrap\n",
    "Run this cell first. It makes the repo importable and defines common directories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-bootstrap",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "\n",
    "def find_repo_root(start: Path) -> Path:\n",
    "    p = start\n",
    "    for _ in range(8):\n",
    "        if (p / 'src').exists() and (p / 'docs').exists():\n",
    "            return p\n",
    "        p = p.parent\n",
    "    raise RuntimeError('Could not find repo root. Start Jupyter from the repo root.')\n",
    "\n",
    "\n",
    "PROJECT_ROOT = find_repo_root(Path.cwd())\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.append(str(PROJECT_ROOT))\n",
    "\n",
    "DATA_DIR = PROJECT_ROOT / 'data'\n",
    "RAW_DIR = DATA_DIR / 'raw'\n",
    "PROCESSED_DIR = DATA_DIR / 'processed'\n",
    "SAMPLE_DIR = DATA_DIR / 'sample'\n",
    "\n",
    "PROJECT_ROOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "plt.rcParams['figure.dpi'] = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-load-header",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "\n",
    "We load macroeconomic quarterly data. The GDP growth columns give us a realistic\n",
    "economic variable to build confidence intervals around."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-load-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(SAMPLE_DIR / 'macro_quarterly_sample.csv', index_col=0, parse_dates=True)\n",
    "print(f'Shape: {df.shape}')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-s1-header",
   "metadata": {},
   "source": [
    "<a id=\"what-is-a-confidence-interval\"></a>\n",
    "## What is a confidence interval?\n",
    "\n",
    "### Goal\n",
    "Understand the precise definition of a confidence interval and dispel the most common\n",
    "misconception about its interpretation.\n",
    "\n",
    "### Why this matters in economics\n",
    "Every empirical paper, policy brief, and regression table reports confidence intervals.\n",
    "Misinterpreting them leads to overconfident policy recommendations and flawed conclusions.\n",
    "Getting the definition right is not pedantry \u2014 it changes how you think about uncertainty.\n",
    "\n",
    "---\n",
    "\n",
    "### Definition\n",
    "\n",
    "A **confidence interval** is a range constructed from sample data using a procedure\n",
    "that, **across repeated samples**, captures the true population parameter a specified\n",
    "fraction of the time.\n",
    "\n",
    "For a 95% CI:\n",
    "- If you could draw 100 independent samples and build a 95% CI from each,\n",
    "  approximately 95 of those intervals would contain the true parameter.\n",
    "- The remaining ~5 would miss it entirely.\n",
    "\n",
    "### The critical misconception\n",
    "\n",
    "> **WRONG:** \"There is a 95% probability that the true mean is in this interval.\"\n",
    "\n",
    "> **RIGHT:** \"This interval was constructed by a procedure that captures the true\n",
    "> parameter 95% of the time across repeated samples.\"\n",
    "\n",
    "The parameter is **fixed** (it does not move). The interval is **random** (it changes\n",
    "from sample to sample). Once you have computed a specific interval, the true parameter\n",
    "is either in it or not \u2014 there is no probability left to assign.\n",
    "\n",
    "### Analogy\n",
    "\n",
    "A 95% CI is like a fishing net that catches a specific fish 95% of the time you cast it.\n",
    "Once you have already cast the net and pulled it in, the fish is either in the net or it\n",
    "is not. Saying \"there is a 95% chance the fish is in this net\" after you have already\n",
    "pulled it in confuses the long-run property of the net with the outcome of a single cast.\n",
    "\n",
    "### Components of a CI for the mean\n",
    "\n",
    "$$\\text{CI} = \\bar{x} \\pm t_{\\alpha/2,\\, n-1} \\cdot \\frac{s}{\\sqrt{n}}$$\n",
    "\n",
    "where:\n",
    "- $\\bar{x}$ = sample mean (point estimate),\n",
    "- $t_{\\alpha/2,\\, n-1}$ = critical value from the t-distribution with $n-1$ degrees of freedom,\n",
    "- $s$ = sample standard deviation,\n",
    "- $n$ = sample size,\n",
    "- $s / \\sqrt{n}$ = standard error of the mean."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-s1-turn",
   "metadata": {},
   "source": [
    "### Your Turn (1): State the definition in your own words\n",
    "\n",
    "In the cell below, write 2\u20133 sentences explaining what a 95% confidence interval\n",
    "means. Then write 1 sentence explaining what it does **not** mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-s1-todo",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Write your interpretation as a comment or print statement.\n",
    "#\n",
    "# What a 95% CI means:\n",
    "# ...\n",
    "#\n",
    "# What it does NOT mean:\n",
    "# ...\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-s1-interp",
   "metadata": {},
   "source": [
    "**Interpretation prompt:** If someone says \"there is a 95% chance the true GDP growth\n",
    "rate is between 1.8% and 3.2%,\" what is wrong with that statement? How would you\n",
    "correct it?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-s2-header",
   "metadata": {},
   "source": [
    "<a id=\"constructing-a-ci-for-the-mean\"></a>\n",
    "## Constructing a CI for the mean\n",
    "\n",
    "### Goal\n",
    "Build a confidence interval for the mean of a real economic variable \u2014 first by hand\n",
    "using the formula, then using `scipy.stats.t.interval()`. Compare z-based and t-based\n",
    "intervals.\n",
    "\n",
    "### Why this matters in economics\n",
    "Estimating the average GDP growth rate, unemployment rate, or inflation rate with\n",
    "uncertainty is a fundamental task. The choice between z and t critical values matters\n",
    "when sample sizes are small (as they often are in macro quarterly data)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-s2-turn1",
   "metadata": {},
   "source": [
    "### Your Turn (1): Compute a 95% CI by hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-s2-todo1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract GDP growth data (drop NaN values)\n",
    "gdp_growth = df['gdp_growth_qoq_annualized'].dropna()\n",
    "\n",
    "# TODO: Compute the sample statistics\n",
    "n = ...           # sample size\n",
    "x_bar = ...       # sample mean\n",
    "s = ...           # sample standard deviation\n",
    "se = ...          # standard error of the mean = s / sqrt(n)\n",
    "\n",
    "print(f'n = {n}')\n",
    "print(f'x_bar = {x_bar:.4f}')\n",
    "print(f's = {s:.4f}')\n",
    "print(f'se = {se:.4f}')\n",
    "\n",
    "# TODO: Get the t-critical value for 95% confidence with n-1 degrees of freedom\n",
    "alpha = 0.05\n",
    "t_crit = ...      # Hint: stats.t.ppf(1 - alpha/2, df=n-1)\n",
    "\n",
    "print(f't_crit = {t_crit:.4f}')\n",
    "\n",
    "# TODO: Compute the confidence interval\n",
    "ci_lower = ...    # x_bar - t_crit * se\n",
    "ci_upper = ...    # x_bar + t_crit * se\n",
    "\n",
    "print(f'\\n95% CI for mean GDP growth (by hand): [{ci_lower:.4f}, {ci_upper:.4f}]')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-s2-turn2",
   "metadata": {},
   "source": [
    "### Your Turn (2): Verify with scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-s2-todo2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Use scipy.stats.t.interval() to compute the same CI.\n",
    "# Hint: stats.t.interval(confidence=0.95, df=n-1, loc=x_bar, scale=se)\n",
    "ci_scipy = ...\n",
    "\n",
    "print(f'95% CI (scipy): [{ci_scipy[0]:.4f}, {ci_scipy[1]:.4f}]')\n",
    "\n",
    "# TODO: Verify these match your hand-computed values.\n",
    "# Hint: np.isclose(ci_lower, ci_scipy[0])\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-s2-turn3",
   "metadata": {},
   "source": [
    "### Your Turn (3): Compare z-based vs t-based CIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-s2-todo3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The z-based CI uses the normal distribution instead of t.\n",
    "# For large n, z and t are nearly identical.\n",
    "# For small n, the t-interval is wider (more conservative).\n",
    "\n",
    "# TODO: Compute z-critical value for 95% confidence\n",
    "z_crit = ...      # Hint: stats.norm.ppf(1 - alpha/2)\n",
    "\n",
    "ci_z_lower = x_bar - z_crit * se\n",
    "ci_z_upper = x_bar + z_crit * se\n",
    "\n",
    "print(f'z_crit = {z_crit:.4f}, t_crit = {t_crit:.4f}')\n",
    "print(f'95% CI (z-based): [{ci_z_lower:.4f}, {ci_z_upper:.4f}]')\n",
    "print(f'95% CI (t-based): [{ci_lower:.4f}, {ci_upper:.4f}]')\n",
    "print(f'Width (z): {ci_z_upper - ci_z_lower:.4f}')\n",
    "print(f'Width (t): {ci_upper - ci_lower:.4f}')\n",
    "\n",
    "# TODO: For small samples, repeat this comparison with only the first 10 observations.\n",
    "# How much wider is the t-interval vs the z-interval when n is small?\n",
    "gdp_small = gdp_growth.iloc[:10]\n",
    "n_small = ...\n",
    "x_bar_small = ...\n",
    "se_small = ...\n",
    "t_crit_small = ...\n",
    "z_crit_small = z_crit  # z doesn't depend on n\n",
    "\n",
    "ci_t_small = (x_bar_small - t_crit_small * se_small, x_bar_small + t_crit_small * se_small)\n",
    "ci_z_small = (x_bar_small - z_crit_small * se_small, x_bar_small + z_crit_small * se_small)\n",
    "\n",
    "print(f'\\nSmall sample (n={n_small}):')\n",
    "print(f't_crit = {t_crit_small:.4f} vs z_crit = {z_crit_small:.4f}')\n",
    "print(f'Width (z): {ci_z_small[1] - ci_z_small[0]:.4f}')\n",
    "print(f'Width (t): {ci_t_small[1] - ci_t_small[0]:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-s2-interp",
   "metadata": {},
   "source": [
    "**Interpretation prompt:**\n",
    "- Why is the t-interval wider than the z-interval for small samples?\n",
    "- At what sample size does the difference become negligible?\n",
    "- For macro quarterly data (where n is typically 60\u2013100 quarters), does the choice matter much?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-s3-header",
   "metadata": {},
   "source": [
    "<a id=\"visualizing-the-repeated-sampling-interpretation\"></a>\n",
    "## Visualizing the repeated sampling interpretation\n",
    "\n",
    "### Goal\n",
    "Make the definition of \"95% confidence\" tangible. Generate 100 samples from a known\n",
    "population, build a 95% CI from each, and visualize which intervals capture the true\n",
    "mean and which miss.\n",
    "\n",
    "### Why this matters in economics\n",
    "When you report a 95% CI for the effect of a minimum wage increase on employment, you\n",
    "are relying on a procedure that, if applied to many independent studies, would produce\n",
    "intervals containing the true effect about 95% of the time. This simulation makes that\n",
    "abstract property concrete."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-s3-turn1",
   "metadata": {},
   "source": [
    "### Your Turn (1): Repeated-sampling CI simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-s3-todo1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulation parameters\n",
    "rng = np.random.default_rng(42)\n",
    "true_mean = 2.5        # True population mean (e.g., true average GDP growth %)\n",
    "true_std = 3.0         # True population standard deviation\n",
    "sample_size = 30       # Each sample draws this many observations\n",
    "n_simulations = 100    # Number of repeated samples\n",
    "confidence = 0.95\n",
    "\n",
    "# TODO: For each simulation, draw a sample, compute the CI, and store results.\n",
    "results = []\n",
    "for i in range(n_simulations):\n",
    "    # Draw a random sample from the population\n",
    "    sample = ...  # Hint: rng.normal(loc=true_mean, scale=true_std, size=sample_size)\n",
    "\n",
    "    # Compute sample statistics\n",
    "    x_bar_sim = ...  # sample mean\n",
    "    se_sim = ...     # standard error = sample std / sqrt(n)\n",
    "\n",
    "    # Compute the 95% CI using scipy\n",
    "    ci_low, ci_high = ...  # Hint: stats.t.interval(...)\n",
    "\n",
    "    # Does this interval contain the true mean?\n",
    "    contains_true = ...  # Hint: ci_low <= true_mean <= ci_high\n",
    "\n",
    "    results.append({\n",
    "        'sim': i,\n",
    "        'x_bar': x_bar_sim,\n",
    "        'ci_low': ci_low,\n",
    "        'ci_high': ci_high,\n",
    "        'contains_true': contains_true\n",
    "    })\n",
    "\n",
    "ci_df = pd.DataFrame(results)\n",
    "\n",
    "# How many intervals missed the true mean?\n",
    "n_miss = (ci_df['contains_true'] == False).sum()\n",
    "print(f'{n_miss} out of {n_simulations} intervals missed the true mean.')\n",
    "print(f'Coverage rate: {ci_df[\"contains_true\"].mean():.1%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-s3-turn2",
   "metadata": {},
   "source": [
    "### Your Turn (2): Plot all 100 intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-s3-todo2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create a plot with 100 horizontal lines, one per CI.\n",
    "# Color intervals that contain the true mean in blue/green,\n",
    "# and intervals that miss in red.\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 12))\n",
    "\n",
    "for _, row in ci_df.iterrows():\n",
    "    color = ...  # 'steelblue' if contains_true, else 'red'\n",
    "    ax.hlines(y=row['sim'], xmin=row['ci_low'], xmax=row['ci_high'],\n",
    "              color=color, linewidth=1.2, alpha=0.7)\n",
    "    ax.plot(row['x_bar'], row['sim'], 'o', color=color, markersize=2)\n",
    "\n",
    "# Draw the true mean as a vertical line\n",
    "ax.axvline(x=true_mean, color='black', linestyle='--', linewidth=1.5, label=f'True mean = {true_mean}')\n",
    "\n",
    "ax.set_xlabel('GDP Growth (%)')\n",
    "ax.set_ylabel('Simulation index')\n",
    "ax.set_title(f'100 Confidence Intervals (95%): {n_miss} miss the true mean (red)')\n",
    "ax.legend(loc='upper right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-s3-interp",
   "metadata": {},
   "source": [
    "**Interpretation prompt:**\n",
    "- Approximately how many red intervals did you expect? How many did you actually get?\n",
    "- If you re-run the simulation with a different random seed, will you get exactly the same count?\n",
    "- Does the fact that some intervals miss the true mean make them \"wrong\"? Why or why not?\n",
    "- How does this visualization connect to the fishing-net analogy from section 1?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-s4-header",
   "metadata": {},
   "source": [
    "<a id=\"effect-of-sample-size-on-ci-width\"></a>\n",
    "## Effect of sample size on CI width\n",
    "\n",
    "### Goal\n",
    "Demonstrate that confidence interval width shrinks proportionally to $1/\\sqrt{n}$.\n",
    "More data means more precision.\n",
    "\n",
    "### Why this matters in economics\n",
    "Data collection is expensive. Understanding how CI width scales with sample size helps\n",
    "economists plan surveys, decide whether to collect more quarterly observations, and\n",
    "evaluate the precision of estimates from small vs. large datasets. Quadrupling the\n",
    "sample size only halves the CI width."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-s4-turn1",
   "metadata": {},
   "source": [
    "### Your Turn (1): Compute CIs for different sample sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-s4-todo1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We simulate from a known population to isolate the sample-size effect.\n",
    "rng = np.random.default_rng(123)\n",
    "population = rng.normal(loc=2.5, scale=3.0, size=10_000)\n",
    "\n",
    "sample_sizes = [10, 30, 100, 500]\n",
    "alpha = 0.05\n",
    "\n",
    "# TODO: For each sample size, draw a sample, compute a 95% CI, and record the width.\n",
    "size_results = []\n",
    "for n_i in sample_sizes:\n",
    "    sample = rng.choice(population, size=n_i, replace=False)\n",
    "    x_bar_i = ...\n",
    "    se_i = ...\n",
    "    ci_low_i, ci_high_i = ...  # Hint: stats.t.interval(...)\n",
    "    width_i = ...\n",
    "\n",
    "    size_results.append({\n",
    "        'n': n_i,\n",
    "        'x_bar': x_bar_i,\n",
    "        'ci_low': ci_low_i,\n",
    "        'ci_high': ci_high_i,\n",
    "        'width': width_i\n",
    "    })\n",
    "\n",
    "size_df = pd.DataFrame(size_results)\n",
    "size_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-s4-turn2",
   "metadata": {},
   "source": [
    "### Your Turn (2): Plot CI width vs sample size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-s4-todo2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create a plot showing CI width as a function of sample size.\n",
    "# Overlay a theoretical curve proportional to 1/sqrt(n) for comparison.\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "\n",
    "ax.plot(size_df['n'], size_df['width'], 'o-', color='steelblue', linewidth=2,\n",
    "        markersize=8, label='Observed CI width')\n",
    "\n",
    "# Theoretical scaling: width ~ c / sqrt(n)\n",
    "# Use the first point to calibrate the constant c\n",
    "c = ...  # size_df['width'].iloc[0] * np.sqrt(size_df['n'].iloc[0])\n",
    "n_range = np.linspace(10, 500, 200)\n",
    "theoretical_width = c / np.sqrt(n_range)\n",
    "ax.plot(n_range, theoretical_width, '--', color='gray', alpha=0.7,\n",
    "        label=r'Theoretical: $c / \\sqrt{n}$')\n",
    "\n",
    "ax.set_xlabel('Sample size (n)')\n",
    "ax.set_ylabel('95% CI width')\n",
    "ax.set_title('Confidence interval width shrinks with sample size')\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-s4-interp",
   "metadata": {},
   "source": [
    "**Interpretation prompt:**\n",
    "- By what factor does the CI width decrease when you go from n=10 to n=100?\n",
    "  Does this match the $1/\\sqrt{n}$ scaling (i.e., roughly $\\sqrt{10}$ times narrower)?\n",
    "- If you are a policy researcher with a budget to survey households, and you want\n",
    "  to cut your CI width in half, how many more observations do you need?\n",
    "- Why does the theoretical curve not match perfectly? (Hint: think about what else\n",
    "  changes with sample size.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-s5-header",
   "metadata": {},
   "source": [
    "<a id=\"effect-of-confidence-level-on-ci-width\"></a>\n",
    "## Effect of confidence level on CI width\n",
    "\n",
    "### Goal\n",
    "Show the trade-off between confidence level and precision: higher confidence requires\n",
    "a wider interval.\n",
    "\n",
    "### Why this matters in economics\n",
    "In practice, economists must choose a confidence level. A 99% CI is more cautious but\n",
    "less precise. An 80% CI is narrower but misses more often. The choice reflects the\n",
    "cost of being wrong: a central bank forecasting inflation may prefer 99% confidence,\n",
    "while a quick exploratory analysis might use 90%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-s5-turn1",
   "metadata": {},
   "source": [
    "### Your Turn (1): Compute CIs at different confidence levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-s5-todo1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the GDP growth data\n",
    "gdp_growth = df['gdp_growth_qoq_annualized'].dropna()\n",
    "n = len(gdp_growth)\n",
    "x_bar = gdp_growth.mean()\n",
    "se = gdp_growth.std(ddof=1) / np.sqrt(n)\n",
    "\n",
    "conf_levels = [0.80, 0.90, 0.95, 0.99]\n",
    "\n",
    "# TODO: Compute a CI for each confidence level and store results.\n",
    "level_results = []\n",
    "for conf in conf_levels:\n",
    "    ci_low_c, ci_high_c = ...  # Hint: stats.t.interval(confidence=conf, df=n-1, loc=x_bar, scale=se)\n",
    "    width_c = ...\n",
    "\n",
    "    level_results.append({\n",
    "        'confidence': f'{conf:.0%}',\n",
    "        'ci_low': ci_low_c,\n",
    "        'ci_high': ci_high_c,\n",
    "        'width': width_c\n",
    "    })\n",
    "\n",
    "level_df = pd.DataFrame(level_results)\n",
    "level_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-s5-turn2",
   "metadata": {},
   "source": [
    "### Your Turn (2): Visualize nested intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-s5-todo2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Plot the nested CIs as horizontal bars, one on top of the other.\n",
    "# The widest (99%) should be at the top, the narrowest (80%) at the bottom.\n",
    "\n",
    "colors = ['#2ca02c', '#1f77b4', '#ff7f0e', '#d62728']\n",
    "fig, ax = plt.subplots(figsize=(10, 4))\n",
    "\n",
    "for i, row in level_df.iterrows():\n",
    "    ax.barh(y=row['confidence'], width=row['width'],\n",
    "            left=row['ci_low'], height=0.5,\n",
    "            color=colors[i], alpha=0.7, edgecolor='black')\n",
    "    ax.text(row['ci_high'] + 0.05, i, f\"width={row['width']:.3f}\",\n",
    "            va='center', fontsize=10)\n",
    "\n",
    "ax.axvline(x=x_bar, color='black', linestyle='--', label=f'Sample mean = {x_bar:.3f}')\n",
    "ax.set_xlabel('GDP Growth (%, annualized)')\n",
    "ax.set_title('Confidence intervals at different confidence levels')\n",
    "ax.legend(loc='upper right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-s5-interp",
   "metadata": {},
   "source": [
    "**Interpretation prompt:**\n",
    "- How much wider is the 99% CI compared to the 80% CI?\n",
    "- In what situation would you prefer an 80% CI over a 99% CI?\n",
    "- Is a 99.99% CI always better? What is the cost of extreme confidence?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-s6-header",
   "metadata": {},
   "source": [
    "<a id=\"confidence-intervals-for-regression-coefficients\"></a>\n",
    "## Confidence intervals for regression coefficients\n",
    "\n",
    "### Goal\n",
    "Bridge from CIs for the mean to CIs for regression coefficients. Fit a simple\n",
    "regression with `statsmodels`, extract coefficient CIs, and interpret them.\n",
    "\n",
    "### Why this matters in economics\n",
    "In applied econometrics, you rarely just estimate a mean. You estimate the effect of\n",
    "one variable on another while controlling for confounders. The [0.025, 0.975] columns\n",
    "in `statsmodels` output give you the 95% CI for each coefficient. If zero is inside\n",
    "the CI for a coefficient, you cannot reject the null of no effect at the 5% level."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-s6-turn1",
   "metadata": {},
   "source": [
    "### Your Turn (1): Fit a simple regression and extract CIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-s6-todo1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will regress GDP growth on the unemployment rate.\n",
    "# This is a simple illustrative regression, not a causal model.\n",
    "\n",
    "reg_df = df[['gdp_growth_qoq_annualized', 'UNRATE']].dropna()\n",
    "\n",
    "y = reg_df['gdp_growth_qoq_annualized']\n",
    "X = sm.add_constant(reg_df[['UNRATE']])\n",
    "\n",
    "# TODO: Fit the OLS regression\n",
    "res = ...\n",
    "\n",
    "# TODO: Print the summary\n",
    "...\n",
    "\n",
    "# TODO: Extract the 95% confidence intervals using res.conf_int(alpha=0.05)\n",
    "ci_table = ...\n",
    "ci_table.columns = ['CI_lower', 'CI_upper']\n",
    "print('\\n95% Confidence Intervals for Coefficients:')\n",
    "print(ci_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-s6-turn2",
   "metadata": {},
   "source": [
    "### Your Turn (2): Interpret the regression CI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-s6-todo2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Extract the coefficient and CI for UNRATE.\n",
    "coef_unrate = ...    # res.params['UNRATE']\n",
    "ci_low_unrate = ...  # ci_table.loc['UNRATE', 'CI_lower']\n",
    "ci_high_unrate = ... # ci_table.loc['UNRATE', 'CI_upper']\n",
    "\n",
    "print(f'Coefficient on UNRATE: {coef_unrate:.4f}')\n",
    "print(f'95% CI: [{ci_low_unrate:.4f}, {ci_high_unrate:.4f}]')\n",
    "\n",
    "# TODO: Check whether zero is inside the CI.\n",
    "zero_in_ci = ...\n",
    "print(f'\\nDoes the CI contain zero? {zero_in_ci}')\n",
    "if zero_in_ci:\n",
    "    print('=> Cannot reject H0: no linear association at the 5% level.')\n",
    "else:\n",
    "    print('=> Reject H0: evidence of a linear association at the 5% level.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-s6-turn3",
   "metadata": {},
   "source": [
    "### Your Turn (3): Visualize the coefficient CI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-s6-todo3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create a coefficient plot showing each coefficient as a point\n",
    "# with its CI as a horizontal error bar.\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 3))\n",
    "\n",
    "coef_names = res.params.index.tolist()\n",
    "coef_vals = res.params.values\n",
    "ci_vals = res.conf_int(alpha=0.05).values\n",
    "\n",
    "for i, name in enumerate(coef_names):\n",
    "    ci_err = [[coef_vals[i] - ci_vals[i, 0]], [ci_vals[i, 1] - coef_vals[i]]]\n",
    "    ax.errorbar(coef_vals[i], i, xerr=ci_err, fmt='o', color='steelblue',\n",
    "                capsize=5, markersize=8, linewidth=2)\n",
    "\n",
    "ax.axvline(x=0, color='red', linestyle='--', alpha=0.7, label='Zero (no effect)')\n",
    "ax.set_yticks(range(len(coef_names)))\n",
    "ax.set_yticklabels(coef_names)\n",
    "ax.set_xlabel('Coefficient value')\n",
    "ax.set_title('Regression coefficients with 95% CIs')\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-s6-interp",
   "metadata": {},
   "source": [
    "**Interpretation prompt:**\n",
    "- Write one sentence interpreting the CI for the UNRATE coefficient: \"The 95% CI for\n",
    "  the effect of unemployment on GDP growth is [a, b], which means...\"\n",
    "- If zero is in the interval, does that mean the true effect is exactly zero?\n",
    "- How would your interpretation change if you used HAC standard errors?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-s7-header",
   "metadata": {},
   "source": [
    "<a id=\"margin-of-error-and-practical-significance\"></a>\n",
    "## Margin of error and practical significance\n",
    "\n",
    "### Goal\n",
    "Understand the margin of error, its relationship to CI width, and the distinction\n",
    "between statistical precision and practical importance.\n",
    "\n",
    "### Why this matters in economics\n",
    "A narrow confidence interval around a small effect is a precise result showing that\n",
    "the effect is near zero \u2014 this is informative. A wide confidence interval around a\n",
    "large point estimate is uninformative because the true effect could be anywhere from\n",
    "large positive to near zero (or even negative). CI width tells you whether you have\n",
    "enough data to draw a meaningful conclusion."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-s7-turn1",
   "metadata": {},
   "source": [
    "### Your Turn (1): Compute the margin of error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-s7-todo1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The margin of error (ME) is half the CI width.\n",
    "# CI = point_estimate +/- ME\n",
    "\n",
    "gdp_growth = df['gdp_growth_qoq_annualized'].dropna()\n",
    "n = len(gdp_growth)\n",
    "x_bar = gdp_growth.mean()\n",
    "se = gdp_growth.std(ddof=1) / np.sqrt(n)\n",
    "\n",
    "# TODO: Compute the margin of error for a 95% CI\n",
    "t_crit_95 = stats.t.ppf(0.975, df=n-1)\n",
    "margin_of_error = ...  # t_crit_95 * se\n",
    "\n",
    "print(f'Point estimate (mean GDP growth): {x_bar:.4f}')\n",
    "print(f'Margin of error (95%): {margin_of_error:.4f}')\n",
    "print(f'CI width: {2 * margin_of_error:.4f}')\n",
    "print(f'CI: [{x_bar - margin_of_error:.4f}, {x_bar + margin_of_error:.4f}]')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-s7-turn2",
   "metadata": {},
   "source": [
    "### Your Turn (2): Interpret different scenarios\n",
    "\n",
    "Below are four hypothetical results from economic studies. For each, interpret\n",
    "whether the result is informative and what it tells us about practical significance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-s7-todo2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Four hypothetical study results:\n",
    "# Each tuple: (description, point_estimate, ci_lower, ci_upper)\n",
    "scenarios = [\n",
    "    ('Effect of job training on wages ($/hr)',    0.50, 0.10, 0.90),\n",
    "    ('Effect of tax cut on GDP growth (%)',       1.20, -0.80, 3.20),\n",
    "    ('Effect of class size on test scores (pts)', 0.02, -0.01, 0.05),\n",
    "    ('Effect of minimum wage on employment (%)',  -0.30, -0.50, -0.10),\n",
    "]\n",
    "\n",
    "print('Scenario Analysis: Margin of Error and Practical Significance')\n",
    "print('=' * 70)\n",
    "\n",
    "for desc, pe, ci_lo, ci_hi in scenarios:\n",
    "    me = (ci_hi - ci_lo) / 2\n",
    "    contains_zero = ci_lo <= 0 <= ci_hi\n",
    "    print(f'\\n{desc}')\n",
    "    print(f'  Point estimate: {pe:+.2f}')\n",
    "    print(f'  95% CI: [{ci_lo:+.2f}, {ci_hi:+.2f}]')\n",
    "    print(f'  Margin of error: {me:.2f}')\n",
    "    print(f'  Contains zero: {contains_zero}')\n",
    "\n",
    "# TODO: For each scenario, write 1-2 sentences interpreting the result.\n",
    "# Consider:\n",
    "#   - Is the CI narrow or wide relative to the point estimate?\n",
    "#   - Is the result statistically significant (CI excludes zero)?\n",
    "#   - Is the result practically significant (effect large enough to matter)?\n",
    "#   - Is the result informative (CI narrow enough to draw a conclusion)?\n",
    "...\n",
    "\n",
    "# Scenario 1 interpretation: ...\n",
    "# Scenario 2 interpretation: ...\n",
    "# Scenario 3 interpretation: ...\n",
    "# Scenario 4 interpretation: ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-s7-interp",
   "metadata": {},
   "source": [
    "**Interpretation prompt:**\n",
    "- Which scenario is a \"precise null result\" (narrow CI around a small effect)?\n",
    "- Which scenario is uninformative (wide CI that does not rule out important alternatives)?\n",
    "- Why is \"statistically significant but practically unimportant\" a real problem in economics?\n",
    "- Why is a wide CI not the same thing as \"no effect\"?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-bridge",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Where This Shows Up Later\n",
    "\n",
    "Confidence intervals are not just a statistics exercise \u2014 they are central to every\n",
    "subsequent module in this project:\n",
    "\n",
    "- **Regression (02_regression):** Every regression summary in `statsmodels` reports\n",
    "  the `[0.025, 0.975]` columns \u2014 those are 95% CIs for each coefficient. You will\n",
    "  interpret them to assess whether predictors have meaningful effects.\n",
    "\n",
    "- **Causal inference (06_causal):** Difference-in-differences, instrumental variables,\n",
    "  and panel methods all produce treatment effect estimates with CIs. The CI tells you\n",
    "  not just \"is the effect nonzero?\" but \"how large could the effect plausibly be?\"\n",
    "\n",
    "- **Time series (07_time_series_econ):** Impulse response functions are plotted with\n",
    "  confidence bands. A response whose CI includes zero at all horizons is not statistically\n",
    "  significant.\n",
    "\n",
    "- **Robust inference:** When you switch from OLS standard errors to HC3 or HAC standard\n",
    "  errors, the coefficients stay the same but the CIs change. Understanding why is key\n",
    "  to correct inference."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-checkpoint-header",
   "metadata": {},
   "source": [
    "<a id=\"checkpoint-self-check\"></a>\n",
    "## Checkpoint (Self-Check)\n",
    "\n",
    "Run the assertions below to verify your understanding. Then write 2\u20133 sentences\n",
    "summarizing the key takeaways."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-checkpoint",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick sanity checks\n",
    "# Uncomment and fill in after completing the sections above.\n",
    "\n",
    "# 1. The CI from scipy should match the hand-computed CI.\n",
    "# assert np.isclose(ci_lower, ci_scipy[0], atol=1e-6)\n",
    "# assert np.isclose(ci_upper, ci_scipy[1], atol=1e-6)\n",
    "\n",
    "# 2. The coverage rate from the simulation should be near 0.95.\n",
    "# assert 0.85 <= ci_df['contains_true'].mean() <= 1.0\n",
    "\n",
    "# 3. CI width should shrink as sample size grows.\n",
    "# assert size_df['width'].is_monotonic_decreasing\n",
    "\n",
    "# 4. CI width should grow as confidence level increases.\n",
    "# assert level_df['width'].is_monotonic_increasing\n",
    "\n",
    "# TODO: Write 2-3 summary sentences:\n",
    "# - What does a 95% CI mean?\n",
    "# - What is the most common misinterpretation?\n",
    "# - How do sample size and confidence level affect CI width?\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-extensions",
   "metadata": {},
   "source": [
    "## Extensions (Optional)\n",
    "\n",
    "- **Bootstrap confidence intervals:** Instead of assuming normality, resample the data\n",
    "  with replacement 10,000 times and take the 2.5th and 97.5th percentiles of the\n",
    "  bootstrapped means. Compare to the t-based CI.\n",
    "- **Asymmetric CIs:** For skewed data (e.g., income), bootstrap CIs may be asymmetric\n",
    "  around the point estimate. Try this with the RSAFS (retail sales) column.\n",
    "- **Prediction intervals vs. confidence intervals:** A CI covers the mean; a prediction\n",
    "  interval covers a single new observation. Compute both and compare widths.\n",
    "- **CI for a proportion:** If you have a binary variable (e.g., recession indicator),\n",
    "  compute a CI for the proportion using the Wilson or Clopper-Pearson method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-reflection",
   "metadata": {},
   "source": [
    "## Reflection\n",
    "\n",
    "- What assumptions are you making when constructing a t-based CI?\n",
    "  (Hint: independence, approximate normality of the sampling distribution.)\n",
    "- How would autocorrelation in quarterly macro data violate those assumptions?\n",
    "- If you had to communicate uncertainty about GDP growth to a policymaker who has\n",
    "  never taken a statistics course, how would you explain a 95% CI?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-solutions-header",
   "metadata": {},
   "source": [
    "<a id=\"solutions-reference\"></a>\n",
    "## Solutions (Reference)\n",
    "\n",
    "Try the TODOs first. Use these only to unblock yourself or to compare approaches.\n",
    "\n",
    "<details><summary>Solution: Constructing a CI for the mean</summary>\n",
    "\n",
    "_One possible approach. Your variable names may differ; align them with the notebook._\n",
    "\n",
    "```python\n",
    "# Reference solution for 04_confidence_intervals \u2014 Constructing a CI for the mean\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "\n",
    "gdp_growth = df['gdp_growth_qoq_annualized'].dropna()\n",
    "\n",
    "n = len(gdp_growth)\n",
    "x_bar = gdp_growth.mean()\n",
    "s = gdp_growth.std(ddof=1)\n",
    "se = s / np.sqrt(n)\n",
    "\n",
    "alpha = 0.05\n",
    "t_crit = stats.t.ppf(1 - alpha / 2, df=n - 1)\n",
    "\n",
    "ci_lower = x_bar - t_crit * se\n",
    "ci_upper = x_bar + t_crit * se\n",
    "print(f'95% CI (by hand): [{ci_lower:.4f}, {ci_upper:.4f}]')\n",
    "\n",
    "# Verify with scipy\n",
    "ci_scipy = stats.t.interval(confidence=0.95, df=n - 1, loc=x_bar, scale=se)\n",
    "print(f'95% CI (scipy):   [{ci_scipy[0]:.4f}, {ci_scipy[1]:.4f}]')\n",
    "\n",
    "assert np.isclose(ci_lower, ci_scipy[0], atol=1e-10)\n",
    "assert np.isclose(ci_upper, ci_scipy[1], atol=1e-10)\n",
    "\n",
    "# z-based comparison\n",
    "z_crit = stats.norm.ppf(1 - alpha / 2)\n",
    "ci_z_lower = x_bar - z_crit * se\n",
    "ci_z_upper = x_bar + z_crit * se\n",
    "print(f'\\n95% CI (z-based): [{ci_z_lower:.4f}, {ci_z_upper:.4f}]')\n",
    "print(f'z_crit = {z_crit:.4f}, t_crit = {t_crit:.4f}')\n",
    "\n",
    "# Small sample comparison\n",
    "gdp_small = gdp_growth.iloc[:10]\n",
    "n_small = len(gdp_small)\n",
    "x_bar_small = gdp_small.mean()\n",
    "se_small = gdp_small.std(ddof=1) / np.sqrt(n_small)\n",
    "t_crit_small = stats.t.ppf(0.975, df=n_small - 1)\n",
    "\n",
    "print(f'\\nSmall sample (n={n_small}):')\n",
    "print(f't_crit = {t_crit_small:.4f} vs z_crit = {z_crit:.4f}')\n",
    "print(f'Width (t): {2 * t_crit_small * se_small:.4f}')\n",
    "print(f'Width (z): {2 * z_crit * se_small:.4f}')\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "<details><summary>Solution: Visualizing the repeated sampling interpretation</summary>\n",
    "\n",
    "_One possible approach. Your variable names may differ; align them with the notebook._\n",
    "\n",
    "```python\n",
    "# Reference solution for 04_confidence_intervals \u2014 Repeated sampling simulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "rng = np.random.default_rng(42)\n",
    "true_mean = 2.5\n",
    "true_std = 3.0\n",
    "sample_size = 30\n",
    "n_simulations = 100\n",
    "\n",
    "results = []\n",
    "for i in range(n_simulations):\n",
    "    sample = rng.normal(loc=true_mean, scale=true_std, size=sample_size)\n",
    "    x_bar_sim = sample.mean()\n",
    "    se_sim = sample.std(ddof=1) / np.sqrt(sample_size)\n",
    "    ci_low, ci_high = stats.t.interval(confidence=0.95, df=sample_size - 1,\n",
    "                                        loc=x_bar_sim, scale=se_sim)\n",
    "    contains_true = ci_low <= true_mean <= ci_high\n",
    "    results.append({\n",
    "        'sim': i, 'x_bar': x_bar_sim,\n",
    "        'ci_low': ci_low, 'ci_high': ci_high,\n",
    "        'contains_true': contains_true\n",
    "    })\n",
    "\n",
    "ci_df = pd.DataFrame(results)\n",
    "n_miss = (~ci_df['contains_true']).sum()\n",
    "print(f'{n_miss} out of {n_simulations} intervals missed the true mean.')\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 12))\n",
    "for _, row in ci_df.iterrows():\n",
    "    color = 'steelblue' if row['contains_true'] else 'red'\n",
    "    ax.hlines(y=row['sim'], xmin=row['ci_low'], xmax=row['ci_high'],\n",
    "              color=color, linewidth=1.2, alpha=0.7)\n",
    "    ax.plot(row['x_bar'], row['sim'], 'o', color=color, markersize=2)\n",
    "\n",
    "ax.axvline(x=true_mean, color='black', linestyle='--', linewidth=1.5,\n",
    "           label=f'True mean = {true_mean}')\n",
    "ax.set_xlabel('GDP Growth (%)')\n",
    "ax.set_ylabel('Simulation index')\n",
    "ax.set_title(f'100 CIs (95%): {n_miss} miss the true mean (red)')\n",
    "ax.legend(loc='upper right')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "<details><summary>Solution: Effect of sample size on CI width</summary>\n",
    "\n",
    "_One possible approach. Your variable names may differ; align them with the notebook._\n",
    "\n",
    "```python\n",
    "# Reference solution for 04_confidence_intervals \u2014 Sample size effect\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "rng = np.random.default_rng(123)\n",
    "population = rng.normal(loc=2.5, scale=3.0, size=10_000)\n",
    "\n",
    "sample_sizes = [10, 30, 100, 500]\n",
    "size_results = []\n",
    "for n_i in sample_sizes:\n",
    "    sample = rng.choice(population, size=n_i, replace=False)\n",
    "    x_bar_i = sample.mean()\n",
    "    se_i = sample.std(ddof=1) / np.sqrt(n_i)\n",
    "    ci_low_i, ci_high_i = stats.t.interval(confidence=0.95, df=n_i - 1,\n",
    "                                            loc=x_bar_i, scale=se_i)\n",
    "    width_i = ci_high_i - ci_low_i\n",
    "    size_results.append({'n': n_i, 'x_bar': x_bar_i,\n",
    "                         'ci_low': ci_low_i, 'ci_high': ci_high_i,\n",
    "                         'width': width_i})\n",
    "\n",
    "size_df = pd.DataFrame(size_results)\n",
    "print(size_df)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "ax.plot(size_df['n'], size_df['width'], 'o-', color='steelblue',\n",
    "        linewidth=2, markersize=8, label='Observed CI width')\n",
    "\n",
    "c = size_df['width'].iloc[0] * np.sqrt(size_df['n'].iloc[0])\n",
    "n_range = np.linspace(10, 500, 200)\n",
    "ax.plot(n_range, c / np.sqrt(n_range), '--', color='gray', alpha=0.7,\n",
    "        label=r'Theoretical: $c / \\sqrt{n}$')\n",
    "\n",
    "ax.set_xlabel('Sample size (n)')\n",
    "ax.set_ylabel('95% CI width')\n",
    "ax.set_title('CI width shrinks with sample size')\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "<details><summary>Solution: Effect of confidence level on CI width</summary>\n",
    "\n",
    "_One possible approach. Your variable names may differ; align them with the notebook._\n",
    "\n",
    "```python\n",
    "# Reference solution for 04_confidence_intervals \u2014 Confidence level effect\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "gdp_growth = df['gdp_growth_qoq_annualized'].dropna()\n",
    "n = len(gdp_growth)\n",
    "x_bar = gdp_growth.mean()\n",
    "se = gdp_growth.std(ddof=1) / np.sqrt(n)\n",
    "\n",
    "conf_levels = [0.80, 0.90, 0.95, 0.99]\n",
    "level_results = []\n",
    "for conf in conf_levels:\n",
    "    ci_low_c, ci_high_c = stats.t.interval(confidence=conf, df=n - 1,\n",
    "                                            loc=x_bar, scale=se)\n",
    "    width_c = ci_high_c - ci_low_c\n",
    "    level_results.append({'confidence': f'{conf:.0%}',\n",
    "                          'ci_low': ci_low_c, 'ci_high': ci_high_c,\n",
    "                          'width': width_c})\n",
    "\n",
    "level_df = pd.DataFrame(level_results)\n",
    "print(level_df)\n",
    "\n",
    "colors = ['#2ca02c', '#1f77b4', '#ff7f0e', '#d62728']\n",
    "fig, ax = plt.subplots(figsize=(10, 4))\n",
    "for i, row in level_df.iterrows():\n",
    "    ax.barh(y=row['confidence'], width=row['width'],\n",
    "            left=row['ci_low'], height=0.5,\n",
    "            color=colors[i], alpha=0.7, edgecolor='black')\n",
    "    ax.text(row['ci_high'] + 0.05, i, f\"width={row['width']:.3f}\",\n",
    "            va='center', fontsize=10)\n",
    "\n",
    "ax.axvline(x=x_bar, color='black', linestyle='--',\n",
    "           label=f'Sample mean = {x_bar:.3f}')\n",
    "ax.set_xlabel('GDP Growth (%, annualized)')\n",
    "ax.set_title('CIs at different confidence levels')\n",
    "ax.legend(loc='upper right')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "<details><summary>Solution: Confidence intervals for regression coefficients</summary>\n",
    "\n",
    "_One possible approach. Your variable names may differ; align them with the notebook._\n",
    "\n",
    "```python\n",
    "# Reference solution for 04_confidence_intervals \u2014 Regression CIs\n",
    "import statsmodels.api as sm\n",
    "\n",
    "reg_df = df[['gdp_growth_qoq_annualized', 'UNRATE']].dropna()\n",
    "y = reg_df['gdp_growth_qoq_annualized']\n",
    "X = sm.add_constant(reg_df[['UNRATE']])\n",
    "\n",
    "res = sm.OLS(y, X).fit()\n",
    "print(res.summary())\n",
    "\n",
    "ci_table = res.conf_int(alpha=0.05)\n",
    "ci_table.columns = ['CI_lower', 'CI_upper']\n",
    "print('\\n95% Confidence Intervals:')\n",
    "print(ci_table)\n",
    "\n",
    "coef_unrate = res.params['UNRATE']\n",
    "ci_low_unrate = ci_table.loc['UNRATE', 'CI_lower']\n",
    "ci_high_unrate = ci_table.loc['UNRATE', 'CI_upper']\n",
    "\n",
    "zero_in_ci = ci_low_unrate <= 0 <= ci_high_unrate\n",
    "print(f'\\nCoefficient on UNRATE: {coef_unrate:.4f}')\n",
    "print(f'95% CI: [{ci_low_unrate:.4f}, {ci_high_unrate:.4f}]')\n",
    "print(f'Contains zero: {zero_in_ci}')\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "<details><summary>Solution: Margin of error and practical significance</summary>\n",
    "\n",
    "_One possible approach. Your variable names may differ; align them with the notebook._\n",
    "\n",
    "```python\n",
    "# Reference solution for 04_confidence_intervals \u2014 Margin of error\n",
    "from scipy import stats\n",
    "\n",
    "gdp_growth = df['gdp_growth_qoq_annualized'].dropna()\n",
    "n = len(gdp_growth)\n",
    "x_bar = gdp_growth.mean()\n",
    "se = gdp_growth.std(ddof=1) / np.sqrt(n)\n",
    "\n",
    "t_crit_95 = stats.t.ppf(0.975, df=n - 1)\n",
    "margin_of_error = t_crit_95 * se\n",
    "\n",
    "print(f'Point estimate: {x_bar:.4f}')\n",
    "print(f'Margin of error (95%): {margin_of_error:.4f}')\n",
    "print(f'CI: [{x_bar - margin_of_error:.4f}, {x_bar + margin_of_error:.4f}]')\n",
    "\n",
    "# Scenario interpretations:\n",
    "# 1. Job training: narrow CI excluding zero => statistically significant,\n",
    "#    effect ($0.10 to $0.90/hr) is modest but real.\n",
    "# 2. Tax cut: wide CI crossing zero => NOT statistically significant;\n",
    "#    too imprecise to draw conclusions.\n",
    "# 3. Class size: very narrow CI near zero => precise null result;\n",
    "#    effect is real but practically negligible.\n",
    "# 4. Minimum wage: narrow CI excluding zero, all negative =>\n",
    "#    statistically and practically significant negative effect.\n",
    "```\n",
    "\n",
    "</details>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbformat_minor": 5,
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}