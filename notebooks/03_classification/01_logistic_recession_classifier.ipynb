{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 01 Logistic Recession Classifier\n",
        "\n",
        "Logistic regression, ROC/PR, and threshold tuning.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Table of Contents\n",
        "- Train/test split\n",
        "- Fit logistic\n",
        "- ROC/PR\n",
        "- Threshold tuning\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Why This Notebook Matters\n",
        "Classification notebooks turn the recession label into a **probability model**.\n",
        "You will learn how to evaluate rare-event prediction and how to choose thresholds intentionally.\n",
        "\n",
        "\n",
        "## What You Will Produce\n",
        "- (no file output; learning/analysis notebook)\n",
        "\n",
        "## Success Criteria\n",
        "- You can explain what you built and why each step exists.\n",
        "- You can run your work end-to-end without undefined variables.\n",
        "\n",
        "## Common Pitfalls\n",
        "- Running cells top-to-bottom without reading the instructions.\n",
        "- Leaving `...` placeholders in code cells.\n",
        "- Reporting only accuracy on imbalanced data.\n",
        "- Using threshold=0.5 by default without considering costs.\n",
        "\n",
        "## Matching Guide\n",
        "- `docs/guides/03_classification/01_logistic_recession_classifier.md`\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## How To Use This Notebook\n",
        "- This notebook is hands-on. Most code cells are incomplete on purpose.\n",
        "- Complete each TODO, then run the cell.\n",
        "- Use the matching guide (`docs/guides/03_classification/01_logistic_recession_classifier.md`) for deep explanations and alternative examples.\n",
        "- Write short interpretation notes as you go (what changed, why it matters).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Environment Bootstrap\n",
        "Run this cell first. It makes the repo importable and defines common directories.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "from pathlib import Path\n",
        "import sys\n",
        "\n",
        "\n",
        "def find_repo_root(start: Path) -> Path:\n",
        "    p = start\n",
        "    for _ in range(8):\n",
        "        if (p / 'src').exists() and (p / 'docs').exists():\n",
        "            return p\n",
        "        p = p.parent\n",
        "    raise RuntimeError('Could not find repo root. Start Jupyter from the repo root.')\n",
        "\n",
        "\n",
        "PROJECT_ROOT = find_repo_root(Path.cwd())\n",
        "if str(PROJECT_ROOT) not in sys.path:\n",
        "    sys.path.append(str(PROJECT_ROOT))\n",
        "\n",
        "DATA_DIR = PROJECT_ROOT / 'data'\n",
        "RAW_DIR = DATA_DIR / 'raw'\n",
        "PROCESSED_DIR = DATA_DIR / 'processed'\n",
        "SAMPLE_DIR = DATA_DIR / 'sample'\n",
        "\n",
        "PROJECT_ROOT\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Goal\n",
        "Train a logistic regression classifier for next-quarter recession and interpret coefficients/odds.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Your Turn: Fit model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# TODO: Build train/test split by time\n",
        "# Fit StandardScaler + LogisticRegression\n",
        "# Evaluate metrics and plot ROC/PR\n",
        "...\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Your Turn: Threshold tuning\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# TODO: Evaluate at thresholds 0.3, 0.5, 0.7\n",
        "# Discuss precision/recall tradeoffs\n",
        "...\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Checkpoint (Self-Check)\n",
        "Run a few asserts and write 2-3 sentences summarizing what you verified.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# TODO: After you build X/y and split by time, validate the split.\n",
        "# Example (adjust variable names):\n",
        "# assert X_train.index.max() < X_test.index.min()\n",
        "# assert y_train.index.equals(X_train.index)\n",
        "# assert y_test.index.equals(X_test.index)\n",
        "# assert not X_train.isna().any().any()\n",
        "# assert not X_test.isna().any().any()\n",
        "...\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Extensions (Optional)\n",
        "- Try one additional variant beyond the main path (different features, different split, different model).\n",
        "- Write down what improved, what got worse, and your hypothesis for why.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Reflection\n",
        "- What did you assume implicitly (about timing, availability, stationarity, or costs)?\n",
        "- If you had to ship this model, what would you monitor?\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Solutions (Reference)\n",
        "\n",
        "Try the TODOs first. Use these only to unblock yourself or to compare approaches.\n",
        "\n",
        "<details><summary>Solution: Train/test split</summary>\n",
        "\n",
        "```python\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "df = pd.read_csv(SAMPLE_DIR / 'macro_quarterly_sample.csv', index_col=0, parse_dates=True).dropna()\n",
        "target = 'target_recession_next_q'\n",
        "drop_cols = {target, 'recession', 'GDPC1', 'gdp_growth_qoq', 'gdp_growth_qoq_annualized', 'gdp_growth_yoy'}\n",
        "X = df[[c for c in df.columns if c not in drop_cols]].astype(float)\n",
        "y = df[target].astype(int)\n",
        "split = int(len(df)*0.8)\n",
        "X_tr, X_te = X.iloc[:split], X.iloc[split:]\n",
        "y_tr, y_te = y.iloc[:split], y.iloc[split:]\n",
        "```\n",
        "\n",
        "</details>\n",
        "\n",
        "<details><summary>Solution: Fit logistic</summary>\n",
        "\n",
        "```python\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from src import evaluation\n",
        "\n",
        "clf = Pipeline([('scaler', StandardScaler()), ('m', LogisticRegression(max_iter=5000))])\n",
        "clf.fit(X_tr, y_tr)\n",
        "p = clf.predict_proba(X_te)[:,1]\n",
        "evaluation.classification_metrics(y_te.to_numpy(), p)\n",
        "```\n",
        "\n",
        "</details>\n",
        "\n",
        "<details><summary>Solution: ROC/PR</summary>\n",
        "\n",
        "```python\n",
        "from sklearn.metrics import roc_curve, precision_recall_curve\n",
        "from src import plots\n",
        "\n",
        "fpr, tpr, _ = roc_curve(y_te, p)\n",
        "prec, rec, _ = precision_recall_curve(y_te, p)\n",
        "plots.plot_roc_curve(fpr, tpr)\n",
        "plots.plot_pr_curve(rec, prec)\n",
        "```\n",
        "\n",
        "</details>\n",
        "\n",
        "<details><summary>Solution: Threshold tuning</summary>\n",
        "\n",
        "```python\n",
        "from src import evaluation\n",
        "for thr in [0.3, 0.5, 0.7]:\n",
        "    print(thr, evaluation.classification_metrics(y_te.to_numpy(), p, threshold=thr))\n",
        "```\n",
        "\n",
        "</details>\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "python3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}