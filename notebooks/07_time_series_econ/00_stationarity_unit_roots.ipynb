{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 00 Stationarity and Unit Roots\n",
        "\n",
        "ADF/KPSS, differencing, and spurious regression intuition.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Table of Contents\n",
        "- [Load macro series](#load-macro-series)\n",
        "- [Transformations](#transformations)\n",
        "- [ADF/KPSS tests](#adf-kpss-tests)\n",
        "- [Spurious regression demo](#spurious-regression-demo)\n",
        "- [Checkpoint (Self-Check)](#checkpoint-self-check)\n",
        "- [Solutions (Reference)](#solutions-reference)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Why This Notebook Matters\n",
        "Time-series econometrics notebooks build the classical toolkit you need before trusting macro regressions:\n",
        "- stationarity + unit roots,\n",
        "- cointegration + error correction,\n",
        "- VAR dynamics and impulse responses.\n",
        "\n",
        "\n",
        "## Prerequisites (Quick Self-Check)\n",
        "- Completed Part 01 macro panel notebooks (or have `panel_monthly.csv` / sample available).\n",
        "- Comfort with differencing/log transforms and reading time series plots.\n",
        "\n",
        "## What You Will Produce\n",
        "- (no file output; learning/analysis notebook)\n",
        "\n",
        "## Success Criteria\n",
        "- You can explain what you built and why each step exists.\n",
        "- You can run your work end-to-end without undefined variables.\n",
        "\n",
        "## Common Pitfalls\n",
        "- Running cells top-to-bottom without reading the instructions.\n",
        "- Leaving `...` placeholders in code cells.\n",
        "- Running tests without plotting or transforming the series first.\n",
        "- Treating impulse responses as structural causality without an identification story.\n",
        "\n",
        "## Quick Fixes (When You Get Stuck)\n",
        "- If you see `ModuleNotFoundError`, re-run the bootstrap cell and restart the kernel; make sure `PROJECT_ROOT` is the repo root.\n",
        "- If a `data/processed/*` file is missing, either run the matching build script (see guide) or use the notebook\u2019s `data/sample/*` fallback.\n",
        "- If results look \u201ctoo good,\u201d suspect leakage; re-check shifts, rolling windows, and time splits.\n",
        "- If a model errors, check dtypes (`astype(float)`) and missingness (`dropna()` on required columns).\n",
        "\n",
        "## Matching Guide\n",
        "- `docs/guides/07_time_series_econ/00_stationarity_unit_roots.md`\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## How To Use This Notebook\n",
        "- Work section-by-section; don\u2019t skip the markdown.\n",
        "- Most code cells are incomplete on purpose: replace TODOs and `...`, then run.\n",
        "- After each section, write 2\u20134 sentences answering the interpretation prompts (what changed, why it matters).\n",
        "- Prefer `data/processed/*` if you have built the real datasets; otherwise use the bundled `data/sample/*` fallbacks.\n",
        "- Use the **Checkpoint (Self-Check)** section to catch mistakes early.\n",
        "- Use **Solutions (Reference)** only to unblock yourself; then re-implement without looking.\n",
        "- Use the matching guide (`docs/guides/07_time_series_econ/00_stationarity_unit_roots.md`) for the math, assumptions, and deeper context.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"environment-bootstrap\"></a>\n",
        "## Environment Bootstrap\n",
        "Run this cell first. It makes the repo importable and defines common directories.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "from pathlib import Path\n",
        "import sys\n",
        "\n",
        "\n",
        "def find_repo_root(start: Path) -> Path:\n",
        "    p = start\n",
        "    for _ in range(8):\n",
        "        if (p / 'src').exists() and (p / 'docs').exists():\n",
        "            return p\n",
        "        p = p.parent\n",
        "    raise RuntimeError('Could not find repo root. Start Jupyter from the repo root.')\n",
        "\n",
        "\n",
        "PROJECT_ROOT = find_repo_root(Path.cwd())\n",
        "if str(PROJECT_ROOT) not in sys.path:\n",
        "    sys.path.append(str(PROJECT_ROOT))\n",
        "\n",
        "DATA_DIR = PROJECT_ROOT / 'data'\n",
        "RAW_DIR = DATA_DIR / 'raw'\n",
        "PROCESSED_DIR = DATA_DIR / 'processed'\n",
        "SAMPLE_DIR = DATA_DIR / 'sample'\n",
        "\n",
        "PROJECT_ROOT\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Goal\n",
        "Learn the stationarity toolkit that prevents common macro mistakes:\n",
        "- spurious regression\n",
        "- over-trusting p-values on trending series\n",
        "- misinterpreting dynamics\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Primer: pandas time series essentials (indexing, resampling, lags)\n",
        "\n",
        "Most \u201cmysterious bugs\u201d in time series work come from index and alignment mistakes. This primer gives you the minimum patterns to avoid them.\n",
        "\n",
        "### 1) DatetimeIndex (the first thing to verify)\n",
        "\n",
        "Most time-series operations assume a `DatetimeIndex`:\n",
        "\n",
        "```python\n",
        "import pandas as pd\n",
        "\n",
        "df = df.copy()\n",
        "df.index = pd.to_datetime(df.index)\n",
        "df = df.sort_index()\n",
        "assert isinstance(df.index, pd.DatetimeIndex)\n",
        "```\n",
        "\n",
        "**Expected output / sanity checks**\n",
        "- `df.index.min(), df.index.max()` look reasonable\n",
        "- `df.index.is_monotonic_increasing` is `True`\n",
        "\n",
        "### 2) Resampling (frequency alignment)\n",
        "\n",
        "Resampling converts one frequency to another. Choose the aggregation rule intentionally.\n",
        "\n",
        "```python\n",
        "# month-end last value (end-of-period)\n",
        "df_me_last = df.resample(\"ME\").last()\n",
        "\n",
        "# month-end mean (average-of-period)\n",
        "df_me_mean = df.resample(\"ME\").mean()\n",
        "\n",
        "# quarter-end mean\n",
        "df_q_mean = df.resample(\"QE\").mean()\n",
        "```\n",
        "\n",
        "**Interpretation matters**\n",
        "- `.last()` treats end-of-period value as \u201cthe period\u2019s value.\u201d\n",
        "- `.mean()` treats the period average as \u201cthe period\u2019s value.\u201d\n",
        "\n",
        "### 3) Alignment and merging\n",
        "\n",
        "When joining series, always check missingness after the join:\n",
        "\n",
        "```python\n",
        "merged = df1.join(df2, how=\"outer\").sort_index()\n",
        "print(merged.isna().sum().sort_values(ascending=False).head(10))\n",
        "```\n",
        "\n",
        "### 4) Lags and rolling windows (watch for leakage!)\n",
        "\n",
        "```python\n",
        "# lag 1 period (past-only)\n",
        "df[\"x_lag1\"] = df[\"x\"].shift(1)\n",
        "\n",
        "# rolling mean using past values ending at t\n",
        "df[\"x_roll12\"] = df[\"x\"].rolling(12).mean()\n",
        "```\n",
        "\n",
        "**Leakage pitfalls**\n",
        "- `shift(-1)` uses the future.\n",
        "- `rolling(..., center=True)` uses the future.\n",
        "\n",
        "### 5) A quick workflow you should repeat\n",
        "\n",
        "1) Set and verify DatetimeIndex.\n",
        "2) Resample intentionally (mean vs last).\n",
        "3) Join and inspect missingness.\n",
        "4) Add lags/rolls (past-only).\n",
        "5) `dropna()` to build a clean modeling table.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Primer: Classical time-series econometrics with `statsmodels` (ADF/KPSS, cointegration, VAR/IRF)\n",
        "\n",
        "This repo already teaches time-aware evaluation for ML. This primer introduces the classical econometrics toolkit for time series:\n",
        "- stationarity / unit roots,\n",
        "- cointegration and error correction ideas,\n",
        "- VARs and impulse responses.\n",
        "\n",
        "Deep theory is in the guides; this primer focuses on \u201chow to use the tools correctly.\u201d\n",
        "\n",
        "### Before you start: what you should always do\n",
        "\n",
        "1) **Plot the series in levels** (look for trends, breaks).\n",
        "2) **Choose transformations** (diff/logdiff) for stationarity.\n",
        "3) **Drop missing values** before tests/models.\n",
        "\n",
        "### Stationarity tests (ADF / KPSS)\n",
        "\n",
        "Two common tests:\n",
        "- **ADF**: null = unit root (nonstationary)\n",
        "- **KPSS**: null = stationary\n",
        "\n",
        "```python\n",
        "from statsmodels.tsa.stattools import adfuller, kpss\n",
        "\n",
        "x = df[\"SERIES\"].dropna().to_numpy()\n",
        "\n",
        "adf_stat, adf_p, *_ = adfuller(x)\n",
        "kpss_stat, kpss_p, *_ = kpss(x, regression=\"c\", nlags=\"auto\")\n",
        "\n",
        "print(\"ADF p:\", adf_p, \"KPSS p:\", kpss_p)\n",
        "```\n",
        "\n",
        "**Expected output / sanity check**\n",
        "- trending level series often: ADF p not small, KPSS p small\n",
        "- differenced series often: ADF p small, KPSS p not small\n",
        "\n",
        "### Cointegration (Engle\u2013Granger test)\n",
        "\n",
        "If two series are individually nonstationary but move together long-run, they may be cointegrated.\n",
        "\n",
        "```python\n",
        "from statsmodels.tsa.stattools import coint\n",
        "\n",
        "y = df[\"Y\"].dropna()\n",
        "x = df[\"X\"].dropna()\n",
        "\n",
        "stat, p, _ = coint(y, x)\n",
        "print(\"coint p:\", p)\n",
        "```\n",
        "\n",
        "### VAR (vector autoregression)\n",
        "\n",
        "VAR models multiple stationary-ish series jointly.\n",
        "\n",
        "```python\n",
        "from statsmodels.tsa.api import VAR\n",
        "\n",
        "X = df[[\"UNRATE\", \"FEDFUNDS\", \"INDPRO\"]].astype(float).dropna()\n",
        "X = X.diff().dropna()  # common stationarity transform\n",
        "\n",
        "model = VAR(X)\n",
        "res = model.fit(maxlags=8, ic=\"aic\")  # or choose lags manually\n",
        "print(\"lags chosen:\", res.k_ar)\n",
        "print(res.summary())\n",
        "```\n",
        "\n",
        "**Expected output / sanity check**\n",
        "- `res.k_ar` is the chosen lag length\n",
        "- `res.is_stable(verbose=False)` should be True for a stable VAR\n",
        "\n",
        "### Granger causality (predictive, not causal)\n",
        "\n",
        "```python\n",
        "res.test_causality(\"UNRATE\", [\"FEDFUNDS\"]).summary()\n",
        "```\n",
        "\n",
        "Interpretation: \u201cdo lagged FEDFUNDS help predict UNRATE beyond lagged UNRATE?\u201d\n",
        "\n",
        "### Impulse responses (IRFs)\n",
        "\n",
        "```python\n",
        "irf = res.irf(12)\n",
        "irf.plot(orth=True)  # orthogonalized IRFs (ordering matters)\n",
        "```\n",
        "\n",
        "**Important:** orthogonalized IRFs depend on a Cholesky ordering.\n",
        "\n",
        "### Common pitfalls (and quick fixes)\n",
        "\n",
        "- **Nonstationary inputs:** VAR on levels can be nonsense.\n",
        "  - Fix: difference/logdiff; or use cointegration/VECM logic.\n",
        "- **Too many lags:** eats degrees of freedom and can destabilize the model.\n",
        "  - Fix: try smaller maxlags, compare AIC/BIC, check diagnostics.\n",
        "- **Misinterpreting Granger causality:** it is about predictive content, not structural causality.\n",
        "- **Forgetting ordering:** orth IRFs change when you reorder variables.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"load-macro-series\"></a>\n",
        "## Load macro series\n",
        "\n",
        "### Background\n",
        "Stationarity analysis is only meaningful if your time index is correct.\n",
        "So the first task is: load a clean monthly panel with a proper `DatetimeIndex`.\n",
        "\n",
        "### What you should see\n",
        "- a DataFrame indexed by dates (monthly).\n",
        "- key macro columns like CPI, unemployment, production.\n",
        "\n",
        "### Interpretation prompts\n",
        "- Which of these series looks trending in levels?\n",
        "- Which series might be closer to stationary already (in levels)?\n",
        "\n",
        "### Goal\n",
        "Load the macro monthly panel.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Your Turn: Load panel_monthly.csv (or sample)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "path = PROCESSED_DIR / 'panel_monthly.csv'\n",
        "if path.exists():\n",
        "    df = pd.read_csv(path, index_col=0, parse_dates=True)\n",
        "else:\n",
        "    df = pd.read_csv(SAMPLE_DIR / 'panel_monthly_sample.csv', index_col=0, parse_dates=True)\n",
        "\n",
        "df = df.dropna().copy()\n",
        "df.head()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"transformations\"></a>\n",
        "## Transformations\n",
        "\n",
        "### Background\n",
        "Many macro series are nonstationary in levels.\n",
        "Common fixes are:\n",
        "- differences (change),\n",
        "- percent changes (growth rates),\n",
        "- log-differences (approx growth rates for positive series).\n",
        "\n",
        "### What you should see\n",
        "- transformed columns with fewer trends.\n",
        "- a smaller DataFrame after `dropna()` (because differencing creates missing first row).\n",
        "\n",
        "### Interpretation prompts\n",
        "- Why might log-differences be preferred for production indexes?\n",
        "- What information do you lose when you difference?\n",
        "\n",
        "### Goal\n",
        "Create stationary-ish transformations (diff, pct change, log diff).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Your Turn: Differences and growth rates\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# TODO: Pick a few series and create transformations\n",
        "tmp = df[['CPIAUCSL', 'UNRATE', 'INDPRO']].astype(float).copy()\n",
        "tmp['dCPI'] = tmp['CPIAUCSL'].diff()\n",
        "tmp['dUNRATE'] = tmp['UNRATE'].diff()\n",
        "\n",
        "# log-diff for industrial production (example)\n",
        "x = tmp['INDPRO'].where(tmp['INDPRO'] > 0)\n",
        "tmp['dlog_INDPRO'] = np.log(x).diff()\n",
        "\n",
        "tmp = tmp.dropna()\n",
        "tmp.head()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"adf-kpss-tests\"></a>\n",
        "## ADF/KPSS tests\n",
        "\n",
        "### Background\n",
        "ADF and KPSS are complementary diagnostics:\n",
        "- ADF null: unit root (nonstationary)\n",
        "- KPSS null: stationary\n",
        "\n",
        "No single p-value is a proof. Use tests alongside plots and economic context.\n",
        "\n",
        "### What you should see\n",
        "- different p-values for level vs differenced series.\n",
        "- clearer stationarity evidence after transformation.\n",
        "\n",
        "### Interpretation prompts\n",
        "- In words: what does a small ADF p-value suggest?\n",
        "- In words: what does a small KPSS p-value suggest?\n",
        "\n",
        "### Goal\n",
        "Run stationarity diagnostics on levels vs transformed series.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Your Turn: ADF and KPSS\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "from statsmodels.tsa.stattools import adfuller, kpss\n",
        "\n",
        "# TODO: Choose one series and compare levels vs diff\n",
        "x = df['CPIAUCSL'].astype(float).dropna()\n",
        "dx = x.diff().dropna()\n",
        "\n",
        "out = {\n",
        "    'adf_p_level': adfuller(x)[1],\n",
        "    'adf_p_diff': adfuller(dx)[1],\n",
        "    'kpss_p_level': kpss(x, regression='c', nlags='auto')[1],\n",
        "    'kpss_p_diff': kpss(dx, regression='c', nlags='auto')[1],\n",
        "}\n",
        "out\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"spurious-regression-demo\"></a>\n",
        "## Spurious regression demo\n",
        "\n",
        "### Background\n",
        "A classic macro trap is regressing one trending series on another.\n",
        "You can get a high $R^2$ and significant coefficients even when the relationship is meaningless.\n",
        "\n",
        "### What you should see\n",
        "- the levels regression often has a higher $R^2$ than the differences regression.\n",
        "- this demonstrates why stationarity checks are a prerequisite for inference.\n",
        "\n",
        "### Interpretation prompts\n",
        "- Why can $R^2$ be high in a spurious regression?\n",
        "- What would you do next if you *needed* a meaningful long-run relationship? (hint: cointegration)\n",
        "\n",
        "### Goal\n",
        "Show how levels-on-levels regressions can look good for the wrong reasons.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Your Turn: Levels vs differences\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import statsmodels.api as sm\n",
        "\n",
        "tmp2 = df[['CPIAUCSL', 'INDPRO']].astype(float).dropna()\n",
        "\n",
        "# Levels regression\n",
        "res_lvl = sm.OLS(tmp2['CPIAUCSL'], sm.add_constant(tmp2[['INDPRO']], has_constant='add')).fit()\n",
        "\n",
        "# Differences regression\n",
        "d = tmp2.diff().dropna()\n",
        "res_diff = sm.OLS(d['CPIAUCSL'], sm.add_constant(d[['INDPRO']], has_constant='add')).fit()\n",
        "\n",
        "print('R2 levels:', res_lvl.rsquared)\n",
        "print('R2 diffs :', res_diff.rsquared)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"checkpoint-self-check\"></a>\n",
        "## Checkpoint (Self-Check)\n",
        "Run a few asserts and write 2-3 sentences summarizing what you verified.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# TODO: Validate your time series table is well-formed.\n",
        "# Example (adjust variable names):\n",
        "# assert isinstance(df.index, pd.DatetimeIndex)\n",
        "# assert df.index.is_monotonic_increasing\n",
        "# assert df.shape[0] > 30\n",
        "#\n",
        "# TODO: If you built transformed series (diff/logdiff), confirm no future leakage.\n",
        "# Hint: transformations should only use past/current values (shift/diff), never future.\n",
        "...\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Extensions (Optional)\n",
        "- Try one additional variant beyond the main path (different features, different split, different model).\n",
        "- Write down what improved, what got worse, and your hypothesis for why.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Reflection\n",
        "- What did you assume implicitly (about timing, availability, stationarity, or costs)?\n",
        "- If you had to ship this model, what would you monitor?\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"solutions-reference\"></a>\n",
        "## Solutions (Reference)\n",
        "\n",
        "Try the TODOs first. Use these only to unblock yourself or to compare approaches.\n",
        "\n",
        "<details><summary>Solution: Load macro series</summary>\n",
        "\n",
        "_One possible approach. Your variable names may differ; align them with the notebook._\n",
        "\n",
        "```python\n",
        "# Reference solution for 00_stationarity_unit_roots \u2014 Load macro series\n",
        "import pandas as pd\n",
        "\n",
        "path = PROCESSED_DIR / 'panel_monthly.csv'\n",
        "if path.exists():\n",
        "    df = pd.read_csv(path, index_col=0, parse_dates=True)\n",
        "else:\n",
        "    df = pd.read_csv(SAMPLE_DIR / 'panel_monthly_sample.csv', index_col=0, parse_dates=True)\n",
        "\n",
        "df = df.dropna().copy()\n",
        "df.head()\n",
        "```\n",
        "\n",
        "</details>\n",
        "\n",
        "<details><summary>Solution: Transformations</summary>\n",
        "\n",
        "_One possible approach. Your variable names may differ; align them with the notebook._\n",
        "\n",
        "```python\n",
        "# Reference solution for 00_stationarity_unit_roots \u2014 Transformations\n",
        "# Example: difference CPI and unemployment\n",
        "df_t = df[['CPIAUCSL', 'UNRATE']].astype(float).copy()\n",
        "df_t['dCPI'] = df_t['CPIAUCSL'].diff()\n",
        "df_t['dUNRATE'] = df_t['UNRATE'].diff()\n",
        "df_t = df_t.dropna()\n",
        "df_t.head()\n",
        "```\n",
        "\n",
        "</details>\n",
        "\n",
        "<details><summary>Solution: ADF/KPSS tests</summary>\n",
        "\n",
        "_One possible approach. Your variable names may differ; align them with the notebook._\n",
        "\n",
        "```python\n",
        "# Reference solution for 00_stationarity_unit_roots \u2014 ADF/KPSS tests\n",
        "from statsmodels.tsa.stattools import adfuller, kpss\n",
        "\n",
        "x = df['CPIAUCSL'].astype(float).dropna()\n",
        "dx = x.diff().dropna()\n",
        "\n",
        "adf_p_level = adfuller(x)[1]\n",
        "adf_p_diff = adfuller(dx)[1]\n",
        "kpss_p_level = kpss(x, regression='c', nlags='auto')[1]\n",
        "kpss_p_diff = kpss(dx, regression='c', nlags='auto')[1]\n",
        "\n",
        "{'adf_p_level': adf_p_level, 'adf_p_diff': adf_p_diff, 'kpss_p_level': kpss_p_level, 'kpss_p_diff': kpss_p_diff}\n",
        "```\n",
        "\n",
        "</details>\n",
        "\n",
        "<details><summary>Solution: Spurious regression demo</summary>\n",
        "\n",
        "_One possible approach. Your variable names may differ; align them with the notebook._\n",
        "\n",
        "```python\n",
        "# Reference solution for 00_stationarity_unit_roots \u2014 Spurious regression demo\n",
        "import statsmodels.api as sm\n",
        "\n",
        "# Levels-on-levels can look 'significant' even when dynamics are mis-specified.\n",
        "tmp = df[['CPIAUCSL', 'INDPRO']].astype(float).dropna()\n",
        "res_lvl = sm.OLS(tmp['CPIAUCSL'], sm.add_constant(tmp[['INDPRO']], has_constant='add')).fit()\n",
        "res_diff = sm.OLS(tmp['CPIAUCSL'].diff().dropna(), sm.add_constant(tmp['INDPRO'].diff().dropna(), has_constant='add')).fit()\n",
        "\n",
        "(res_lvl.rsquared, res_diff.rsquared)\n",
        "```\n",
        "\n",
        "</details>\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "python3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}