{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 01 Cointegration and Error Correction\n",
        "\n",
        "Engle-Granger cointegration and error correction models (ECM).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Table of Contents\n",
        "- [Construct cointegrated pair](#construct-cointegrated-pair)\n",
        "- [Engle-Granger test](#engle-granger-test)\n",
        "- [Error correction model](#error-correction-model)\n",
        "- [Interpretation](#interpretation)\n",
        "- [Checkpoint (Self-Check)](#checkpoint-self-check)\n",
        "- [Solutions (Reference)](#solutions-reference)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Why This Notebook Matters\n",
        "Time-series econometrics notebooks build the classical toolkit you need before trusting macro regressions:\n",
        "- stationarity + unit roots,\n",
        "- cointegration + error correction,\n",
        "- VAR dynamics and impulse responses.\n",
        "\n",
        "\n",
        "## Prerequisites (Quick Self-Check)\n",
        "- Completed Part 01 macro panel notebooks (or have `panel_monthly.csv` / sample available).\n",
        "- Comfort with differencing/log transforms and reading time series plots.\n",
        "\n",
        "## What You Will Produce\n",
        "- (no file output; learning/analysis notebook)\n",
        "\n",
        "## Success Criteria\n",
        "- You can explain what you built and why each step exists.\n",
        "- You can run your work end-to-end without undefined variables.\n",
        "\n",
        "## Common Pitfalls\n",
        "- Running cells top-to-bottom without reading the instructions.\n",
        "- Leaving `...` placeholders in code cells.\n",
        "- Running tests without plotting or transforming the series first.\n",
        "- Treating impulse responses as structural causality without an identification story.\n",
        "\n",
        "## Quick Fixes (When You Get Stuck)\n",
        "- If you see `ModuleNotFoundError`, re-run the bootstrap cell and restart the kernel; make sure `PROJECT_ROOT` is the repo root.\n",
        "- If a `data/processed/*` file is missing, either run the matching build script (see guide) or use the notebook\u2019s `data/sample/*` fallback.\n",
        "- If results look \u201ctoo good,\u201d suspect leakage; re-check shifts, rolling windows, and time splits.\n",
        "- If a model errors, check dtypes (`astype(float)`) and missingness (`dropna()` on required columns).\n",
        "\n",
        "## Matching Guide\n",
        "- `docs/guides/07_time_series_econ/01_cointegration_error_correction.md`\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## How To Use This Notebook\n",
        "- Work section-by-section; don\u2019t skip the markdown.\n",
        "- Most code cells are incomplete on purpose: replace TODOs and `...`, then run.\n",
        "- After each section, write 2\u20134 sentences answering the interpretation prompts (what changed, why it matters).\n",
        "- Prefer `data/processed/*` if you have built the real datasets; otherwise use the bundled `data/sample/*` fallbacks.\n",
        "- Use the **Checkpoint (Self-Check)** section to catch mistakes early.\n",
        "- Use **Solutions (Reference)** only to unblock yourself; then re-implement without looking.\n",
        "- Use the matching guide (`docs/guides/07_time_series_econ/01_cointegration_error_correction.md`) for the math, assumptions, and deeper context.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"environment-bootstrap\"></a>\n",
        "## Environment Bootstrap\n",
        "Run this cell first. It makes the repo importable and defines common directories.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "from pathlib import Path\n",
        "import sys\n",
        "\n",
        "\n",
        "def find_repo_root(start: Path) -> Path:\n",
        "    p = start\n",
        "    for _ in range(8):\n",
        "        if (p / 'src').exists() and (p / 'docs').exists():\n",
        "            return p\n",
        "        p = p.parent\n",
        "    raise RuntimeError('Could not find repo root. Start Jupyter from the repo root.')\n",
        "\n",
        "\n",
        "PROJECT_ROOT = find_repo_root(Path.cwd())\n",
        "if str(PROJECT_ROOT) not in sys.path:\n",
        "    sys.path.append(str(PROJECT_ROOT))\n",
        "\n",
        "DATA_DIR = PROJECT_ROOT / 'data'\n",
        "RAW_DIR = DATA_DIR / 'raw'\n",
        "PROCESSED_DIR = DATA_DIR / 'processed'\n",
        "SAMPLE_DIR = DATA_DIR / 'sample'\n",
        "\n",
        "PROJECT_ROOT\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Goal\n",
        "Learn cointegration and error correction models (ECM):\n",
        "- long-run equilibrium relationship\n",
        "- short-run dynamics that correct deviations\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Primer: Classical time-series econometrics with `statsmodels` (ADF/KPSS, cointegration, VAR/IRF)\n",
        "\n",
        "This repo already teaches time-aware evaluation for ML. This primer introduces the classical econometrics toolkit for time series:\n",
        "- stationarity / unit roots,\n",
        "- cointegration and error correction ideas,\n",
        "- VARs and impulse responses.\n",
        "\n",
        "Deep theory is in the guides; this primer focuses on \u201chow to use the tools correctly.\u201d\n",
        "\n",
        "### Before you start: what you should always do\n",
        "\n",
        "1) **Plot the series in levels** (look for trends, breaks).\n",
        "2) **Choose transformations** (diff/logdiff) for stationarity.\n",
        "3) **Drop missing values** before tests/models.\n",
        "\n",
        "### Stationarity tests (ADF / KPSS)\n",
        "\n",
        "Two common tests:\n",
        "- **ADF**: null = unit root (nonstationary)\n",
        "- **KPSS**: null = stationary\n",
        "\n",
        "```python\n",
        "from statsmodels.tsa.stattools import adfuller, kpss\n",
        "\n",
        "x = df[\"SERIES\"].dropna().to_numpy()\n",
        "\n",
        "adf_stat, adf_p, *_ = adfuller(x)\n",
        "kpss_stat, kpss_p, *_ = kpss(x, regression=\"c\", nlags=\"auto\")\n",
        "\n",
        "print(\"ADF p:\", adf_p, \"KPSS p:\", kpss_p)\n",
        "```\n",
        "\n",
        "**Expected output / sanity check**\n",
        "- trending level series often: ADF p not small, KPSS p small\n",
        "- differenced series often: ADF p small, KPSS p not small\n",
        "\n",
        "### Cointegration (Engle\u2013Granger test)\n",
        "\n",
        "If two series are individually nonstationary but move together long-run, they may be cointegrated.\n",
        "\n",
        "```python\n",
        "from statsmodels.tsa.stattools import coint\n",
        "\n",
        "y = df[\"Y\"].dropna()\n",
        "x = df[\"X\"].dropna()\n",
        "\n",
        "stat, p, _ = coint(y, x)\n",
        "print(\"coint p:\", p)\n",
        "```\n",
        "\n",
        "### VAR (vector autoregression)\n",
        "\n",
        "VAR models multiple stationary-ish series jointly.\n",
        "\n",
        "```python\n",
        "from statsmodels.tsa.api import VAR\n",
        "\n",
        "X = df[[\"UNRATE\", \"FEDFUNDS\", \"INDPRO\"]].astype(float).dropna()\n",
        "X = X.diff().dropna()  # common stationarity transform\n",
        "\n",
        "model = VAR(X)\n",
        "res = model.fit(maxlags=8, ic=\"aic\")  # or choose lags manually\n",
        "print(\"lags chosen:\", res.k_ar)\n",
        "print(res.summary())\n",
        "```\n",
        "\n",
        "**Expected output / sanity check**\n",
        "- `res.k_ar` is the chosen lag length\n",
        "- `res.is_stable(verbose=False)` should be True for a stable VAR\n",
        "\n",
        "### Granger causality (predictive, not causal)\n",
        "\n",
        "```python\n",
        "res.test_causality(\"UNRATE\", [\"FEDFUNDS\"]).summary()\n",
        "```\n",
        "\n",
        "Interpretation: \u201cdo lagged FEDFUNDS help predict UNRATE beyond lagged UNRATE?\u201d\n",
        "\n",
        "### Impulse responses (IRFs)\n",
        "\n",
        "```python\n",
        "irf = res.irf(12)\n",
        "irf.plot(orth=True)  # orthogonalized IRFs (ordering matters)\n",
        "```\n",
        "\n",
        "**Important:** orthogonalized IRFs depend on a Cholesky ordering.\n",
        "\n",
        "### Common pitfalls (and quick fixes)\n",
        "\n",
        "- **Nonstationary inputs:** VAR on levels can be nonsense.\n",
        "  - Fix: difference/logdiff; or use cointegration/VECM logic.\n",
        "- **Too many lags:** eats degrees of freedom and can destabilize the model.\n",
        "  - Fix: try smaller maxlags, compare AIC/BIC, check diagnostics.\n",
        "- **Misinterpreting Granger causality:** it is about predictive content, not structural causality.\n",
        "- **Forgetting ordering:** orth IRFs change when you reorder variables.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"construct-cointegrated-pair\"></a>\n",
        "## Construct cointegrated pair\n",
        "\n",
        "### Background\n",
        "Cointegration is the key exception to the \u201clevels regressions are spurious\u201d warning.\n",
        "Two series can be nonstationary individually but have a stable long-run relationship.\n",
        "\n",
        "### What you should see\n",
        "- `x` and `y` trend over time.\n",
        "- `y - x` should look roughly stationary (because we simulated cointegration).\n",
        "\n",
        "### Interpretation prompts\n",
        "- In one sentence: what does it mean for two series to be cointegrated?\n",
        "- Why do we simulate first before applying to real macro series?\n",
        "\n",
        "### Goal\n",
        "Construct a pair of series that are individually nonstationary but cointegrated.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Your Turn: Simulate a cointegrated pair\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "rng = np.random.default_rng(0)\n",
        "n = 240\n",
        "idx = pd.date_range('2000-01-31', periods=n, freq='ME')\n",
        "\n",
        "x = rng.normal(size=n).cumsum()\n",
        "y = 1.0 * x + rng.normal(scale=0.5, size=n)\n",
        "\n",
        "df = pd.DataFrame({'x': x, 'y': y}, index=idx)\n",
        "df.head()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"engle-granger-test\"></a>\n",
        "## Engle-Granger test\n",
        "\n",
        "### Background\n",
        "The Engle\u2013Granger approach:\n",
        "1) regress $y$ on $x$ in levels,\n",
        "2) test whether the residual is stationary.\n",
        "\n",
        "### What you should see\n",
        "- a cointegration test p-value (often small in this simulated example).\n",
        "\n",
        "### Interpretation prompts\n",
        "- What is the null hypothesis in the cointegration test?\n",
        "- If the p-value were large, what would that suggest?\n",
        "\n",
        "### Goal\n",
        "Run a cointegration test and interpret the p-value carefully.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Your Turn: Cointegration test\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "from statsmodels.tsa.stattools import coint\n",
        "\n",
        "t_stat, p_val, _ = coint(df['y'], df['x'])\n",
        "{'t': t_stat, 'p': p_val}\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"error-correction-model\"></a>\n",
        "## Error correction model\n",
        "\n",
        "### Background\n",
        "An ECM links:\n",
        "- short-run changes ($\\Delta y_t$)\n",
        "- to long-run disequilibrium (lagged residual from the levels relationship).\n",
        "\n",
        "### What you should see\n",
        "- an estimated coefficient on `u_lag1` (often negative in a stable cointegrated system).\n",
        "- interpretation as \u201cspeed of adjustment.\u201d\n",
        "\n",
        "### Interpretation prompts\n",
        "- What does the sign of the error-correction coefficient mean?\n",
        "- Why do we use the lagged residual rather than the current residual?\n",
        "\n",
        "### Goal\n",
        "Fit an ECM:\n",
        "- short-run changes depend on long-run disequilibrium (lagged residual)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Your Turn: Fit ECM\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import statsmodels.api as sm\n",
        "\n",
        "# Long-run regression\n",
        "lr = sm.OLS(df['y'], sm.add_constant(df[['x']], has_constant='add')).fit()\n",
        "df['u'] = lr.resid\n",
        "\n",
        "# ECM regression\n",
        "ecm = pd.DataFrame({\n",
        "    'dy': df['y'].diff(),\n",
        "    'dx': df['x'].diff(),\n",
        "    'u_lag1': df['u'].shift(1),\n",
        "}).dropna()\n",
        "\n",
        "res = sm.OLS(ecm['dy'], sm.add_constant(ecm[['dx', 'u_lag1']], has_constant='add')).fit()\n",
        "res.params\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"interpretation\"></a>\n",
        "## Interpretation\n",
        "\n",
        "Write 5-8 sentences:\n",
        "- What does the error-correction coefficient mean?\n",
        "- What would you expect if there were no cointegration?\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"checkpoint-self-check\"></a>\n",
        "## Checkpoint (Self-Check)\n",
        "Run a few asserts and write 2-3 sentences summarizing what you verified.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# TODO: Validate your time series table is well-formed.\n",
        "# Example (adjust variable names):\n",
        "# assert isinstance(df.index, pd.DatetimeIndex)\n",
        "# assert df.index.is_monotonic_increasing\n",
        "# assert df.shape[0] > 30\n",
        "#\n",
        "# TODO: If you built transformed series (diff/logdiff), confirm no future leakage.\n",
        "# Hint: transformations should only use past/current values (shift/diff), never future.\n",
        "...\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Extensions (Optional)\n",
        "- Try one additional variant beyond the main path (different features, different split, different model).\n",
        "- Write down what improved, what got worse, and your hypothesis for why.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Reflection\n",
        "- What did you assume implicitly (about timing, availability, stationarity, or costs)?\n",
        "- If you had to ship this model, what would you monitor?\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"solutions-reference\"></a>\n",
        "## Solutions (Reference)\n",
        "\n",
        "Try the TODOs first. Use these only to unblock yourself or to compare approaches.\n",
        "\n",
        "<details><summary>Solution: Construct cointegrated pair</summary>\n",
        "\n",
        "_One possible approach. Your variable names may differ; align them with the notebook._\n",
        "\n",
        "```python\n",
        "# Reference solution for 01_cointegration_error_correction \u2014 Construct cointegrated pair\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "rng = np.random.default_rng(0)\n",
        "n = 240\n",
        "idx = pd.date_range('2000-01-31', periods=n, freq='ME')\n",
        "\n",
        "x = rng.normal(size=n).cumsum()  # random walk\n",
        "y = 1.0 * x + rng.normal(scale=0.5, size=n)  # cointegrated with x\n",
        "\n",
        "df = pd.DataFrame({'x': x, 'y': y}, index=idx)\n",
        "df.head()\n",
        "```\n",
        "\n",
        "</details>\n",
        "\n",
        "<details><summary>Solution: Engle-Granger test</summary>\n",
        "\n",
        "_One possible approach. Your variable names may differ; align them with the notebook._\n",
        "\n",
        "```python\n",
        "# Reference solution for 01_cointegration_error_correction \u2014 Engle-Granger test\n",
        "from statsmodels.tsa.stattools import coint\n",
        "\n",
        "t_stat, p_val, _ = coint(df['y'], df['x'])\n",
        "{'t': t_stat, 'p': p_val}\n",
        "```\n",
        "\n",
        "</details>\n",
        "\n",
        "<details><summary>Solution: Error correction model</summary>\n",
        "\n",
        "_One possible approach. Your variable names may differ; align them with the notebook._\n",
        "\n",
        "```python\n",
        "# Reference solution for 01_cointegration_error_correction \u2014 Error correction model\n",
        "import statsmodels.api as sm\n",
        "\n",
        "# Step 1: long-run relationship\n",
        "lr = sm.OLS(df['y'], sm.add_constant(df[['x']], has_constant='add')).fit()\n",
        "df['u'] = lr.resid\n",
        "\n",
        "# Step 2: ECM\n",
        "ecm = pd.DataFrame({\n",
        "    'dy': df['y'].diff(),\n",
        "    'dx': df['x'].diff(),\n",
        "    'u_lag1': df['u'].shift(1),\n",
        "}).dropna()\n",
        "\n",
        "res = sm.OLS(ecm['dy'], sm.add_constant(ecm[['dx', 'u_lag1']], has_constant='add')).fit()\n",
        "res.params\n",
        "```\n",
        "\n",
        "</details>\n",
        "\n",
        "<details><summary>Solution: Interpretation</summary>\n",
        "\n",
        "_One possible approach. Your variable names may differ; align them with the notebook._\n",
        "\n",
        "```python\n",
        "# Reference solution for 01_cointegration_error_correction \u2014 Interpretation\n",
        "# Explain what the error-correction coefficient implies about mean reversion.\n",
        "```\n",
        "\n",
        "</details>\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "python3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}