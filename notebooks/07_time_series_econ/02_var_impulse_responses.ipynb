{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02 VAR and Impulse Responses\n",
    "\n",
    "Fit VARs, test Granger causality, and interpret IRFs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "- [Build stationary dataset](#build-stationary-dataset)\n",
    "- [Fit VAR + choose lags](#fit-var-choose-lags)\n",
    "- [Granger causality](#granger-causality)\n",
    "- [IRFs + forecasting](#irfs-forecasting)\n",
    "- [Checkpoint (Self-Check)](#checkpoint-self-check)\n",
    "- [Solutions (Reference)](#solutions-reference)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why This Notebook Matters\n",
    "Time-series econometrics notebooks build the classical toolkit you need before trusting macro regressions:\n",
    "- stationarity + unit roots,\n",
    "- cointegration + error correction,\n",
    "- VAR dynamics and impulse responses.\n",
    "\n",
    "\n",
    "## Prerequisites (Quick Self-Check)\n",
    "- Completed Part 01 macro panel notebooks (or have `panel_monthly.csv` / sample available).\n",
    "- Comfort with differencing/log transforms and reading time series plots.\n",
    "\n",
    "## What You Will Produce\n",
    "- (no file output; learning/analysis notebook)\n",
    "\n",
    "## Success Criteria\n",
    "- You can explain what you built and why each step exists.\n",
    "- You can run your work end-to-end without undefined variables.\n",
    "\n",
    "## Common Pitfalls\n",
    "- Running cells top-to-bottom without reading the instructions.\n",
    "- Leaving `...` placeholders in code cells.\n",
    "- Running tests without plotting or transforming the series first.\n",
    "- Treating impulse responses as structural causality without an identification story.\n",
    "\n",
    "## Quick Fixes (When You Get Stuck)\n",
    "- If you see `ModuleNotFoundError`, re-run the bootstrap cell and restart the kernel; make sure `PROJECT_ROOT` is the repo root.\n",
    "- If a `data/processed/*` file is missing, either run the matching build script (see guide) or use the notebook’s `data/sample/*` fallback.\n",
    "- If results look “too good,” suspect leakage; re-check shifts, rolling windows, and time splits.\n",
    "- If a model errors, check dtypes (`astype(float)`) and missingness (`dropna()` on required columns).\n",
    "\n",
    "## Matching Guide\n",
    "- `docs/guides/07_time_series_econ/02_var_impulse_responses.md`\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How To Use This Notebook\n",
    "- Work section-by-section; don’t skip the markdown.\n",
    "- Most code cells are incomplete on purpose: replace TODOs and `...`, then run.\n",
    "- After each section, write 2–4 sentences answering the interpretation prompts (what changed, why it matters).\n",
    "- Prefer `data/processed/*` if you have built the real datasets; otherwise use the bundled `data/sample/*` fallbacks.\n",
    "- Use the **Checkpoint (Self-Check)** section to catch mistakes early.\n",
    "- Use **Solutions (Reference)** only to unblock yourself; then re-implement without looking.\n",
    "- Use the matching guide (`docs/guides/07_time_series_econ/02_var_impulse_responses.md`) for the math, assumptions, and deeper context.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"environment-bootstrap\"></a>\n",
    "## Environment Bootstrap\n",
    "Run this cell first. It makes the repo importable and defines common directories.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "\n",
    "def find_repo_root(start: Path) -> Path:\n",
    "    p = start\n",
    "    for _ in range(8):\n",
    "        if (p / 'src').exists() and (p / 'docs').exists():\n",
    "            return p\n",
    "        p = p.parent\n",
    "    raise RuntimeError('Could not find repo root. Start Jupyter from the repo root.')\n",
    "\n",
    "\n",
    "PROJECT_ROOT = find_repo_root(Path.cwd())\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.append(str(PROJECT_ROOT))\n",
    "\n",
    "DATA_DIR = PROJECT_ROOT / 'data'\n",
    "RAW_DIR = DATA_DIR / 'raw'\n",
    "PROCESSED_DIR = DATA_DIR / 'processed'\n",
    "SAMPLE_DIR = DATA_DIR / 'sample'\n",
    "\n",
    "PROJECT_ROOT\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal\n",
    "Fit a VAR on transformed macro series and interpret:\n",
    "- lag selection\n",
    "- Granger causality\n",
    "- impulse response functions (IRFs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Primer: Classical time-series econometrics with `statsmodels` (ADF/KPSS, cointegration, VAR/IRF)\n",
    "\n",
    "This repo already teaches time-aware evaluation for ML. This primer introduces the classical econometrics toolkit for time series:\n",
    "- stationarity / unit roots,\n",
    "- cointegration and error correction ideas,\n",
    "- VARs and impulse responses.\n",
    "\n",
    "Deep theory is in the guides; this primer focuses on “how to use the tools correctly.”\n",
    "\n",
    "### Before you start: what you should always do\n",
    "\n",
    "1) **Plot the series in levels** (look for trends, breaks).\n",
    "2) **Choose transformations** (diff/logdiff) for stationarity.\n",
    "3) **Drop missing values** before tests/models.\n",
    "\n",
    "### Stationarity tests (ADF / KPSS)\n",
    "\n",
    "Two common tests:\n",
    "- **ADF**: null = unit root (nonstationary)\n",
    "- **KPSS**: null = stationary\n",
    "\n",
    "```python\n",
    "from statsmodels.tsa.stattools import adfuller, kpss\n",
    "\n",
    "x = df[\"SERIES\"].dropna().to_numpy()\n",
    "\n",
    "adf_stat, adf_p, *_ = adfuller(x)\n",
    "kpss_stat, kpss_p, *_ = kpss(x, regression=\"c\", nlags=\"auto\")\n",
    "\n",
    "print(\"ADF p:\", adf_p, \"KPSS p:\", kpss_p)\n",
    "```\n",
    "\n",
    "**Expected output / sanity check**\n",
    "- trending level series often: ADF p not small, KPSS p small\n",
    "- differenced series often: ADF p small, KPSS p not small\n",
    "\n",
    "### Cointegration (Engle–Granger test)\n",
    "\n",
    "If two series are individually nonstationary but move together long-run, they may be cointegrated.\n",
    "\n",
    "```python\n",
    "from statsmodels.tsa.stattools import coint\n",
    "\n",
    "y = df[\"Y\"].dropna()\n",
    "x = df[\"X\"].dropna()\n",
    "\n",
    "stat, p, _ = coint(y, x)\n",
    "print(\"coint p:\", p)\n",
    "```\n",
    "\n",
    "### VAR (vector autoregression)\n",
    "\n",
    "VAR models multiple stationary-ish series jointly.\n",
    "\n",
    "```python\n",
    "from statsmodels.tsa.api import VAR\n",
    "\n",
    "X = df[[\"UNRATE\", \"FEDFUNDS\", \"INDPRO\"]].astype(float).dropna()\n",
    "X = X.diff().dropna()  # common stationarity transform\n",
    "\n",
    "model = VAR(X)\n",
    "res = model.fit(maxlags=8, ic=\"aic\")  # or choose lags manually\n",
    "print(\"lags chosen:\", res.k_ar)\n",
    "print(res.summary())\n",
    "```\n",
    "\n",
    "**Expected output / sanity check**\n",
    "- `res.k_ar` is the chosen lag length\n",
    "- `res.is_stable(verbose=False)` should be True for a stable VAR\n",
    "\n",
    "### Granger causality (predictive, not causal)\n",
    "\n",
    "```python\n",
    "res.test_causality(\"UNRATE\", [\"FEDFUNDS\"]).summary()\n",
    "```\n",
    "\n",
    "Interpretation: “do lagged FEDFUNDS help predict UNRATE beyond lagged UNRATE?”\n",
    "\n",
    "### Impulse responses (IRFs)\n",
    "\n",
    "```python\n",
    "irf = res.irf(12)\n",
    "irf.plot(orth=True)  # orthogonalized IRFs (ordering matters)\n",
    "```\n",
    "\n",
    "**Important:** orthogonalized IRFs depend on a Cholesky ordering.\n",
    "\n",
    "### Common pitfalls (and quick fixes)\n",
    "\n",
    "- **Nonstationary inputs:** VAR on levels can be nonsense.\n",
    "  - Fix: difference/logdiff; or use cointegration/VECM logic.\n",
    "- **Too many lags:** eats degrees of freedom and can destabilize the model.\n",
    "  - Fix: try smaller maxlags, compare AIC/BIC, check diagnostics.\n",
    "- **Misinterpreting Granger causality:** it is about predictive content, not structural causality.\n",
    "- **Forgetting ordering:** orth IRFs change when you reorder variables.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"build-stationary-dataset\"></a>\n",
    "## Build stationary dataset\n",
    "\n",
    "### Background\n",
    "VARs generally require stable (stationary-ish) inputs.\n",
    "A common first pass is to difference level series.\n",
    "\n",
    "### What you should see\n",
    "- a DataFrame of transformed series (no missing values).\n",
    "- columns are numeric floats.\n",
    "\n",
    "### Interpretation prompts\n",
    "- What does differencing do to trends and to noise?\n",
    "- Which series might require log-differencing rather than differencing?\n",
    "\n",
    "### Goal\n",
    "Build a small stationary-ish dataset to fit a VAR.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your Turn: Load and transform\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "panel = pd.read_csv(SAMPLE_DIR / 'panel_monthly_sample.csv', index_col=0, parse_dates=True).dropna()\n",
    "\n",
    "# TODO: Choose a few columns and difference them\n",
    "df = panel[['UNRATE', 'FEDFUNDS', 'INDPRO']].astype(float).diff().dropna()\n",
    "df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"fit-var-choose-lags\"></a>\n",
    "## Fit VAR + choose lags\n",
    "\n",
    "### Background\n",
    "VAR lag length is a bias–variance decision:\n",
    "- too few lags → leftover autocorrelation and misspecification,\n",
    "- too many lags → unstable estimates and low degrees of freedom.\n",
    "\n",
    "### What you should see\n",
    "- a chosen lag order (`res.k_ar`).\n",
    "- a model summary with coefficients for lagged terms.\n",
    "\n",
    "### Interpretation prompts\n",
    "- Why might AIC choose more lags than BIC?\n",
    "- What diagnostic would you check if you suspect too few lags?\n",
    "\n",
    "### Goal\n",
    "Fit a VAR and choose lags using an information criterion.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your Turn: Fit VAR\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "from statsmodels.tsa.api import VAR\n",
    "\n",
    "# TODO: Fit and inspect chosen lag order\n",
    "res = VAR(df).fit(maxlags=8, ic='aic')\n",
    "res.k_ar\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"granger-causality\"></a>\n",
    "## Granger causality\n",
    "\n",
    "### Background\n",
    "Granger causality asks a forecasting question:\n",
    "- do lagged values of $x$ help predict $y$ beyond lagged $y$?\n",
    "\n",
    "It is not structural causality.\n",
    "\n",
    "### What you should see\n",
    "- a test output summary for one direction (e.g., FEDFUNDS → UNRATE).\n",
    "\n",
    "### Interpretation prompts\n",
    "- Rewrite the Granger test result as a forecasting statement (not a causal one).\n",
    "- Why can a third variable create apparent Granger relationships?\n",
    "\n",
    "### Goal\n",
    "Run at least one Granger causality test.\n",
    "\n",
    "Reminder: this is predictive causality, not structural causality.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your Turn: Test causality\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Example: do lagged FEDFUNDS help predict UNRATE?\n",
    "res.test_causality('UNRATE', ['FEDFUNDS']).summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## IRFs + forecasting\n\n### Background\nImpulse responses trace how a one-time shock propagates through the VAR dynamics.\nOrthogonalized IRFs (Cholesky) impose an identification choice via variable ordering.\n\n### Reduced-form vs Structural VARs\n\nThe VAR estimated here is a **reduced-form** VAR: it captures correlations and dynamics but does not identify structural shocks. The Cholesky decomposition imposes a recursive ordering assumption:\n- The first variable responds to its own shock contemporaneously.\n- The second variable can respond to the first variable's shock contemporaneously, but the first cannot respond to the second's.\n- And so on.\n\nA **Structural VAR (SVAR)** uses economic theory to justify identification restrictions (e.g., short-run zero restrictions, long-run restrictions, or sign restrictions). SVARs are beyond this notebook's scope, but you should know they exist when interpreting IRFs.\n\n### Granger causality: what it is and what it is NOT\n\nGranger causality is a statistical concept: \"$x$ Granger-causes $y$\" means lagged $x$ has predictive content for $y$ beyond lagged $y$ itself. This is **not structural causality**:\n- A third variable $z$ that drives both $x$ and $y$ can create apparent Granger causality.\n- The Fed may set rates in response to expected unemployment, creating a statistical relationship that reverses the causal direction.\n- Granger causality depends on the information set (which variables are in the VAR).\n\n**Rule**: Always write Granger causality results as forecasting statements, never as causal claims.\n\n### What you should see\n- an IRF plot over the chosen horizon.\n- qualitative responses that decay if the VAR is stable.\n\n### Interpretation prompts\n- How does changing the variable ordering change the meaning of the shock?\n- Which IRF responses would you view as economically plausible vs suspicious?\n\n### Goal\nCompute and plot impulse responses.\n\nCaution:\n- orthogonalized IRFs depend on variable ordering.\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your Turn: IRFs\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "irf = res.irf(12)\n",
    "irf.plot(orth=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"checkpoint-self-check\"></a>\n",
    "## Checkpoint (Self-Check)\n",
    "Run a few asserts and write 2-3 sentences summarizing what you verified.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# TODO: Validate your time series table is well-formed.\n",
    "# Example (adjust variable names):\n",
    "# assert isinstance(df.index, pd.DatetimeIndex)\n",
    "# assert df.index.is_monotonic_increasing\n",
    "# assert df.shape[0] > 30\n",
    "#\n",
    "# TODO: If you built transformed series (diff/logdiff), confirm no future leakage.\n",
    "# Hint: transformations should only use past/current values (shift/diff), never future.\n",
    "...\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extensions (Optional)\n",
    "- Try one additional variant beyond the main path (different features, different split, different model).\n",
    "- Write down what improved, what got worse, and your hypothesis for why.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reflection\n",
    "- What did you assume implicitly (about timing, availability, stationarity, or costs)?\n",
    "- If you had to ship this model, what would you monitor?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"solutions-reference\"></a>\n",
    "## Solutions (Reference)\n",
    "\n",
    "Try the TODOs first. Use these only to unblock yourself or to compare approaches.\n",
    "\n",
    "<details><summary>Solution: Build stationary dataset</summary>\n",
    "\n",
    "_One possible approach. Your variable names may differ; align them with the notebook._\n",
    "\n",
    "```python\n",
    "# Reference solution for 02_var_impulse_responses — Build stationary dataset\n",
    "import pandas as pd\n",
    "\n",
    "panel = pd.read_csv(SAMPLE_DIR / 'panel_monthly_sample.csv', index_col=0, parse_dates=True).dropna()\n",
    "df = panel[['UNRATE', 'FEDFUNDS', 'INDPRO']].astype(float).diff().dropna()\n",
    "df.head()\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "<details><summary>Solution: Fit VAR + choose lags</summary>\n",
    "\n",
    "_One possible approach. Your variable names may differ; align them with the notebook._\n",
    "\n",
    "```python\n",
    "# Reference solution for 02_var_impulse_responses — Fit VAR + choose lags\n",
    "from statsmodels.tsa.api import VAR\n",
    "\n",
    "res = VAR(df).fit(maxlags=8, ic='aic')\n",
    "res.k_ar\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "<details><summary>Solution: Granger causality</summary>\n",
    "\n",
    "_One possible approach. Your variable names may differ; align them with the notebook._\n",
    "\n",
    "```python\n",
    "# Reference solution for 02_var_impulse_responses — Granger causality\n",
    "# Example: do lagged FEDFUNDS help predict UNRATE?\n",
    "res.test_causality('UNRATE', ['FEDFUNDS']).summary()\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "<details><summary>Solution: IRFs + forecasting</summary>\n",
    "\n",
    "_One possible approach. Your variable names may differ; align them with the notebook._\n",
    "\n",
    "```python\n",
    "# Reference solution for 02_var_impulse_responses — IRFs + forecasting\n",
    "irf = res.irf(12)\n",
    "irf.plot(orth=True)\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}