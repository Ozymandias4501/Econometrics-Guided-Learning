{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 01 PCA Macro Factors\n",
        "\n",
        "Extract factors and interpret loadings.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Table of Contents\n",
        "- [Standardize](#standardize)\n",
        "- [Fit PCA](#fit-pca)\n",
        "- [Interpret loadings](#interpret-loadings)\n",
        "- [Checkpoint (Self-Check)](#checkpoint-self-check)\n",
        "- [Solutions (Reference)](#solutions-reference)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Why This Notebook Matters\n",
        "Unsupervised notebooks help you understand macro structure:\n",
        "- latent factors (PCA),\n",
        "- regimes (clustering),\n",
        "- anomalies/crises.\n",
        "\n",
        "\n",
        "## What You Will Produce\n",
        "- (no file output; learning/analysis notebook)\n",
        "\n",
        "## Success Criteria\n",
        "- You can explain what you built and why each step exists.\n",
        "- You can run your work end-to-end without undefined variables.\n",
        "\n",
        "## Common Pitfalls\n",
        "- Running cells top-to-bottom without reading the instructions.\n",
        "- Leaving `...` placeholders in code cells.\n",
        "- Forgetting to standardize features before PCA/clustering.\n",
        "- Over-interpreting clusters as causal regimes.\n",
        "\n",
        "## Matching Guide\n",
        "- `docs/guides/04_unsupervised/01_pca_macro_factors.md`\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## How To Use This Notebook\n",
        "- This notebook is hands-on. Most code cells are incomplete on purpose.\n",
        "- Complete each TODO, then run the cell.\n",
        "- Use the matching guide (`docs/guides/04_unsupervised/01_pca_macro_factors.md`) for deep explanations and alternative examples.\n",
        "- Write short interpretation notes as you go (what changed, why it matters).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"environment-bootstrap\"></a>\n",
        "## Environment Bootstrap\n",
        "Run this cell first. It makes the repo importable and defines common directories.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "from pathlib import Path\n",
        "import sys\n",
        "\n",
        "\n",
        "def find_repo_root(start: Path) -> Path:\n",
        "    p = start\n",
        "    for _ in range(8):\n",
        "        if (p / 'src').exists() and (p / 'docs').exists():\n",
        "            return p\n",
        "        p = p.parent\n",
        "    raise RuntimeError('Could not find repo root. Start Jupyter from the repo root.')\n",
        "\n",
        "\n",
        "PROJECT_ROOT = find_repo_root(Path.cwd())\n",
        "if str(PROJECT_ROOT) not in sys.path:\n",
        "    sys.path.append(str(PROJECT_ROOT))\n",
        "\n",
        "DATA_DIR = PROJECT_ROOT / 'data'\n",
        "RAW_DIR = DATA_DIR / 'raw'\n",
        "PROCESSED_DIR = DATA_DIR / 'processed'\n",
        "SAMPLE_DIR = DATA_DIR / 'sample'\n",
        "\n",
        "PROJECT_ROOT\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Goal\n",
        "Use PCA to extract a small number of macro factors from many indicators.\n",
        "\n",
        "Why PCA is useful here:\n",
        "- macro series are correlated\n",
        "- PCA creates orthogonal (uncorrelated) components\n",
        "- components can act like \"macro factors\" (growth, inflation, rates, etc.)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Primer: pandas Time Series Essentials\n",
        "\n",
        "### DatetimeIndex\n",
        "Most time series work in pandas assumes your DataFrame is indexed by time.\n",
        "\n",
        "```python\n",
        "import pandas as pd\n",
        "\n",
        "# idx = pd.to_datetime(df['date'])\n",
        "# df = df.set_index(idx).sort_index()\n",
        "# assert isinstance(df.index, pd.DatetimeIndex)\n",
        "```\n",
        "\n",
        "If you see weird behavior (resample errors, merges not aligning), check:\n",
        "- `df.index.dtype`\n",
        "- `df.index.min(), df.index.max()`\n",
        "- `df.index.is_monotonic_increasing`\n",
        "\n",
        "### Resampling\n",
        "> **Goal:** convert one frequency to another.\n",
        "\n",
        "Common examples:\n",
        "- daily -> month-end\n",
        "- monthly -> quarter-end\n",
        "\n",
        "```python\n",
        "# month-end last value\n",
        "# df_me_last = df.resample('ME').last()\n",
        "\n",
        "# month-end mean\n",
        "# df_me_mean = df.resample('ME').mean()\n",
        "\n",
        "# quarter-end mean\n",
        "# df_q_mean = df.resample('QE').mean()\n",
        "```\n",
        "\n",
        "**Interpretation matters.** For economic series:\n",
        "- using `.last()` treats the end-of-period value as \u201cthe period\u2019s value\u201d\n",
        "- using `.mean()` treats the period average as \u201cthe period\u2019s value\u201d\n",
        "\n",
        "Neither is universally correct; you should choose based on measurement and use case.\n",
        "\n",
        "### Alignment and merging\n",
        "When joining multiple time series, you need to ensure they share:\n",
        "- the same index type (`DatetimeIndex`)\n",
        "- the same frequency convention (month-end vs month-start; quarter-end vs quarter-start)\n",
        "\n",
        "```python\n",
        "# Example: join two series and inspect missingness\n",
        "# df = df1.join(df2, how='outer').sort_index()\n",
        "# print(df.isna().sum())\n",
        "```\n",
        "\n",
        "### Lags and rolling windows\n",
        "> **Lag:** use past values as features.\n",
        "\n",
        "```python\n",
        "# lag 1 period\n",
        "# df['x_lag1'] = df['x'].shift(1)\n",
        "\n",
        "# rolling mean (past-only)\n",
        "# df['x_roll12'] = df['x'].rolling(12).mean()\n",
        "```\n",
        "\n",
        "### Common gotchas\n",
        "- `shift(-1)` uses the future (leakage for forecasting).\n",
        "- `rolling(..., center=True)` uses future values.\n",
        "- Always `dropna()` after creating lags/rolls to get clean modeling rows.\n",
        "\n",
        "One more gotcha:\n",
        "- If you resample daily -> monthly and then create lags, your lag is \u201cone month\u201d (not one day). Lags are measured in the current index frequency.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"standardize\"></a>\n",
        "## Standardize\n",
        "\n",
        "### Goal\n",
        "Load a monthly panel and standardize features (mean 0, std 1).\n",
        "\n",
        "PCA is sensitive to scale: if one variable has larger units, it can dominate the components.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Your Turn (1): Load panel_monthly.csv (or sample)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "path = PROCESSED_DIR / 'panel_monthly.csv'\n",
        "if path.exists():\n",
        "    df = pd.read_csv(path, index_col=0, parse_dates=True)\n",
        "else:\n",
        "    df = pd.read_csv(SAMPLE_DIR / 'panel_monthly_sample.csv', index_col=0, parse_dates=True)\n",
        "\n",
        "df.head()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Your Turn (2): Build X and standardize\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "x_cols = df.columns.tolist()\n",
        "X = df[x_cols].dropna().copy()\n",
        "\n",
        "sc = StandardScaler().fit(X)\n",
        "X_s = sc.transform(X)\n",
        "\n",
        "# TODO: Validate standardization\n",
        "...\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"fit-pca\"></a>\n",
        "## Fit PCA\n",
        "\n",
        "### Goal\n",
        "Fit PCA and inspect explained variance.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Your Turn (1): Fit PCA\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "pca = PCA(n_components=3).fit(X_s)\n",
        "\n",
        "evr = pd.Series(pca.explained_variance_ratio_, index=[f'PC{i+1}' for i in range(pca.n_components_)])\n",
        "evr\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Your Turn (2): Scree plot\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# TODO: Plot explained variance ratio by component.\n",
        "...\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"interpret-loadings\"></a>\n",
        "## Interpret loadings\n",
        "\n",
        "### Goal\n",
        "Interpret what each component represents in economic terms.\n",
        "\n",
        "Loadings tell you which original variables contribute most to each component.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Your Turn (1): Build a loadings table\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "loadings = pd.DataFrame(\n",
        "    pca.components_.T,\n",
        "    index=x_cols,\n",
        "    columns=[f'PC{i+1}' for i in range(pca.n_components_)],\n",
        ")\n",
        "\n",
        "# TODO: For each PC, list the top + and top - loadings.\n",
        "...\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Your Turn (2): Name the components\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# TODO: Write a name/interpretation for PC1 and PC2.\n",
        "notes = \"\"\"\n",
        "PC1: ...\n",
        "PC2: ...\n",
        "\"\"\"\n",
        "print(notes)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"checkpoint-self-check\"></a>\n",
        "## Checkpoint (Self-Check)\n",
        "Run a few asserts and write 2-3 sentences summarizing what you verified.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# TODO: Confirm your feature matrix is standardized (or justify why not).\n",
        "# Example:\n",
        "# assert abs(X_scaled.mean(axis=0)).max() < 1e-6\n",
        "# assert abs(X_scaled.std(axis=0) - 1).max() < 1e-6\n",
        "...\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Extensions (Optional)\n",
        "- Try one additional variant beyond the main path (different features, different split, different model).\n",
        "- Write down what improved, what got worse, and your hypothesis for why.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Reflection\n",
        "- What did you assume implicitly (about timing, availability, stationarity, or costs)?\n",
        "- If you had to ship this model, what would you monitor?\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"solutions-reference\"></a>\n",
        "## Solutions (Reference)\n",
        "\n",
        "Try the TODOs first. Use these only to unblock yourself or to compare approaches.\n",
        "\n",
        "<details><summary>Solution: Standardize</summary>\n",
        "\n",
        "_One possible approach. Your variable names may differ; align them with the notebook._\n",
        "\n",
        "```python\n",
        "# Reference solution for 01_pca_macro_factors \u2014 Standardize\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "panel = pd.read_csv(SAMPLE_DIR / 'panel_monthly_sample.csv', index_col=0, parse_dates=True).dropna()\n",
        "X = StandardScaler().fit_transform(panel)\n",
        "```\n",
        "\n",
        "</details>\n",
        "\n",
        "<details><summary>Solution: Fit PCA</summary>\n",
        "\n",
        "_One possible approach. Your variable names may differ; align them with the notebook._\n",
        "\n",
        "```python\n",
        "# Reference solution for 01_pca_macro_factors \u2014 Fit PCA\n",
        "from sklearn.decomposition import PCA\n",
        "pca = PCA(n_components=3).fit(X)\n",
        "pca.explained_variance_ratio_\n",
        "```\n",
        "\n",
        "</details>\n",
        "\n",
        "<details><summary>Solution: Interpret loadings</summary>\n",
        "\n",
        "_One possible approach. Your variable names may differ; align them with the notebook._\n",
        "\n",
        "```python\n",
        "# Reference solution for 01_pca_macro_factors \u2014 Interpret loadings\n",
        "import pandas as pd\n",
        "loadings = pd.DataFrame(pca.components_.T, index=panel.columns, columns=[f'PC{i+1}' for i in range(pca.n_components_)])\n",
        "loadings.sort_values('PC1', key=abs, ascending=False).head(10)\n",
        "```\n",
        "\n",
        "</details>\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "python3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}