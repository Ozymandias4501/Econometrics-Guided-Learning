{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 02 Clustering Macro Regimes\n",
        "\n",
        "Cluster regimes and relate them to recessions.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Table of Contents\n",
        "- [Clustering](#clustering)\n",
        "- [Choose k](#choose-k)\n",
        "- [Relate to recessions](#relate-to-recessions)\n",
        "- [Checkpoint (Self-Check)](#checkpoint-self-check)\n",
        "- [Solutions (Reference)](#solutions-reference)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Why This Notebook Matters\n",
        "Unsupervised notebooks help you understand macro structure:\n",
        "- latent factors (PCA),\n",
        "- regimes (clustering),\n",
        "- anomalies/crises.\n",
        "\n",
        "\n",
        "## What You Will Produce\n",
        "- (no file output; learning/analysis notebook)\n",
        "\n",
        "## Success Criteria\n",
        "- You can explain what you built and why each step exists.\n",
        "- You can run your work end-to-end without undefined variables.\n",
        "\n",
        "## Common Pitfalls\n",
        "- Running cells top-to-bottom without reading the instructions.\n",
        "- Leaving `...` placeholders in code cells.\n",
        "- Forgetting to standardize features before PCA/clustering.\n",
        "- Over-interpreting clusters as causal regimes.\n",
        "\n",
        "## Matching Guide\n",
        "- `docs/guides/04_unsupervised/02_clustering_macro_regimes.md`\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## How To Use This Notebook\n",
        "- This notebook is hands-on. Most code cells are incomplete on purpose.\n",
        "- Complete each TODO, then run the cell.\n",
        "- Use the matching guide (`docs/guides/04_unsupervised/02_clustering_macro_regimes.md`) for deep explanations and alternative examples.\n",
        "- Write short interpretation notes as you go (what changed, why it matters).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"environment-bootstrap\"></a>\n",
        "## Environment Bootstrap\n",
        "Run this cell first. It makes the repo importable and defines common directories.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "from pathlib import Path\n",
        "import sys\n",
        "\n",
        "\n",
        "def find_repo_root(start: Path) -> Path:\n",
        "    p = start\n",
        "    for _ in range(8):\n",
        "        if (p / 'src').exists() and (p / 'docs').exists():\n",
        "            return p\n",
        "        p = p.parent\n",
        "    raise RuntimeError('Could not find repo root. Start Jupyter from the repo root.')\n",
        "\n",
        "\n",
        "PROJECT_ROOT = find_repo_root(Path.cwd())\n",
        "if str(PROJECT_ROOT) not in sys.path:\n",
        "    sys.path.append(str(PROJECT_ROOT))\n",
        "\n",
        "DATA_DIR = PROJECT_ROOT / 'data'\n",
        "RAW_DIR = DATA_DIR / 'raw'\n",
        "PROCESSED_DIR = DATA_DIR / 'processed'\n",
        "SAMPLE_DIR = DATA_DIR / 'sample'\n",
        "\n",
        "PROJECT_ROOT\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Goal\n",
        "Cluster macro periods into \"regimes\" and relate regimes to your technical recession label.\n",
        "\n",
        "Clustering is exploratory:\n",
        "- you are not predicting a target\n",
        "- you are summarizing structure in the data\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Primer: pandas Time Series Essentials\n",
        "\n",
        "### DatetimeIndex\n",
        "Most time series work in pandas assumes your DataFrame is indexed by time.\n",
        "\n",
        "```python\n",
        "import pandas as pd\n",
        "\n",
        "# idx = pd.to_datetime(df['date'])\n",
        "# df = df.set_index(idx).sort_index()\n",
        "# assert isinstance(df.index, pd.DatetimeIndex)\n",
        "```\n",
        "\n",
        "If you see weird behavior (resample errors, merges not aligning), check:\n",
        "- `df.index.dtype`\n",
        "- `df.index.min(), df.index.max()`\n",
        "- `df.index.is_monotonic_increasing`\n",
        "\n",
        "### Resampling\n",
        "> **Goal:** convert one frequency to another.\n",
        "\n",
        "Common examples:\n",
        "- daily -> month-end\n",
        "- monthly -> quarter-end\n",
        "\n",
        "```python\n",
        "# month-end last value\n",
        "# df_me_last = df.resample('ME').last()\n",
        "\n",
        "# month-end mean\n",
        "# df_me_mean = df.resample('ME').mean()\n",
        "\n",
        "# quarter-end mean\n",
        "# df_q_mean = df.resample('QE').mean()\n",
        "```\n",
        "\n",
        "**Interpretation matters.** For economic series:\n",
        "- using `.last()` treats the end-of-period value as \u201cthe period\u2019s value\u201d\n",
        "- using `.mean()` treats the period average as \u201cthe period\u2019s value\u201d\n",
        "\n",
        "Neither is universally correct; you should choose based on measurement and use case.\n",
        "\n",
        "### Alignment and merging\n",
        "When joining multiple time series, you need to ensure they share:\n",
        "- the same index type (`DatetimeIndex`)\n",
        "- the same frequency convention (month-end vs month-start; quarter-end vs quarter-start)\n",
        "\n",
        "```python\n",
        "# Example: join two series and inspect missingness\n",
        "# df = df1.join(df2, how='outer').sort_index()\n",
        "# print(df.isna().sum())\n",
        "```\n",
        "\n",
        "### Lags and rolling windows\n",
        "> **Lag:** use past values as features.\n",
        "\n",
        "```python\n",
        "# lag 1 period\n",
        "# df['x_lag1'] = df['x'].shift(1)\n",
        "\n",
        "# rolling mean (past-only)\n",
        "# df['x_roll12'] = df['x'].rolling(12).mean()\n",
        "```\n",
        "\n",
        "### Common gotchas\n",
        "- `shift(-1)` uses the future (leakage for forecasting).\n",
        "- `rolling(..., center=True)` uses future values.\n",
        "- Always `dropna()` after creating lags/rolls to get clean modeling rows.\n",
        "\n",
        "One more gotcha:\n",
        "- If you resample daily -> monthly and then create lags, your lag is \u201cone month\u201d (not one day). Lags are measured in the current index frequency.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"clustering\"></a>\n",
        "## Clustering\n",
        "\n",
        "### Goal\n",
        "Choose a feature representation and fit a clustering algorithm.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Your Turn (1): Load data and choose features to cluster\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "path = PROCESSED_DIR / 'macro_quarterly.csv'\n",
        "if path.exists():\n",
        "    df = pd.read_csv(path, index_col=0, parse_dates=True)\n",
        "else:\n",
        "    df = pd.read_csv(SAMPLE_DIR / 'macro_quarterly_sample.csv', index_col=0, parse_dates=True)\n",
        "\n",
        "# TODO: Choose a small set of features (levels or lags).\n",
        "x_cols = ['UNRATE', 'FEDFUNDS', 'CPIAUCSL', 'INDPRO', 'RSAFS', 'T10Y2Y']\n",
        "\n",
        "df_m = df[x_cols + ['recession']].dropna().copy()\n",
        "df_m.head()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Your Turn (2): Standardize features\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "sc = StandardScaler().fit(df_m[x_cols])\n",
        "X = sc.transform(df_m[x_cols])\n",
        "\n",
        "# TODO: sanity-check scaling (mean ~0, std ~1)\n",
        "...\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Your Turn (3): Fit a clustering model (KMeans)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "from sklearn.cluster import KMeans\n",
        "\n",
        "# TODO: Choose a k to start (you'll justify it in the next section)\n",
        "k = 4\n",
        "km = KMeans(n_clusters=k, random_state=0, n_init=20)\n",
        "labels = km.fit_predict(X)\n",
        "\n",
        "df_m['cluster'] = labels\n",
        "df_m['cluster'].value_counts()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"choose-k\"></a>\n",
        "## Choose k\n",
        "\n",
        "### Goal\n",
        "Try multiple k values and use a diagnostic to pick one.\n",
        "\n",
        "We'll use the silhouette score as a simple quantitative guide (not a proof).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Your Turn: Compute silhouette scores for k=2..6\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_score\n",
        "\n",
        "rows = []\n",
        "for k in range(2, 7):\n",
        "    km = KMeans(n_clusters=k, random_state=0, n_init=20)\n",
        "    lab = km.fit_predict(X)\n",
        "    rows.append({'k': k, 'silhouette': float(silhouette_score(X, lab))})\n",
        "\n",
        "pd.DataFrame(rows)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"relate-to-recessions\"></a>\n",
        "## Relate to recessions\n",
        "\n",
        "### Goal\n",
        "Relate cluster assignments to recession periods.\n",
        "\n",
        "A useful first question:\n",
        "- Which clusters have the highest recession rate?\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Your Turn (1): Recession rate by cluster\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "rate = df_m.groupby('cluster')['recession'].mean().sort_values(ascending=False)\n",
        "rate\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Your Turn (2): Visualize clusters over time\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# TODO: Plot one feature over time and color by cluster.\n",
        "# Or plot clusters as colored bands over the timeline.\n",
        "...\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"checkpoint-self-check\"></a>\n",
        "## Checkpoint (Self-Check)\n",
        "Run a few asserts and write 2-3 sentences summarizing what you verified.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# TODO: Confirm your feature matrix is standardized (or justify why not).\n",
        "# Example:\n",
        "# assert abs(X_scaled.mean(axis=0)).max() < 1e-6\n",
        "# assert abs(X_scaled.std(axis=0) - 1).max() < 1e-6\n",
        "...\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Extensions (Optional)\n",
        "- Try one additional variant beyond the main path (different features, different split, different model).\n",
        "- Write down what improved, what got worse, and your hypothesis for why.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Reflection\n",
        "- What did you assume implicitly (about timing, availability, stationarity, or costs)?\n",
        "- If you had to ship this model, what would you monitor?\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"solutions-reference\"></a>\n",
        "## Solutions (Reference)\n",
        "\n",
        "Try the TODOs first. Use these only to unblock yourself or to compare approaches.\n",
        "\n",
        "<details><summary>Solution: Clustering</summary>\n",
        "\n",
        "_One possible approach. Your variable names may differ; align them with the notebook._\n",
        "\n",
        "```python\n",
        "# Reference solution for 02_clustering_macro_regimes \u2014 Clustering\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "panel = pd.read_csv(SAMPLE_DIR / 'panel_monthly_sample.csv', index_col=0, parse_dates=True).dropna()\n",
        "X = StandardScaler().fit_transform(panel)\n",
        "kmeans = KMeans(n_clusters=4, random_state=0).fit(X)\n",
        "labels = pd.Series(kmeans.labels_, index=panel.index, name='cluster')\n",
        "labels.value_counts()\n",
        "```\n",
        "\n",
        "</details>\n",
        "\n",
        "<details><summary>Solution: Choose k</summary>\n",
        "\n",
        "_One possible approach. Your variable names may differ; align them with the notebook._\n",
        "\n",
        "```python\n",
        "# Reference solution for 02_clustering_macro_regimes \u2014 Choose k\n",
        "# Try k=3..6 and compare interpretability.\n",
        "```\n",
        "\n",
        "</details>\n",
        "\n",
        "<details><summary>Solution: Relate to recessions</summary>\n",
        "\n",
        "_One possible approach. Your variable names may differ; align them with the notebook._\n",
        "\n",
        "```python\n",
        "# Reference solution for 02_clustering_macro_regimes \u2014 Relate to recessions\n",
        "# Join monthly clusters to quarterly recession labels by resampling cluster mode to quarters.\n",
        "import pandas as pd\n",
        "gdp = pd.read_csv(SAMPLE_DIR / 'gdp_quarterly_sample.csv', index_col=0, parse_dates=True)\n",
        "cluster_q = labels.resample('QE').agg(lambda s: s.value_counts().index[0])\n",
        "joined = pd.DataFrame({'cluster': cluster_q}).join(gdp[['recession']], how='inner')\n",
        "pd.crosstab(joined['cluster'], joined['recession'])\n",
        "```\n",
        "\n",
        "</details>\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "python3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}