{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 02 Stats Basics for ML\n",
        "\n",
        "Correlation, collinearity, bias/variance, and overfitting basics.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Table of Contents\n",
        "- Correlation vs causation\n",
        "- Multicollinearity (VIF)\n",
        "- Bias/variance\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Why This Notebook Matters\n",
        "Foundations notebooks build the intuition that prevents the most common mistakes in economic ML:\n",
        "- leaking future information,\n",
        "- evaluating with the wrong split strategy,\n",
        "- over-interpreting coefficients.\n",
        "\n",
        "\n",
        "## What You Will Produce\n",
        "- (no file output; learning/analysis notebook)\n",
        "\n",
        "## Success Criteria\n",
        "- You can explain what you built and why each step exists.\n",
        "- You can run your work end-to-end without undefined variables.\n",
        "\n",
        "## Common Pitfalls\n",
        "- Running cells top-to-bottom without reading the instructions.\n",
        "- Leaving `...` placeholders in code cells.\n",
        "- Using random splits on time series.\n",
        "- Assuming correlation implies causation.\n",
        "\n",
        "## Matching Guide\n",
        "- `docs/guides/00_foundations/02_stats_basics_for_ml.md`\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## How To Use This Notebook\n",
        "- This notebook is hands-on. Most code cells are incomplete on purpose.\n",
        "- Complete each TODO, then run the cell.\n",
        "- Use the matching guide (`docs/guides/00_foundations/02_stats_basics_for_ml.md`) for deep explanations and alternative examples.\n",
        "- Write short interpretation notes as you go (what changed, why it matters).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Environment Bootstrap\n",
        "Run this cell first. It makes the repo importable and defines common directories.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "from pathlib import Path\n",
        "import sys\n",
        "\n",
        "\n",
        "def find_repo_root(start: Path) -> Path:\n",
        "    p = start\n",
        "    for _ in range(8):\n",
        "        if (p / 'src').exists() and (p / 'docs').exists():\n",
        "            return p\n",
        "        p = p.parent\n",
        "    raise RuntimeError('Could not find repo root. Start Jupyter from the repo root.')\n",
        "\n",
        "\n",
        "PROJECT_ROOT = find_repo_root(Path.cwd())\n",
        "if str(PROJECT_ROOT) not in sys.path:\n",
        "    sys.path.append(str(PROJECT_ROOT))\n",
        "\n",
        "DATA_DIR = PROJECT_ROOT / 'data'\n",
        "RAW_DIR = DATA_DIR / 'raw'\n",
        "PROCESSED_DIR = DATA_DIR / 'processed'\n",
        "SAMPLE_DIR = DATA_DIR / 'sample'\n",
        "\n",
        "PROJECT_ROOT\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Concept\n",
        "Core statistics ideas that show up constantly in ML: correlation, collinearity, bias/variance, and overfitting.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Your Turn: Correlation vs Causation\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# TODO: Simulate two correlated variables and a target\n",
        "# Then compute correlations and explain why correlation != causation\n",
        "...\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Your Turn: Multicollinearity (VIF)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# TODO: Create two nearly identical features\n",
        "# Compute VIF using src.econometrics.vif_table\n",
        "...\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Your Turn: Bias/Variance\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# TODO: Fit a simple model vs a more flexible model on synthetic data\n",
        "# Compare train vs test performance\n",
        "...\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Checkpoint (Self-Check)\n",
        "Run a few asserts and write 2-3 sentences summarizing what you verified.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# TODO: Run a quick sanity check on any DataFrame/Series you created in this notebook.\n",
        "# Example (adjust variable names):\n",
        "# assert df.index.is_monotonic_increasing\n",
        "# assert df.isna().sum().sum() == 0\n",
        "#\n",
        "# TODO: Write 2-3 sentences:\n",
        "# - What would leakage look like in YOUR code?\n",
        "# - How would you detect it?\n",
        "...\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Extensions (Optional)\n",
        "- Try one additional variant beyond the main path (different features, different split, different model).\n",
        "- Write down what improved, what got worse, and your hypothesis for why.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Reflection\n",
        "- What did you assume implicitly (about timing, availability, stationarity, or costs)?\n",
        "- If you had to ship this model, what would you monitor?\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Solutions (Reference)\n",
        "\n",
        "Try the TODOs first. Use these only to unblock yourself or to compare approaches.\n",
        "\n",
        "<details><summary>Solution: Correlation vs causation</summary>\n",
        "\n",
        "```python\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "rng = np.random.default_rng(0)\n",
        "n = 800\n",
        "z = rng.normal(size=n)\n",
        "x = z + rng.normal(scale=0.8, size=n)\n",
        "w = z + rng.normal(scale=0.8, size=n)\n",
        "y = 2.0*z + rng.normal(scale=1.0, size=n)\n",
        "df = pd.DataFrame({'x': x, 'w': w, 'y': y})\n",
        "df.corr()\n",
        "```\n",
        "\n",
        "</details>\n",
        "\n",
        "<details><summary>Solution: Multicollinearity (VIF)</summary>\n",
        "\n",
        "```python\n",
        "import statsmodels.api as sm\n",
        "from src.econometrics import vif_table\n",
        "\n",
        "# Make x2 highly correlated with x\n",
        "df['x2'] = df['x'] * 0.95 + np.random.default_rng(1).normal(scale=0.2, size=len(df))\n",
        "vif_table(df, ['x', 'x2'])\n",
        "\n",
        "X = sm.add_constant(df[['x', 'x2']])\n",
        "res = sm.OLS(df['y'], X).fit()\n",
        "res.summary()\n",
        "```\n",
        "\n",
        "</details>\n",
        "\n",
        "<details><summary>Solution: Bias/variance</summary>\n",
        "\n",
        "```python\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "X = df[['x']].to_numpy()\n",
        "y = df['y'].to_numpy()\n",
        "split = int(len(df) * 0.8)\n",
        "\n",
        "lin = LinearRegression().fit(X[:split], y[:split])\n",
        "tree = DecisionTreeRegressor(random_state=0).fit(X[:split], y[:split])\n",
        "\n",
        "rmse_lin_tr = mean_squared_error(y[:split], lin.predict(X[:split]), squared=False)\n",
        "rmse_lin_te = mean_squared_error(y[split:], lin.predict(X[split:]), squared=False)\n",
        "rmse_tree_tr = mean_squared_error(y[:split], tree.predict(X[:split]), squared=False)\n",
        "rmse_tree_te = mean_squared_error(y[split:], tree.predict(X[split:]), squared=False)\n",
        "\n",
        "(\n",
        "    {'linear_train': rmse_lin_tr, 'linear_test': rmse_lin_te},\n",
        "    {'tree_train': rmse_tree_tr, 'tree_test': rmse_tree_te},\n",
        ")\n",
        "```\n",
        "\n",
        "</details>\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "python3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}